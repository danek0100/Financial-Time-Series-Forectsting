{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Прогрессивный анализ влияния признаков на качество прогнозирования\n",
        "\n",
        "Этот ноутбук предназначен для анализа того, как поэтапное добавление различных типов признаков влияет на качество прогнозирования временных рядов.\n",
        "\n",
        "## Этапы анализа:\n",
        "1. **Базовая модель** - обучение только на ряду `close` (univariate)\n",
        "2. **+ Аномалии** - добавление колонки аномалий\n",
        "3. **+ Новости** - добавление взвешенной оценки новостей  \n",
        "4. **+ Паттерны свечей** - добавление паттернов японских свечей\n",
        "5. **+ Технические индикаторы** - добавление технических индикаторов\n",
        "6. **+ TSFresh признаки** - добавление статистических свойств временных рядов\n",
        "7. **+ PCA компоненты** - добавление сжатых признаков\n",
        "\n",
        "## Метрики оценки:\n",
        "- **RMSE** - среднеквадратичная ошибка\n",
        "- **MAPE** - средняя абсолютная процентная ошибка  \n",
        "- **DA** - точность направления (Directional Accuracy)\n",
        "\n",
        "## Модель:\n",
        "- **RandomForest** из DARTS с анализом важности признаков\n",
        "- **Горизонт прогноза**: последние 20 дней\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# DARTS библиотеки\n",
        "from darts import TimeSeries\n",
        "from darts.models import RandomForest\n",
        "from darts.metrics import rmse, mape\n",
        "from darts.utils.utils import SeasonalityMode, TrendMode\n",
        "\n",
        "# Библиотеки для анализа\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Настройка отображения\n",
        "plt.style.use('seaborn-v0_8')\n",
        "plt.rcParams['figure.figsize'] = (15, 8)\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "print(\"Библиотеки загружены успешно\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Пути к данным\n",
        "INPUT_PATH = 'data/multivariate_series/'\n",
        "OUTPUT_PATH = 'results/progressive_analysis/'\n",
        "\n",
        "# Создаем выходную папку если её нет\n",
        "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
        "\n",
        "# Список тикеров\n",
        "tickers = ['AFLT', 'LKOH', 'MOEX', 'NVTK', 'PIKK', 'SBER', 'VKCO', 'VTBR', 'X5', 'YDEX']\n",
        "\n",
        "# Параметры анализа\n",
        "FORECAST_HORIZON = 20  # Количество дней для прогноза\n",
        "TEST_SIZE = 30         # Размер тестовой выборки (больше чем горизонт прогноза)\n",
        "\n",
        "print(f\"Параметры анализа:\")\n",
        "print(f\"- Входные данные: {INPUT_PATH}\")\n",
        "print(f\"- Результаты: {OUTPUT_PATH}\")\n",
        "print(f\"- Горизонт прогноза: {FORECAST_HORIZON} дней\")\n",
        "print(f\"- Размер тестовой выборки: {TEST_SIZE} дней\")\n",
        "print(f\"- Тикеры для анализа: {tickers}\")\n",
        "\n",
        "# Загружаем данные\n",
        "data = {}\n",
        "for ticker in tickers:\n",
        "    try:\n",
        "        file_path = f\"{INPUT_PATH}{ticker}_multivariate.csv\"\n",
        "        df = pd.read_csv(file_path)\n",
        "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "        df = df.set_index('timestamp').sort_index()\n",
        "        data[ticker] = df\n",
        "        print(f\"Загружен {ticker}: {df.shape}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Ошибка загрузки {ticker}: {str(e)}\")\n",
        "\n",
        "print(f\"\\nУспешно загружено {len(data)} тикеров\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Вспомогательные функции\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_directional_accuracy(actual, predicted):\n",
        "    \"\"\"\n",
        "    Вычисляет точность направления (Directional Accuracy)\n",
        "    \n",
        "    Args:\n",
        "        actual: фактические значения\n",
        "        predicted: прогнозируемые значения\n",
        "    \n",
        "    Returns:\n",
        "        DA: точность направления (от 0 до 1)\n",
        "    \"\"\"\n",
        "    if len(actual) <= 1 or len(predicted) <= 1:\n",
        "        return np.nan\n",
        "    \n",
        "    # Направление изменения фактических значений\n",
        "    actual_direction = np.diff(actual) > 0\n",
        "    \n",
        "    # Направление изменения прогнозов\n",
        "    predicted_direction = np.diff(predicted) > 0\n",
        "    \n",
        "    # Точность направления\n",
        "    da = np.mean(actual_direction == predicted_direction)\n",
        "    \n",
        "    return da\n",
        "\n",
        "def prepare_features_for_stage(df, stage):\n",
        "    \"\"\"\n",
        "    Подготавливает признаки для определенного этапа анализа\n",
        "    \n",
        "    Args:\n",
        "        df: DataFrame с данными\n",
        "        stage: номер этапа (1-7)\n",
        "    \n",
        "    Returns:\n",
        "        feature_columns: список колонок для использования\n",
        "    \"\"\"\n",
        "    \n",
        "    # Базовые колонки (всегда исключаем)\n",
        "    base_exclude = ['open', 'high', 'low', 'volume', 'date', 'daily_headlines', 'return']\n",
        "    \n",
        "    if stage == 1:\n",
        "        # Этап 1: только close (univariate)\n",
        "        return ['close']\n",
        "    \n",
        "    elif stage == 2:\n",
        "        # Этап 2: + аномалии\n",
        "        features = ['close', 'anomaly']\n",
        "        return features\n",
        "    \n",
        "    elif stage == 3:\n",
        "        # Этап 3: + новости\n",
        "        features = ['close', 'anomaly', 'weighted_score_with_decay']\n",
        "        # Добавляем другие новостные признаки если есть\n",
        "        news_cols = [col for col in df.columns if col in ['kernai_daily_avg', 'gigachat_daily_avg', 'deepseek_daily_avg']]\n",
        "        features.extend(news_cols)\n",
        "        return features\n",
        "    \n",
        "    elif stage == 4:\n",
        "        # Этап 4: + паттерны свечей\n",
        "        features = ['close', 'anomaly', 'weighted_score_with_decay']\n",
        "        news_cols = [col for col in df.columns if col in ['kernai_daily_avg', 'gigachat_daily_avg', 'deepseek_daily_avg']]\n",
        "        features.extend(news_cols)\n",
        "        \n",
        "        # Добавляем паттерны\n",
        "        pattern_cols = [col for col in df.columns if 'Pattern_' in col or 'Bullish' in col or 'Bearish' in col or 'Overbought' in col]\n",
        "        features.extend(pattern_cols)\n",
        "        return features\n",
        "    \n",
        "    elif stage == 5:\n",
        "        # Этап 5: + технические индикаторы\n",
        "        features = ['close', 'anomaly', 'weighted_score_with_decay']\n",
        "        news_cols = [col for col in df.columns if col in ['kernai_daily_avg', 'gigachat_daily_avg', 'deepseek_daily_avg']]\n",
        "        features.extend(news_cols)\n",
        "        \n",
        "        pattern_cols = [col for col in df.columns if 'Pattern_' in col or 'Bullish' in col or 'Bearish' in col or 'Overbought' in col]\n",
        "        features.extend(pattern_cols)\n",
        "        \n",
        "        # Добавляем технические индикаторы\n",
        "        tech_indicators = ['SMA_14', 'SMA_50', 'EMA_14', 'EMA_50', 'RSI_14', 'MACD', 'MACD_signal', \n",
        "                          'BB_hband', 'BB_lband', 'ATR_14', 'OBV', 'VWAP']\n",
        "        tech_cols = [col for col in df.columns if any(indicator in col for indicator in tech_indicators)]\n",
        "        features.extend(tech_cols)\n",
        "        return features\n",
        "    \n",
        "    elif stage == 6:\n",
        "        # Этап 6: + TSFresh признаки\n",
        "        features = ['close', 'anomaly', 'weighted_score_with_decay']\n",
        "        news_cols = [col for col in df.columns if col in ['kernai_daily_avg', 'gigachat_daily_avg', 'deepseek_daily_avg']]\n",
        "        features.extend(news_cols)\n",
        "        \n",
        "        pattern_cols = [col for col in df.columns if 'Pattern_' in col or 'Bullish' in col or 'Bearish' in col or 'Overbought' in col]\n",
        "        features.extend(pattern_cols)\n",
        "        \n",
        "        tech_indicators = ['SMA_14', 'SMA_50', 'EMA_14', 'EMA_50', 'RSI_14', 'MACD', 'MACD_signal', \n",
        "                          'BB_hband', 'BB_lband', 'ATR_14', 'OBV', 'VWAP']\n",
        "        tech_cols = [col for col in df.columns if any(indicator in col for indicator in tech_indicators)]\n",
        "        features.extend(tech_cols)\n",
        "        \n",
        "        # Добавляем TSFresh признаки\n",
        "        tsfresh_cols = [col for col in df.columns if 'value__' in col]\n",
        "        features.extend(tsfresh_cols)\n",
        "        return features\n",
        "    \n",
        "    elif stage == 7:\n",
        "        # Этап 7: + PCA компоненты\n",
        "        features = ['close', 'anomaly', 'weighted_score_with_decay']\n",
        "        news_cols = [col for col in df.columns if col in ['kernai_daily_avg', 'gigachat_daily_avg', 'deepseek_daily_avg']]\n",
        "        features.extend(news_cols)\n",
        "        \n",
        "        pattern_cols = [col for col in df.columns if 'Pattern_' in col or 'Bullish' in col or 'Bearish' in col or 'Overbought' in col]\n",
        "        features.extend(pattern_cols)\n",
        "        \n",
        "        tech_indicators = ['SMA_14', 'SMA_50', 'EMA_14', 'EMA_50', 'RSI_14', 'MACD', 'MACD_signal', \n",
        "                          'BB_hband', 'BB_lband', 'ATR_14', 'OBV', 'VWAP']\n",
        "        tech_cols = [col for col in df.columns if any(indicator in col for indicator in tech_indicators)]\n",
        "        features.extend(tech_cols)\n",
        "        \n",
        "        tsfresh_cols = [col for col in df.columns if 'value__' in col]\n",
        "        features.extend(tsfresh_cols)\n",
        "        \n",
        "        # Добавляем PCA компоненты\n",
        "        pca_cols = [col for col in df.columns if col.startswith('PCA_')]\n",
        "        features.extend(pca_cols)\n",
        "        return features\n",
        "    \n",
        "    else:\n",
        "        raise ValueError(f\"Неподдерживаемый этап: {stage}\")\n",
        "\n",
        "def evaluate_model_for_ticker(df, ticker, stage):\n",
        "    \"\"\"\n",
        "    Обучает модель и оценивает её для одного тикера на определенном этапе\n",
        "    Использует стратегию \"точка за точкой\" для честного прогнозирования\n",
        "    \n",
        "    Args:\n",
        "        df: DataFrame с данными тикера\n",
        "        ticker: название тикера\n",
        "        stage: номер этапа (1-7)\n",
        "    \n",
        "    Returns:\n",
        "        results: словарь с метриками и важностью признаков\n",
        "    \"\"\"\n",
        "    \n",
        "    try:\n",
        "        # Подготавливаем признаки для этапа\n",
        "        feature_columns = prepare_features_for_stage(df, stage)\n",
        "        \n",
        "        # Проверяем наличие всех колонок\n",
        "        available_features = [col for col in feature_columns if col in df.columns]\n",
        "        \n",
        "        if len(available_features) == 0:\n",
        "            print(f\"  - Нет доступных признаков для {ticker} на этапе {stage}\")\n",
        "            return None\n",
        "        \n",
        "        # Удаляем строки с NaN в выбранных признаках\n",
        "        df_clean = df[available_features].dropna()\n",
        "        \n",
        "        if len(df_clean) < TEST_SIZE + 10:  # Минимум данных для обучения\n",
        "            print(f\"  - Недостаточно данных для {ticker} на этапе {stage}\")\n",
        "            return None\n",
        "        \n",
        "        # Готовим данные для DARTS\n",
        "        if stage == 1:\n",
        "            # Univariate модель\n",
        "            ts = TimeSeries.from_dataframe(\n",
        "                df_clean, \n",
        "                time_col=None, \n",
        "                value_cols='close',\n",
        "                fill_missing_dates=True,\n",
        "                freq='D'\n",
        "            )\n",
        "            \n",
        "            # Обучаем модель на всех данных кроме тестовых\n",
        "            train_ts = ts[:-TEST_SIZE]\n",
        "            \n",
        "            # Обучаем univariate модель\n",
        "            model = RandomForest(lags=14, random_state=42)\n",
        "            model.fit(train_ts)\n",
        "            \n",
        "            # Прогнозирование точка за точкой\n",
        "            predictions = []\n",
        "            current_ts = ts[:-TEST_SIZE]  # Начинаем с обучающих данных\n",
        "            \n",
        "            for i in range(FORECAST_HORIZON):\n",
        "                # Делаем прогноз на 1 шаг вперед\n",
        "                pred = model.predict(n=1)\n",
        "                predictions.append(pred.values().flatten()[0])\n",
        "                \n",
        "                # Добавляем реальное значение к истории для следующего прогноза\n",
        "                actual_value = ts[len(current_ts)].values().flatten()[0]\n",
        "                actual_ts = TimeSeries.from_values(\n",
        "                    [actual_value], \n",
        "                    start=ts[len(current_ts)].start_time(),\n",
        "                    freq='D'\n",
        "                )\n",
        "                current_ts = current_ts.append(actual_ts)\n",
        "            \n",
        "            # Важность признаков недоступна для univariate\n",
        "            feature_importance = {}\n",
        "            \n",
        "        else:\n",
        "            # Multivariate модель\n",
        "            target_col = 'close'\n",
        "            past_covariates_cols = [col for col in available_features if col != target_col]\n",
        "            \n",
        "            if len(past_covariates_cols) == 0:\n",
        "                # Fallback к univariate если нет ковариат\n",
        "                ts = TimeSeries.from_dataframe(\n",
        "                    df_clean, \n",
        "                    time_col=None, \n",
        "                    value_cols=target_col,\n",
        "                    fill_missing_dates=True,\n",
        "                    freq='D'\n",
        "                )\n",
        "                train_ts = ts[:-TEST_SIZE]\n",
        "                \n",
        "                model = RandomForest(lags=14, random_state=42)\n",
        "                model.fit(train_ts)\n",
        "                \n",
        "                # Прогнозирование точка за точкой\n",
        "                predictions = []\n",
        "                current_ts = ts[:-TEST_SIZE]\n",
        "                \n",
        "                for i in range(FORECAST_HORIZON):\n",
        "                    pred = model.predict(n=1)\n",
        "                    predictions.append(pred.values().flatten()[0])\n",
        "                    \n",
        "                    actual_value = ts[len(current_ts)].values().flatten()[0]\n",
        "                    actual_ts = TimeSeries.from_values(\n",
        "                        [actual_value], \n",
        "                        start=ts[len(current_ts)].start_time(),\n",
        "                        freq='D'\n",
        "                    )\n",
        "                    current_ts = current_ts.append(actual_ts)\n",
        "                \n",
        "                feature_importance = {}\n",
        "                \n",
        "            else:\n",
        "                # Создаем TimeSeries для цели и ковариат\n",
        "                target_ts = TimeSeries.from_dataframe(\n",
        "                    df_clean, \n",
        "                    time_col=None, \n",
        "                    value_cols=target_col,\n",
        "                    fill_missing_dates=True,\n",
        "                    freq='D'\n",
        "                )\n",
        "                past_covariates_ts = TimeSeries.from_dataframe(\n",
        "                    df_clean, \n",
        "                    time_col=None, \n",
        "                    value_cols=past_covariates_cols,\n",
        "                    fill_missing_dates=True,\n",
        "                    freq='D'\n",
        "                )\n",
        "                \n",
        "                # Обучаем на данных до тестового периода\n",
        "                train_target = target_ts[:-TEST_SIZE]\n",
        "                train_covariates = past_covariates_ts[:-TEST_SIZE]\n",
        "                \n",
        "                # Обучаем multivariate модель\n",
        "                model = RandomForest(\n",
        "                    lags=14,\n",
        "                    lags_past_covariates=7,\n",
        "                    random_state=42\n",
        "                )\n",
        "                \n",
        "                model.fit(\n",
        "                    series=train_target,\n",
        "                    past_covariates=train_covariates\n",
        "                )\n",
        "                \n",
        "                # Прогнозирование точка за точкой\n",
        "                predictions = []\n",
        "                current_target = target_ts[:-TEST_SIZE]\n",
        "                current_covariates = past_covariates_ts[:-TEST_SIZE]\n",
        "                \n",
        "                for i in range(FORECAST_HORIZON):\n",
        "                    # Делаем прогноз на 1 шаг вперед\n",
        "                    pred = model.predict(\n",
        "                        n=1,\n",
        "                        past_covariates=current_covariates\n",
        "                    )\n",
        "                    predictions.append(pred.values().flatten()[0])\n",
        "                    \n",
        "                    # Добавляем реальные значения к истории\n",
        "                    actual_target_value = target_ts[len(current_target)].values().flatten()[0]\n",
        "                    actual_target_ts = TimeSeries.from_values(\n",
        "                        [actual_target_value], \n",
        "                        start=target_ts[len(current_target)].start_time(),\n",
        "                        freq='D'\n",
        "                    )\n",
        "                    current_target = current_target.append(actual_target_ts)\n",
        "                    \n",
        "                    # Добавляем реальные значения ковариат\n",
        "                    actual_covariates_values = past_covariates_ts[len(current_covariates)].values()\n",
        "                    actual_covariates_ts = TimeSeries.from_values(\n",
        "                        actual_covariates_values, \n",
        "                        start=past_covariates_ts[len(current_covariates)].start_time(),\n",
        "                        freq='D'\n",
        "                    )\n",
        "                    current_covariates = current_covariates.append(actual_covariates_ts)\n",
        "                \n",
        "                # Извлекаем важность признаков\n",
        "                if hasattr(model.model, 'feature_importances_'):\n",
        "                    importance_values = model.model.feature_importances_\n",
        "                    # Создаем названия признаков (lags + past_covariates)\n",
        "                    feature_names = []\n",
        "                    for lag in range(1, 15):  # lags=14\n",
        "                        feature_names.append(f'{target_col}_lag_{lag}')\n",
        "                    for lag in range(1, 8):   # lags_past_covariates=7\n",
        "                        for col in past_covariates_cols:\n",
        "                            feature_names.append(f'{col}_lag_{lag}')\n",
        "                    \n",
        "                    feature_importance = dict(zip(feature_names[:len(importance_values)], importance_values))\n",
        "                else:\n",
        "                    feature_importance = {}\n",
        "        \n",
        "        # Получаем реальные значения для сравнения\n",
        "        actual_values = ts[-TEST_SIZE:-TEST_SIZE+FORECAST_HORIZON].values().flatten()\n",
        "        predicted_values = np.array(predictions)\n",
        "        \n",
        "        # Убеждаемся что размеры совпадают\n",
        "        min_length = min(len(actual_values), len(predicted_values))\n",
        "        actual_values = actual_values[:min_length]\n",
        "        predicted_values = predicted_values[:min_length]\n",
        "        \n",
        "        if min_length == 0:\n",
        "            print(f\"  - Пустые прогнозы для {ticker} на этапе {stage}\")\n",
        "            return None\n",
        "        \n",
        "        # RMSE\n",
        "        rmse_value = np.sqrt(mean_squared_error(actual_values, predicted_values))\n",
        "        \n",
        "        # MAPE\n",
        "        mape_value = mean_absolute_percentage_error(actual_values, predicted_values) * 100\n",
        "        \n",
        "        # DA (Directional Accuracy)\n",
        "        da_value = calculate_directional_accuracy(actual_values, predicted_values)\n",
        "        \n",
        "        results = {\n",
        "            'ticker': ticker,\n",
        "            'stage': stage,\n",
        "            'rmse': rmse_value,\n",
        "            'mape': mape_value,\n",
        "            'da': da_value,\n",
        "            'feature_count': len(available_features),\n",
        "            'feature_importance': feature_importance\n",
        "        }\n",
        "        \n",
        "        print(f\"  - {ticker}: RMSE={rmse_value:.4f}, MAPE={mape_value:.2f}%, DA={da_value:.3f}, Features={len(available_features)}\")\n",
        "        \n",
        "        return results\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"  - Ошибка для {ticker} на этапе {stage}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "print(\"Вспомогательные функции определены\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Прогрессивный анализ по этапам\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Определяем названия этапов\n",
        "stage_names = {\n",
        "    1: \"Базовая модель (close)\",\n",
        "    2: \"+ Аномалии\", \n",
        "    3: \"+ Новости\",\n",
        "    4: \"+ Паттерны свечей\",\n",
        "    5: \"+ Технические индикаторы\",\n",
        "    6: \"+ TSFresh признаки\", \n",
        "    7: \"+ PCA компоненты\"\n",
        "}\n",
        "\n",
        "# Контейнер для результатов\n",
        "all_results = []\n",
        "stage_summaries = []\n",
        "\n",
        "print(\"🚀 Начинаем прогрессивный анализ влияния признаков\\n\")\n",
        "\n",
        "# Проходим по всем этапам\n",
        "for stage in range(1, 8):\n",
        "    print(f\"📊 ЭТАП {stage}: {stage_names[stage]}\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    stage_results = []\n",
        "    \n",
        "    # Оцениваем каждый тикер на текущем этапе\n",
        "    for ticker in tickers:\n",
        "        if ticker in data:\n",
        "            result = evaluate_model_for_ticker(data[ticker], ticker, stage)\n",
        "            if result is not None:\n",
        "                all_results.append(result)\n",
        "                stage_results.append(result)\n",
        "    \n",
        "    # Вычисляем средние метрики по этапу\n",
        "    if stage_results:\n",
        "        avg_rmse = np.mean([r['rmse'] for r in stage_results])\n",
        "        avg_mape = np.mean([r['mape'] for r in stage_results])\n",
        "        avg_da = np.mean([r['da'] for r in stage_results if not np.isnan(r['da'])])\n",
        "        avg_features = np.mean([r['feature_count'] for r in stage_results])\n",
        "        \n",
        "        stage_summary = {\n",
        "            'stage': stage,\n",
        "            'stage_name': stage_names[stage],\n",
        "            'avg_rmse': avg_rmse,\n",
        "            'avg_mape': avg_mape,\n",
        "            'avg_da': avg_da,\n",
        "            'avg_features': avg_features,\n",
        "            'ticker_count': len(stage_results)\n",
        "        }\n",
        "        \n",
        "        stage_summaries.append(stage_summary)\n",
        "        \n",
        "        print(f\"\\n📈 Средние результаты этапа {stage}:\")\n",
        "        print(f\"   RMSE: {avg_rmse:.4f}\")\n",
        "        print(f\"   MAPE: {avg_mape:.2f}%\")\n",
        "        print(f\"   DA: {avg_da:.3f}\")\n",
        "        print(f\"   Признаков: {avg_features:.1f}\")\n",
        "        print(f\"   Успешных тикеров: {len(stage_results)}/{len(tickers)}\")\n",
        "    else:\n",
        "        print(f\"❌ Нет успешных результатов для этапа {stage}\")\n",
        "    \n",
        "    print(\"\\\\n\" + \"=\"*50 + \"\\\\n\")\n",
        "\n",
        "print(f\"✅ Анализ завершен! Собрано {len(all_results)} результатов из {len(stage_summaries)} этапов\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Итоговая таблица результатов\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Создаем итоговую таблицу\n",
        "results_df = pd.DataFrame(stage_summaries)\n",
        "\n",
        "if not results_df.empty:\n",
        "    print(\"📊 ИТОГОВАЯ ТАБЛИЦА РЕЗУЛЬТАТОВ\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    # Форматируем таблицу для красивого отображения\n",
        "    display_df = results_df.copy()\n",
        "    display_df['RMSE'] = display_df['avg_rmse'].apply(lambda x: f\"{x:.4f}\")\n",
        "    display_df['MAPE (%)'] = display_df['avg_mape'].apply(lambda x: f\"{x:.2f}\")\n",
        "    display_df['DA'] = display_df['avg_da'].apply(lambda x: f\"{x:.3f}\")\n",
        "    display_df['Признаков'] = display_df['avg_features'].apply(lambda x: f\"{x:.0f}\")\n",
        "    display_df['Тикеров'] = display_df['ticker_count'].apply(lambda x: f\"{x}\")\n",
        "    \n",
        "    # Выбираем колонки для отображения\n",
        "    final_table = display_df[['stage', 'stage_name', 'RMSE', 'MAPE (%)', 'DA', 'Признаков', 'Тикеров']].copy()\n",
        "    final_table.columns = ['Этап', 'Описание', 'RMSE', 'MAPE (%)', 'DA', 'Признаков', 'Тикеров']\n",
        "    \n",
        "    print(final_table.to_string(index=False))\n",
        "    \n",
        "    # Сохраняем таблицу\n",
        "    results_df.to_csv(f\"{OUTPUT_PATH}progressive_analysis_summary.csv\", index=False)\n",
        "    final_table.to_csv(f\"{OUTPUT_PATH}progressive_analysis_formatted.csv\", index=False)\n",
        "    \n",
        "    print(f\"\\\\n💾 Результаты сохранены в {OUTPUT_PATH}\")\n",
        "    \n",
        "    # Показываем изменения метрик относительно базовой модели\n",
        "    if len(results_df) > 1:\n",
        "        base_rmse = results_df.iloc[0]['avg_rmse']\n",
        "        base_mape = results_df.iloc[0]['avg_mape'] \n",
        "        base_da = results_df.iloc[0]['avg_da']\n",
        "        \n",
        "        print(\"\\\\n📈 ИЗМЕНЕНИЯ ОТНОСИТЕЛЬНО БАЗОВОЙ МОДЕЛИ:\")\n",
        "        print(\"=\" * 60)\n",
        "        \n",
        "        for i, row in results_df.iterrows():\n",
        "            if i == 0:\n",
        "                continue  # Пропускаем базовую модель\n",
        "                \n",
        "            rmse_change = ((row['avg_rmse'] - base_rmse) / base_rmse) * 100\n",
        "            mape_change = ((row['avg_mape'] - base_mape) / base_mape) * 100\n",
        "            da_change = ((row['avg_da'] - base_da) / base_da) * 100\n",
        "            \n",
        "            print(f\"Этап {row['stage']} - {row['stage_name']}:\")\n",
        "            print(f\"  RMSE: {rmse_change:+.1f}% ({'улучшение' if rmse_change < 0 else 'ухудшение'})\")\n",
        "            print(f\"  MAPE: {mape_change:+.1f}% ({'улучшение' if mape_change < 0 else 'ухудшение'})\")\n",
        "            print(f\"  DA: {da_change:+.1f}% ({'улучшение' if da_change > 0 else 'ухудшение'})\")\n",
        "            print()\n",
        "            \n",
        "else:\n",
        "    print(\"❌ Нет данных для создания итоговой таблицы\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Визуализация изменения метрик\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not results_df.empty:\n",
        "    # Создаем графики изменения метрик\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "    fig.suptitle('Прогрессивное изменение метрик качества прогнозирования', fontsize=16, fontweight='bold')\n",
        "    \n",
        "    # График 1: RMSE\n",
        "    axes[0,0].plot(results_df['stage'], results_df['avg_rmse'], 'o-', linewidth=2, markersize=8, color='red')\n",
        "    axes[0,0].set_title('RMSE (среднеквадратичная ошибка)', fontweight='bold')\n",
        "    axes[0,0].set_xlabel('Этап')\n",
        "    axes[0,0].set_ylabel('RMSE')\n",
        "    axes[0,0].grid(True, alpha=0.3)\n",
        "    axes[0,0].set_xticks(results_df['stage'])\n",
        "    \n",
        "    # График 2: MAPE\n",
        "    axes[0,1].plot(results_df['stage'], results_df['avg_mape'], 'o-', linewidth=2, markersize=8, color='orange')\n",
        "    axes[0,1].set_title('MAPE (средняя абсолютная процентная ошибка)', fontweight='bold')\n",
        "    axes[0,1].set_xlabel('Этап')\n",
        "    axes[0,1].set_ylabel('MAPE (%)')\n",
        "    axes[0,1].grid(True, alpha=0.3)\n",
        "    axes[0,1].set_xticks(results_df['stage'])\n",
        "    \n",
        "    # График 3: DA\n",
        "    axes[1,0].plot(results_df['stage'], results_df['avg_da'], 'o-', linewidth=2, markersize=8, color='green')\n",
        "    axes[1,0].set_title('DA (точность направления)', fontweight='bold')\n",
        "    axes[1,0].set_xlabel('Этап')\n",
        "    axes[1,0].set_ylabel('DA')\n",
        "    axes[1,0].grid(True, alpha=0.3)\n",
        "    axes[1,0].set_xticks(results_df['stage'])\n",
        "    axes[1,0].set_ylim(0, 1)\n",
        "    \n",
        "    # График 4: Количество признаков\n",
        "    axes[1,1].plot(results_df['stage'], results_df['avg_features'], 'o-', linewidth=2, markersize=8, color='purple')\n",
        "    axes[1,1].set_title('Количество признаков', fontweight='bold')\n",
        "    axes[1,1].set_xlabel('Этап')\n",
        "    axes[1,1].set_ylabel('Количество признаков')\n",
        "    axes[1,1].grid(True, alpha=0.3)\n",
        "    axes[1,1].set_xticks(results_df['stage'])\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{OUTPUT_PATH}metrics_progression.png\", dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    # Создаем heatmap сравнения метрик\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
        "    \n",
        "    # Подготавливаем данные для heatmap\n",
        "    heatmap_data = results_df[['stage', 'avg_rmse', 'avg_mape', 'avg_da']].copy()\n",
        "    \n",
        "    # Нормализуем данные для лучшей визуализации (min-max scaling)\n",
        "    for col in ['avg_rmse', 'avg_mape', 'avg_da']:\n",
        "        min_val = heatmap_data[col].min()\n",
        "        max_val = heatmap_data[col].max()\n",
        "        if max_val > min_val:\n",
        "            heatmap_data[col] = (heatmap_data[col] - min_val) / (max_val - min_val)\n",
        "    \n",
        "    # Для RMSE и MAPE - инвертируем (меньше = лучше)\n",
        "    heatmap_data['avg_rmse'] = 1 - heatmap_data['avg_rmse']\n",
        "    heatmap_data['avg_mape'] = 1 - heatmap_data['avg_mape']\n",
        "    \n",
        "    # Создаем heatmap\n",
        "    heatmap_matrix = heatmap_data[['avg_rmse', 'avg_mape', 'avg_da']].T\n",
        "    heatmap_matrix.columns = [f\"Этап {i}\" for i in results_df['stage']]\n",
        "    heatmap_matrix.index = ['RMSE (норм.)', 'MAPE (норм.)', 'DA']\n",
        "    \n",
        "    sns.heatmap(heatmap_matrix, annot=True, cmap='RdYlGn', center=0.5, \n",
        "                cbar_kws={'label': 'Качество (нормализовано)'}, ax=ax)\n",
        "    ax.set_title('Тепловая карта качества моделей по этапам\\\\n(зеленый = лучше, красный = хуже)', \n",
        "                 fontweight='bold', fontsize=14)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{OUTPUT_PATH}quality_heatmap.png\", dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "else:\n",
        "    print(\"❌ Нет данных для визуализации\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Анализ важности признаков\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Анализ важности признаков по этапам\n",
        "print(\"🎯 АНАЛИЗ ВАЖНОСТИ ПРИЗНАКОВ ПО ЭТАПАМ\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Собираем важность признаков для каждого этапа\n",
        "stage_importance = {}\n",
        "\n",
        "for result in all_results:\n",
        "    stage = result['stage']\n",
        "    if stage not in stage_importance:\n",
        "        stage_importance[stage] = {}\n",
        "    \n",
        "    # Агрегируем важность признаков по тикерам\n",
        "    for feature, importance in result['feature_importance'].items():\n",
        "        if feature not in stage_importance[stage]:\n",
        "            stage_importance[stage][feature] = []\n",
        "        stage_importance[stage][feature].append(importance)\n",
        "\n",
        "# Вычисляем средние значения важности для каждого этапа\n",
        "avg_importance = {}\n",
        "for stage, features in stage_importance.items():\n",
        "    avg_importance[stage] = {}\n",
        "    for feature, values in features.items():\n",
        "        avg_importance[stage][feature] = np.mean(values)\n",
        "\n",
        "# Выводим топ-10 важных признаков для каждого этапа\n",
        "for stage in sorted(avg_importance.keys()):\n",
        "    if stage == 1:\n",
        "        print(f\"\\\\n📊 Этап {stage}: {stage_names[stage]}\")\n",
        "        print(\"   (Важность признаков недоступна для univariate модели)\")\n",
        "        continue\n",
        "        \n",
        "    print(f\"\\\\n📊 Этап {stage}: {stage_names[stage]}\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    # Сортируем по важности\n",
        "    sorted_features = sorted(avg_importance[stage].items(), key=lambda x: x[1], reverse=True)\n",
        "    \n",
        "    if sorted_features:\n",
        "        print(\"   Топ-10 важных признаков:\")\n",
        "        for i, (feature, importance) in enumerate(sorted_features[:10], 1):\n",
        "            print(f\"   {i:2d}. {feature}: {importance:.4f}\")\n",
        "    else:\n",
        "        print(\"   Нет данных о важности признаков\")\n",
        "\n",
        "# Создаем визуализацию важности признаков для последнего этапа\n",
        "if avg_importance:\n",
        "    last_stage = max(avg_importance.keys())\n",
        "    if last_stage in avg_importance and avg_importance[last_stage]:\n",
        "        \n",
        "        print(f\"\\\\n🎨 Создание визуализации важности признаков для этапа {last_stage}\")\n",
        "        \n",
        "        # Берем топ-20 признаков для визуализации\n",
        "        sorted_features = sorted(avg_importance[last_stage].items(), key=lambda x: x[1], reverse=True)\n",
        "        top_features = sorted_features[:20]\n",
        "        \n",
        "        if top_features:\n",
        "            features_names = [f[0] for f in top_features]\n",
        "            features_importance = [f[1] for f in top_features]\n",
        "            \n",
        "            # Создаем горизонтальную диаграмму\n",
        "            fig, ax = plt.subplots(1, 1, figsize=(12, 10))\n",
        "            \n",
        "            bars = ax.barh(range(len(features_names)), features_importance, color='skyblue', alpha=0.8)\n",
        "            \n",
        "            # Настраиваем оси\n",
        "            ax.set_yticks(range(len(features_names)))\n",
        "            ax.set_yticklabels(features_names, fontsize=10)\n",
        "            ax.set_xlabel('Важность признака', fontsize=12)\n",
        "            ax.set_title(f'Топ-20 важных признаков - {stage_names[last_stage]}', fontsize=14, fontweight='bold')\n",
        "            \n",
        "            # Добавляем значения на столбцы\n",
        "            for i, bar in enumerate(bars):\n",
        "                width = bar.get_width()\n",
        "                ax.text(width + width*0.01, bar.get_y() + bar.get_height()/2, \n",
        "                       f'{width:.4f}', ha='left', va='center', fontsize=9)\n",
        "            \n",
        "            # Инвертируем порядок для лучшего отображения\n",
        "            ax.invert_yaxis()\n",
        "            ax.grid(axis='x', alpha=0.3)\n",
        "            \n",
        "            plt.tight_layout()\n",
        "            plt.savefig(f\"{OUTPUT_PATH}feature_importance_stage_{last_stage}.png\", dpi=300, bbox_inches='tight')\n",
        "            plt.show()\n",
        "\n",
        "# Создаем сводную таблицу важности признаков\n",
        "print(\"\\\\n📋 СВОДНАЯ ТАБЛИЦА ВАЖНОСТИ ПРИЗНАКОВ\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Создаем DataFrame для важности признаков\n",
        "importance_data = []\n",
        "for stage in sorted(avg_importance.keys()):\n",
        "    if stage == 1:\n",
        "        continue  # Пропускаем univariate модель\n",
        "    \n",
        "    sorted_features = sorted(avg_importance[stage].items(), key=lambda x: x[1], reverse=True)\n",
        "    for rank, (feature, importance) in enumerate(sorted_features[:5], 1):  # Топ-5 для каждого этапа\n",
        "        importance_data.append({\n",
        "            'Этап': stage,\n",
        "            'Описание этапа': stage_names[stage],\n",
        "            'Ранг': rank,\n",
        "            'Признак': feature,\n",
        "            'Важность': importance\n",
        "        })\n",
        "\n",
        "if importance_data:\n",
        "    importance_df = pd.DataFrame(importance_data)\n",
        "    \n",
        "    # Группируем по этапам и выводим\n",
        "    for stage in sorted(importance_df['Этап'].unique()):\n",
        "        stage_data = importance_df[importance_df['Этап'] == stage]\n",
        "        print(f\"\\\\nЭтап {stage}: {stage_data.iloc[0]['Описание этапа']}\")\n",
        "        for _, row in stage_data.iterrows():\n",
        "            print(f\"  {row['Ранг']}. {row['Признак']}: {row['Важность']:.4f}\")\n",
        "    \n",
        "    # Сохраняем в файл\n",
        "    importance_df.to_csv(f\"{OUTPUT_PATH}feature_importance_summary.csv\", index=False)\n",
        "    print(f\"\\\\n💾 Таблица важности признаков сохранена в {OUTPUT_PATH}feature_importance_summary.csv\")\n",
        "\n",
        "print(\"\\\\n✅ Анализ важности признаков завершен!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Выводы и рекомендации\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"🎯 РЕЗЮМЕ ПРОГРЕССИВНОГО АНАЛИЗА\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "if results_df.empty:\n",
        "    print(\"❌ Нет результатов для анализа\")\n",
        "else:\n",
        "    print(f\"✅ Проанализировано {len(results_df)} этапов для {len(tickers)} тикеров\")\n",
        "    print(f\"📊 Собрано {len(all_results)} успешных результатов\")\n",
        "    \n",
        "    # Найдем лучший этап по каждой метрике\n",
        "    best_rmse_stage = results_df.loc[results_df['avg_rmse'].idxmin()]\n",
        "    best_mape_stage = results_df.loc[results_df['avg_mape'].idxmin()]\n",
        "    best_da_stage = results_df.loc[results_df['avg_da'].idxmax()]\n",
        "    \n",
        "    print(\"\\\\n🏆 ЛУЧШИЕ РЕЗУЛЬТАТЫ:\")\n",
        "    print(f\"   Лучший RMSE: Этап {best_rmse_stage['stage']} ({best_rmse_stage['stage_name']}) - {best_rmse_stage['avg_rmse']:.4f}\")\n",
        "    print(f\"   Лучший MAPE: Этап {best_mape_stage['stage']} ({best_mape_stage['stage_name']}) - {best_mape_stage['avg_mape']:.2f}%\")\n",
        "    print(f\"   Лучший DA: Этап {best_da_stage['stage']} ({best_da_stage['stage_name']}) - {best_da_stage['avg_da']:.3f}\")\n",
        "    \n",
        "    # Анализ тренда качества\n",
        "    base_metrics = results_df.iloc[0]\n",
        "    final_metrics = results_df.iloc[-1]\n",
        "    \n",
        "    rmse_change = ((final_metrics['avg_rmse'] - base_metrics['avg_rmse']) / base_metrics['avg_rmse']) * 100\n",
        "    mape_change = ((final_metrics['avg_mape'] - base_metrics['avg_mape']) / base_metrics['avg_mape']) * 100\n",
        "    da_change = ((final_metrics['avg_da'] - base_metrics['avg_da']) / base_metrics['avg_da']) * 100\n",
        "    \n",
        "    print(\"\\\\n📈 ОБЩЕЕ УЛУЧШЕНИЕ (финальный этап vs базовая модель):\")\n",
        "    print(f\"   RMSE: {rmse_change:+.1f}% ({'✅ улучшение' if rmse_change < 0 else '❌ ухудшение'})\")\n",
        "    print(f\"   MAPE: {mape_change:+.1f}% ({'✅ улучшение' if mape_change < 0 else '❌ ухудшение'})\")\n",
        "    print(f\"   DA: {da_change:+.1f}% ({'✅ улучшение' if da_change > 0 else '❌ ухудшение'})\")\n",
        "    \n",
        "    # Рекомендации\n",
        "    print(\"\\\\n💡 РЕКОМЕНДАЦИИ:\")\n",
        "    \n",
        "    # Определяем наиболее эффективные этапы\n",
        "    rmse_improvements = []\n",
        "    mape_improvements = []\n",
        "    da_improvements = []\n",
        "    \n",
        "    for i in range(1, len(results_df)):\n",
        "        prev_metrics = results_df.iloc[i-1]\n",
        "        curr_metrics = results_df.iloc[i]\n",
        "        \n",
        "        rmse_change = ((curr_metrics['avg_rmse'] - prev_metrics['avg_rmse']) / prev_metrics['avg_rmse']) * 100\n",
        "        mape_change = ((curr_metrics['avg_mape'] - prev_metrics['avg_mape']) / prev_metrics['avg_mape']) * 100\n",
        "        da_change = ((curr_metrics['avg_da'] - prev_metrics['avg_da']) / prev_metrics['avg_da']) * 100\n",
        "        \n",
        "        rmse_improvements.append((curr_metrics['stage'], rmse_change))\n",
        "        mape_improvements.append((curr_metrics['stage'], mape_change))\n",
        "        da_improvements.append((curr_metrics['stage'], da_change))\n",
        "    \n",
        "    # Находим этапы с наибольшими улучшениями\n",
        "    best_rmse_improvement = min(rmse_improvements, key=lambda x: x[1])\n",
        "    best_mape_improvement = min(mape_improvements, key=lambda x: x[1])\n",
        "    best_da_improvement = max(da_improvements, key=lambda x: x[1])\n",
        "    \n",
        "    print(f\"   1. Наибольшее улучшение RMSE дал этап {best_rmse_improvement[0]} ({best_rmse_improvement[1]:+.1f}%)\")\n",
        "    print(f\"   2. Наибольшее улучшение MAPE дал этап {best_mape_improvement[0]} ({best_mape_improvement[1]:+.1f}%)\")\n",
        "    print(f\"   3. Наибольшее улучшение DA дал этап {best_da_improvement[0]} ({best_da_improvement[1]:+.1f}%)\")\n",
        "    \n",
        "    # Анализ эффективности по соотношению качества к сложности\n",
        "    print(\"\\\\n⚖️ АНАЛИЗ ЭФФЕКТИВНОСТИ (качество vs сложность):\")\n",
        "    for _, row in results_df.iterrows():\n",
        "        efficiency_score = (1 - row['avg_rmse']/base_metrics['avg_rmse']) / (row['avg_features']/base_metrics['avg_features'])\n",
        "        print(f\"   Этап {row['stage']}: Эффективность = {efficiency_score:.3f} (качество/сложность)\")\n",
        "\n",
        "print(\"\\\\n🎉 ПРОГРЕССИВНЫЙ АНАЛИЗ ЗАВЕРШЕН!\")\n",
        "print(f\"📁 Все результаты сохранены в папке: {OUTPUT_PATH}\")\n",
        "print(\"\\\\nФайлы результатов:\")\n",
        "print(\"   - progressive_analysis_summary.csv - сводка по этапам\")\n",
        "print(\"   - progressive_analysis_formatted.csv - форматированная таблица\")\n",
        "print(\"   - feature_importance_summary.csv - важность признаков\")\n",
        "print(\"   - metrics_progression.png - графики изменения метрик\")\n",
        "print(\"   - quality_heatmap.png - тепловая карта качества\")\n",
        "print(\"   - feature_importance_stage_N.png - важность признаков для последнего этапа\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
