{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8b39e1-ffa8-4496-897f-91212ab885e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install virtualenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069be2bf-cfb4-43e4-88f8-f34d6c849f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import virtualenv\n",
    "import subprocess\n",
    "import os\n",
    "import sys\n",
    "\n",
    "notebook_name = \"anomaly\"\n",
    "virtualenv.cli_run([\"venvs/\" + notebook_name, \"--no-download\"])\n",
    "\n",
    "venv_dir = \"venvs/\" + notebook_name\n",
    "python_path = os.path.join(venv_dir, \"bin\", \"python\")\n",
    "display_name = \"Python (\" + notebook_name + \")\"\n",
    "kernel_name = notebook_name\n",
    "\n",
    "# Установка ipykernel в venv\n",
    "subprocess.check_call([os.path.join(venv_dir, \"bin\", \"pip\"), \"install\", \"ipykernel\"])\n",
    "\n",
    "# Регистрация ядра\n",
    "subprocess.check_call([\n",
    "    python_path, \"-m\", \"ipykernel\", \"install\",\n",
    "    \"--user\",\n",
    "    \"--name\", kernel_name,\n",
    "    \"--display-name\", display_name\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a96ac45-167c-4b26-ad01-f66a14b7a558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/anomaly_detectors/venvs/anomaly/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed5f074-2684-4655-a405-5b59c4ea36a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Путь к pip в активном ядре\n",
    "pip_path = os.path.join(sys.prefix, \"bin\", \"pip\")\n",
    "\n",
    "subprocess.check_call([pip_path, \"install\", \"requests\", \"pyod\", \"matplotlib\", \"scikit-learn\", \"pandas\", \"numpy\", \"seaborn\", \"fedot\", \"fedot_ind\", \"giotto-tda\", \"ruptures\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2556e658-5210-4dfe-b574-79bc567fc265",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'VALID_LINEAR_DETECTION_PIPELINE' from 'fedot_ind.core.repository.constanst_repository' (/workspace/anomaly_detectors/venvs/anomaly/lib/python3.10/site-packages/fedot_ind/core/repository/constanst_repository.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyod\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlscp\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LSCP\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfedot_ind\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmain\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FedotIndustrial\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfedot_ind\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrepository\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstanst_repository\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VALID_LINEAR_DETECTION_PIPELINE\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtime\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'VALID_LINEAR_DETECTION_PIPELINE' from 'fedot_ind.core.repository.constanst_repository' (/workspace/anomaly_detectors/venvs/anomaly/lib/python3.10/site-packages/fedot_ind/core/repository/constanst_repository.py)"
     ]
    }
   ],
   "source": [
    "# Импорты\n",
    "from scipy import stats\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import typing\n",
    "from abc import abstractmethod, ABC\n",
    "import math\n",
    "from numpy import percentile\n",
    "import datetime as dt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from statsmodels.tsa.api import ExponentialSmoothing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from pyod.models.hbos import HBOS\n",
    "from pyod.models.abod import ABOD\n",
    "from pyod.models.lof import LOF\n",
    "from pyod.models.cblof import CBLOF\n",
    "from pyod.models.iforest import IForest\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.mcd import MCD\n",
    "from pyod.models.pca import PCA\n",
    "from pyod.models.lscp import LSCP\n",
    "from fedot_ind.api.main import FedotIndustrial\n",
    "from fedot_ind.core.repository.constanst_repository import VALID_LINEAR_DETECTION_PIPELINE\n",
    "\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "import numpy as np\n",
    "import statistics\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ffce97-39d4-44ec-bca7-22a362e4888d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path=\"../../data/series/\"):\n",
    "    \"\"\"Загрузка временных рядов из CSV файлов\"\"\"\n",
    "    data_dict = {}\n",
    "    data_path = Path(data_path)\n",
    "    \n",
    "    if not data_path.exists():\n",
    "        print(f\"Папка {data_path} не найдена!\")\n",
    "        return data_dict\n",
    "    \n",
    "    for csv_file in data_path.glob(\"*.csv\"):\n",
    "        try:\n",
    "            df = pd.read_csv(csv_file)\n",
    "            if 'timestamp' in df.columns and 'close' in df.columns:\n",
    "                df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "                df = df.set_index('timestamp').sort_index()\n",
    "                symbol = csv_file.stem\n",
    "                data_dict[symbol] = df[['close']]\n",
    "                print(f\"Загружен {symbol}: {len(df)} точек\")\n",
    "            else:\n",
    "                print(f\"Пропущен {csv_file.name}: нет колонок 'timestamp' или 'close'\")\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка загрузки {csv_file.name}: {e}\")\n",
    "    \n",
    "    return data_dict\n",
    "\n",
    "# Загрузка данных\n",
    "data = load_data()\n",
    "print(f\"\\nЗагружено временных рядов: {len(data)}\")\n",
    "\n",
    "if len(data) > 0:\n",
    "    # Выберем первый доступный ряд для демонстрации\n",
    "    symbol = list(data.keys())[0]\n",
    "    df = data[symbol]\n",
    "    print(f\"\\nИспользуем ряд: {symbol}\")\n",
    "    print(f\"Период: {df.index[0]} - {df.index[-1]}\")\n",
    "    print(f\"Количество точек: {len(df)}\")\n",
    "    \n",
    "    # Покажем статистику\n",
    "    print(\"\\nСтатистика ряда:\")\n",
    "    print(df['close'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4971ac-5773-4acf-94c6-a2552b7d5782",
   "metadata": {},
   "source": [
    "# Генерация аномалий"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d1fe52-1e51-4842-a49e-f8371cfa47fc",
   "metadata": {},
   "source": [
    "## BoxPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce99bfc-ce0d-4ce7-8101-366cdfa436b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = df['PHOR'].copy()\n",
    "dp.set_index('timestamp', inplace=True)\n",
    "dp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a662e4-20e1-4398-bc8d-74993b406300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Фильтрация по нужному интервалу\n",
    "start_date = '2023-11-01'\n",
    "end_date   = '2024-02-29'\n",
    "mask = (dp.index >= start_date) & (dp.index <= end_date)\n",
    "close_values = dp.loc[mask, 'close']\n",
    "\n",
    "# 3. Построение горизонтального боксплота\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.boxplot(close_values, vert=False)\n",
    "plt.title('Распределение цен закрытия (2023-11 – 2024-02)')\n",
    "plt.xlabel('Цена закрытия')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1798df1-f745-484f-b17e-51ff2edd1c2c",
   "metadata": {},
   "source": [
    "## Определение распределения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c845faa-c715-4f30-9ac2-b13104f5e9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Shapiro–Wilk\n",
    "stat_sw, p_sw = stats.shapiro(close_values)\n",
    "print(f\"Shapiro–Wilk: W={stat_sw:.4f}, p-value={p_sw:.4f}\")\n",
    "\n",
    "# 3. D’Agostino’s K²\n",
    "stat_k2, p_k2 = stats.normaltest(close_values)\n",
    "print(f\"D’Agostino’s K²: χ²={stat_k2:.4f}, p-value={p_k2:.4f}\")\n",
    "\n",
    "# 4. Anderson–Darling\n",
    "result_ad = stats.anderson(close_values, dist='norm')\n",
    "print(f\"Anderson–Darling: A²={result_ad.statistic:.4f}\")\n",
    "for sl, crit in zip(result_ad.significance_level, result_ad.critical_values):\n",
    "    print(f\"  {sl}% level: {crit:.4f}\")\n",
    "\n",
    "# 5. (Опционально) Lilliefors (в пакете statsmodels)\n",
    "from statsmodels.stats.diagnostic import lilliefors\n",
    "stat_l, p_l = lilliefors(close_values, dist='norm')\n",
    "print(f\"Lilliefors: D={stat_l:.4f}, p-value={p_l:.4f}\")\n",
    "\n",
    "alpha = 0.05  # уровень значимости\n",
    "ad_crit_5 = result_ad.critical_values[result_ad.significance_level.tolist().index(5.0)]\n",
    "if (p_sw > alpha and p_k2 > alpha and p_l > alpha and result_ad.statistic < ad_crit_5):\n",
    "    print(\"\\nИтог: нет оснований отвергать нормальность — распределение близко к нормальному.\")\n",
    "else:\n",
    "    print(\"\\nИтог: есть основания полагать, что распределение отличается от нормального.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833767eb-b906-446d-a771-7391983d23bc",
   "metadata": {},
   "source": [
    "## Генерация данных из распределеня"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d69717-03ed-4480-8083-05e7be5838d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "original = close_values.copy()\n",
    "\n",
    "# 2. Оценка параметров\n",
    "mu = original.mean()\n",
    "sigma = original.std(ddof=0)  # МЛ-оценка σ\n",
    "\n",
    "# 3. Генерация синтетических данных\n",
    "n = len(original)\n",
    "synthetic = np.random.normal(loc=mu, scale=sigma, size=n)\n",
    "\n",
    "# 4. Объединение в один «двойной» ряд\n",
    "combined = pd.Series(\n",
    "    np.concatenate([original.values, synthetic]),\n",
    "    index=pd.date_range(\n",
    "        start=original.index[0],\n",
    "        periods=2*n,\n",
    "        freq=original.index.freq or 'D'\n",
    "    ),\n",
    "    name='close'\n",
    ")\n",
    "\n",
    "# (Опционально) Визуализация\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(combined, label='Original + Synthetic')\n",
    "plt.axvline(combined.index[n], color='red', linestyle='--', label='Переход к синтетике')\n",
    "plt.legend()\n",
    "plt.title('Удвоенный ряд: реальные и сгенерированные значения')\n",
    "plt.xlabel('Дата')\n",
    "plt.ylabel('Цена закрытия')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6460d585-1b9b-4879-aa6d-dec7db427c41",
   "metadata": {},
   "source": [
    "## Генерацция данных из доходностей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80991de9-fe1b-4cc1-9e78-a691bf6be414",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = close_values.copy()\n",
    "\n",
    "# 2. Перевод в лог-доходности\n",
    "log_returns = np.log(prices).diff().dropna()\n",
    "\n",
    "# 3. Оценка параметров\n",
    "mu_r = log_returns.mean()\n",
    "sigma_r = log_returns.std(ddof=0)\n",
    "\n",
    "# 4. Генерация синтетических доходностей и реконструкция цен\n",
    "n = len(log_returns)\n",
    "simulated_r = np.random.normal(loc=mu_r, scale=sigma_r, size=n)\n",
    "P0 = prices.iloc[0]\n",
    "simulated_prices = P0 * np.exp(np.cumsum(simulated_r))\n",
    "\n",
    "# 5. Визуализация\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(prices.index, prices.values, label='Реальные цены')\n",
    "plt.plot(prices.index[1:], simulated_prices, label='Симуляция по лог-доходностям')\n",
    "plt.legend()\n",
    "plt.title('Сравнение реального пути и синтетического на базе лог-доходностей')\n",
    "plt.xlabel('Дата')\n",
    "plt.ylabel('Цена закрытия')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee9c7c9-5e78-46e6-829b-55efcb0c5e8c",
   "metadata": {},
   "source": [
    "## Генерация автоэнкодером"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675392a9-b25e-4cf3-a31b-7de4d3ee56da",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = close_values.copy()\n",
    "\n",
    "# 2. Нормировка в [0,1]\n",
    "scaler = MinMaxScaler()\n",
    "series_scaled = scaler.fit_transform(series.values.reshape(-1, 1))\n",
    "\n",
    "# 3. Формирование обучающих окон\n",
    "L = 20  # длина скользящего окна\n",
    "X = []\n",
    "for i in range(len(series_scaled) - L + 1):\n",
    "    X.append(series_scaled[i:i+L])\n",
    "X = np.array(X)  # форма (n_samples, L, 1)\n",
    "\n",
    "# 4. Определение архитектуры автоэнкодера\n",
    "input_seq = keras.Input(shape=(L, 1))\n",
    "\n",
    "# Кодировщик\n",
    "x = layers.Flatten()(input_seq)\n",
    "x = layers.Dense(16, activation='relu')(x)\n",
    "encoded = layers.Dense(8, activation='relu', name='bottleneck')(x)\n",
    "\n",
    "# Декодировщик\n",
    "x = layers.Dense(16, activation='relu')(encoded)\n",
    "x = layers.Dense(L, activation='sigmoid')(x)\n",
    "decoded = layers.Reshape((L, 1))(x)\n",
    "\n",
    "autoencoder = keras.Model(input_seq, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# 5. Обучение\n",
    "history = autoencoder.fit(\n",
    "    X, X,\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    validation_split=0.1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# 6. Восстановление всего ряда\n",
    "#   Подготовим все окна, пропустим через автоэнкодер и \"склеим\" обратно\n",
    "reconstructed = autoencoder.predict(X, verbose=0)\n",
    "# Для каждого шага i берем только последнюю точку из окна i\n",
    "rec_points = [reconstructed[i, -1, 0] for i in range(len(reconstructed))]\n",
    "# Переводим из скейлинга обратно в оригинальные значения\n",
    "rec_series = scaler.inverse_transform(np.array(rec_points).reshape(-1,1)).flatten()\n",
    "\n",
    "# Так как у нас n_points = len(series)-L+1, подставим соответствующий шаг\n",
    "time_index = series.index[L-1:L-1+len(rec_series)]\n",
    "\n",
    "# 7. Визуализация\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(series.index, series.values, label='Оригинал')\n",
    "plt.plot(time_index, rec_series, label='Восстановлено автоэнкодером')\n",
    "plt.title('Оригинальный ряд и его восстановление автоэнкодером')\n",
    "plt.xlabel('Дата')\n",
    "plt.ylabel('Цена закрытия')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b250c728-ccbe-4248-99a8-f4eabdc601fa",
   "metadata": {},
   "source": [
    "## Замешивание аномалий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73200ac-b4ad-408f-8ce1-6ea01fd4daa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inject_anomalies(\n",
    "    series: pd.Series,\n",
    "    n: int,\n",
    "    anomaly_timestamps: list[pd.Timestamp] = None,\n",
    "    anomaly_prices: list[float] = None,\n",
    "    sigma_multiplier: float = 3.0,\n",
    "    random_state: int = None\n",
    ") -> tuple[pd.Series, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Вставляет n аномалий в pandas.Series с datetime-индексом.\n",
    "\n",
    "    Параметры:\n",
    "    - series: Series с индексом типа datetime и значениями цен\n",
    "    - n:      число аномалий\n",
    "    - anomaly_timestamps: необязательный список из n меток времени для ручной вставки\n",
    "    - anomaly_prices:     необязательный список из n цен аномалий\n",
    "    - sigma_multiplier:   множитель локальной волатильности для автогенерации\n",
    "    - random_state:       seed для reproducibility\n",
    "\n",
    "    Возвращает:\n",
    "    - series_out: Series той же длины, с «вкрапленными» аномалиями\n",
    "    - injected_df: DataFrame с колонками\n",
    "        ['timestamp','original_price','anomaly_price']\n",
    "    \"\"\"\n",
    "    if not isinstance(series, pd.Series):\n",
    "        raise ValueError(\"Ожидается pandas.Series\")\n",
    "    if n <= 0:\n",
    "        raise ValueError(\"n должно быть положительным целым\")\n",
    "\n",
    "    # подготовка\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    series = series.sort_index().copy()\n",
    "\n",
    "    # определяем, где вставлять аномалии\n",
    "    if anomaly_timestamps is not None or anomaly_prices is not None:\n",
    "        # ручная вставка\n",
    "        if anomaly_timestamps is None or anomaly_prices is None:\n",
    "            raise ValueError(\"Нужны оба аргумента: anomaly_timestamps и anomaly_prices\")\n",
    "        if len(anomaly_timestamps) != n or len(anomaly_prices) != n:\n",
    "            raise ValueError(\"anomaly_timestamps и anomaly_prices длины n\")\n",
    "\n",
    "        # Ensure timestamps are timezone-naive if the series index is\n",
    "        idxs_raw = pd.to_datetime(anomaly_timestamps)\n",
    "        if series.index.tz is None and idxs_raw.tz is not None:\n",
    "             idxs = idxs_raw.tz_convert(None)\n",
    "        elif series.index.tz is not None and idxs_raw.tz is None:\n",
    "             raise TypeError(\"Series index is timezone-aware, but anomaly_timestamps are naive.\")\n",
    "        else:\n",
    "             idxs = idxs_raw # Both are naive or both are aware\n",
    "\n",
    "        # Convert to the exact type/frequency of the series index if necessary\n",
    "        # This step might be crucial for exact matches in the index\n",
    "        idxs = pd.DatetimeIndex(idxs, dtype=series.index.dtype, freq=series.index.freq)\n",
    "\n",
    "        for t in idxs:\n",
    "            if t not in series.index:\n",
    "                raise KeyError(f\"Серии не содержит метку {t}\")\n",
    "        anomaly_map = dict(zip(idxs, anomaly_prices))\n",
    "\n",
    "    else:\n",
    "        # автоматическая вставка\n",
    "        # Select from the index values and convert back to DatetimeIndex\n",
    "        # to ensure compatibility for .loc lookup\n",
    "        idxs = pd.DatetimeIndex(rng.choice(series.index.values, size=n, replace=False),\n",
    "                                dtype=series.index.dtype, freq=series.index.freq)\n",
    "\n",
    "        # оценка локальной волатильности через std разностей\n",
    "        sigma = series.diff().std(skipna=True)\n",
    "        noise = rng.normal(0, sigma * sigma_multiplier, size=n)\n",
    "        anomaly_map = {t: series.loc[t] + noise[i] for i, t in enumerate(idxs)}\n",
    "\n",
    "    # внесём аномалии и соберём информацию\n",
    "    injected = []\n",
    "    series_out = series.copy()\n",
    "    for t in idxs:\n",
    "        orig = series_out.loc[t]\n",
    "        anom = anomaly_map[t]\n",
    "        series_out.loc[t] = anom\n",
    "        injected.append({\n",
    "            \"timestamp\": t,\n",
    "            \"original_price\": orig,\n",
    "            \"anomaly_price\": anom\n",
    "        })\n",
    "\n",
    "    injected_df = pd.DataFrame(injected).set_index(\"timestamp\")\n",
    "    return series_out, injected_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e335d267-5b21-4117-9849-df9f6794a438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Берём реальный обрезанный ряд\n",
    "prices = close_values.copy()  # ваша Series из предыдущего шага\n",
    "\n",
    "# 2. Переводим в лог-доходности и генерим синтетику\n",
    "log_returns = np.log(prices).diff().dropna()\n",
    "mu_r = log_returns.mean()\n",
    "sigma_r = log_returns.std(ddof=0)\n",
    "simulated_r = np.random.default_rng(42).normal(loc=mu_r, scale=sigma_r, size=len(log_returns))\n",
    "P0 = prices.iloc[0]\n",
    "simulated_prices = pd.Series(\n",
    "    P0 * np.exp(np.cumsum(simulated_r)),\n",
    "    index=prices.index[1:]\n",
    ")\n",
    "\n",
    "# 3. Вставляем в синтетику n=5 аномалий автоматически\n",
    "augmented, anomalies = inject_anomalies(\n",
    "    series=simulated_prices,\n",
    "    n=5,\n",
    "    sigma_multiplier=4.0,\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "# 4. Визуализируем\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(simulated_prices.index, simulated_prices.values, label='Симуляция без аномалий')\n",
    "plt.plot(augmented.index, augmented.values, label='С аномалиями', alpha=0.8)\n",
    "plt.scatter(anomalies.index, anomalies['anomaly_price'],\n",
    "            color='red', label='Аномалии', zorder=5)\n",
    "plt.legend()\n",
    "plt.title('Смесь синтетического ряда и вкрапленных аномалий')\n",
    "plt.xlabel('Дата')\n",
    "plt.ylabel('Цена')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe424f7e-9112-4d03-9006-70a5bbcb6670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Выбираем вручную, в какие даты и на какие уровни вставить аномалии\n",
    "manual_ts = [\n",
    "    simulated_prices.index[4],  # 5th timestamp (index 4)\n",
    "    simulated_prices.index[9],  # 10th timestamp (index 9)\n",
    "    simulated_prices.index[14], # 15th timestamp (index 14)\n",
    "]\n",
    "\n",
    "# Пусть мы хотим, чтобы цена в эти даты прыгнула на +200, -150 и +300 пунктов соответственно\n",
    "manual_prices = [\n",
    "    simulated_prices.loc[manual_ts[0]] * 1.05, #\n",
    "    simulated_prices.loc[manual_ts[1]] * 0.95, #\n",
    "    simulated_prices.loc[manual_ts[2]] * 1.1, #\n",
    "]\n",
    "\n",
    "# 2. Вызываем функцию inject_anomalies с ручными параметрами\n",
    "augmented_manual, anomalies_manual = inject_anomalies(\n",
    "    series=simulated_prices,\n",
    "    n=3,\n",
    "    anomaly_timestamps=manual_ts,\n",
    "    anomaly_prices=manual_prices\n",
    ")\n",
    "\n",
    "# 3. Смотрим, что получилось\n",
    "print(\"Таблица вручную вставленных аномалий:\")\n",
    "print(anomalies_manual)\n",
    "\n",
    "# 4. Визуализируем оригинал и вручную заданные аномалии\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(simulated_prices.index, simulated_prices.values, label='Симуляция без аномалий')\n",
    "plt.plot(augmented_manual.index, augmented_manual.values, label='С ручными аномалиями', alpha=0.8)\n",
    "plt.scatter(\n",
    "    anomalies_manual.index,\n",
    "    anomalies_manual['anomaly_price'],\n",
    "    color='red',\n",
    "    s=50,\n",
    "    label='Ручные аномалии',\n",
    "    zorder=5\n",
    ")\n",
    "plt.legend()\n",
    "plt.title('Ручная вставка аномалий в синтетический ряд')\n",
    "plt.xlabel('Дата')\n",
    "plt.ylabel('Цена')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39d8aa8-0e88-4654-aefe-d2f41161a66b",
   "metadata": {},
   "source": [
    "## Статистические детекторы аномалий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d691e2bd-40e4-4653-94dd-80f7626a1c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = df['MOEX'].copy()\n",
    "dd['timestamp'] = pd.to_datetime(dd['timestamp'])\n",
    "dd.set_index('timestamp', inplace=True)\n",
    "dd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d1525c-25ae-404e-a99a-a5d603a1cc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_fraction = 0.2\n",
    "column = 'close'\n",
    "c = 'close'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00e1fa4-192c-44e6-adb9-a6e99263edb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbstractAnomalyDetector(ABC):\n",
    "    @abstractmethod\n",
    "    def __init__(self, data: pd.Series, interval=None):\n",
    "        \"\"\"\n",
    "        Detect anomalies and get label for each anomaly\n",
    "        :param data: datetime indexed pd.Series\n",
    "        :param interval: pair of dates to search for anomalies between\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        if interval:\n",
    "            self.start, self.end = interval\n",
    "            if not self.start:\n",
    "                self.start = 0\n",
    "            if not self.end:\n",
    "                self.end = self.data.shape[0]\n",
    "        else:\n",
    "            self.start, self.end = 0, self.data.shape[0]\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_labels(self) -> pd.Series:\n",
    "        pass\n",
    "\n",
    "\n",
    "class OutlierDetector(AbstractAnomalyDetector):\n",
    "    \"\"\"\n",
    "    Detects anomalies using distribution of data\n",
    "    Detects:\n",
    "            Outliers - such points where values are not in 3-sigma range of distribution\n",
    "                (in other words values are too big or too low than the rest of the data);\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data: pd.Series, interval=None):\n",
    "        super().__init__(data, interval)\n",
    "\n",
    "    def get_labels(self):\n",
    "        result = self._search_for_anomalies()\n",
    "        result = result[~np.isnan(result)]\n",
    "        result = pd.DataFrame(index=result.index, data={'label': result.values})['label']\n",
    "        if self.start and self.end:\n",
    "            result = result[self.start:self.end]\n",
    "        return result\n",
    "\n",
    "    def _search_for_anomalies(self):\n",
    "        sigma_min, sigma_max = self.__get_stat()\n",
    "        return self.data.apply(lambda r: 1 if r > sigma_max else -1 if r < sigma_min else np.nan)\n",
    "\n",
    "    def __get_stat(self):\n",
    "        mean_val = self.data.mean()\n",
    "        std_val = self.data.std()\n",
    "        sigma_min = mean_val - 3 * std_val\n",
    "        sigma_max = mean_val + 3 * std_val\n",
    "        return sigma_min, sigma_max\n",
    "\n",
    "\n",
    "class AbstractDistributionBasedAnomalyDetector(AbstractAnomalyDetector):\n",
    "\n",
    "    def __init__(self, data, interval: typing.Tuple[str, str] = None, prev_only: bool = False):\n",
    "        super().__init__(data, interval)\n",
    "        self.prev_only = prev_only\n",
    "\n",
    "    def get_labels(self) -> pd.Series:\n",
    "        result = self._search_for_anomalies()\n",
    "        result = pd.DataFrame(index=self.data.index, data={'label': result})['label']\n",
    "        result = result[~np.isnan(result)]\n",
    "        return result\n",
    "\n",
    "    @abstractmethod\n",
    "    def _search_for_anomalies(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class RareDistributionDetector(AbstractDistributionBasedAnomalyDetector):\n",
    "    \"\"\"\n",
    "    Detects anomalies using distribution of data\n",
    "    Detects:\n",
    "            Rare distributions zones -\n",
    "                such zones where set of values consecutively falls out of range of n*sigma distributions;\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, interval: typing.Tuple[str, str] = None, prev_only: bool = False, n=1, window=50):\n",
    "        super().__init__(data, interval, prev_only)\n",
    "        self.window = window\n",
    "        if window > self.end - self.start:\n",
    "            raise ValueError('Window is bigger than interval')\n",
    "        if not 0 < n < 4:\n",
    "            raise ValueError('n must be in (0,4)')\n",
    "        self.n = n\n",
    "\n",
    "    def _search_for_anomalies(self):\n",
    "        length, = self.data.shape\n",
    "        self.__get_stats(length)\n",
    "        result = np.array([np.nan] * length)\n",
    "\n",
    "        for i in range(self.window if self.prev_only else self.start, self.end - self.window + 1):\n",
    "            is_anomaly = True\n",
    "            if self.prev_only:\n",
    "                self.__get_stats(i)\n",
    "            for w in range(i, i + self.window):\n",
    "                if is_anomaly:\n",
    "                    diff = abs(self.data[w] - self.mean)\n",
    "                    is_anomaly = self.sigma_min < diff < self.sigma_max\n",
    "            if is_anomaly:\n",
    "                result[i:i + self.window] = 1\n",
    "        return result\n",
    "\n",
    "    def __get_stats(self, i):\n",
    "        self.mean = self.data[:i].mean()\n",
    "        self.std = self.data[:i].std()\n",
    "        self.sigma_min = (self.n - 1) * self.std\n",
    "        self.sigma_max = self.sigma_min + self.std\n",
    "\n",
    "\n",
    "class MeanAnomalyDetector(AbstractDistributionBasedAnomalyDetector):\n",
    "    \"\"\"\n",
    "    Detects anomalies using distribution of data\n",
    "    Detects:\n",
    "            out-of-mean anomalies - such zones where values are bigger or lower than mean of given data;\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, interval: typing.Tuple[str, str] = None, prev_only: bool = False, lower=True, window=50):\n",
    "        super().__init__(data, interval, prev_only)\n",
    "        self.window = window\n",
    "        self.lower = lower\n",
    "        if window > self.end - self.start:\n",
    "            raise ValueError('Window is bigger than interval')\n",
    "\n",
    "    def _search_for_anomalies(self):\n",
    "        length, = self.data.shape\n",
    "        self.__get_stats(length)\n",
    "        result = np.array([np.nan] * length)\n",
    "\n",
    "        for i in range(self.window if self.prev_only else self.start, self.end - self.window + 1):\n",
    "            is_anomaly = True\n",
    "            if self.prev_only:\n",
    "                self.__get_stats(i)\n",
    "            for w in range(i, i + self.window):\n",
    "                if is_anomaly:\n",
    "                    is_anomaly = self.data[w] < self.mean if self.lower \\\n",
    "                        else self.data[w] > self.mean\n",
    "            if is_anomaly:\n",
    "                result[i:i + self.window] = 1\n",
    "        return result\n",
    "\n",
    "    def __get_stats(self, i):\n",
    "        self.mean = self.data[:i].mean()\n",
    "\n",
    "\n",
    "class DistributionBasedAnomalyDetector(AbstractDistributionBasedAnomalyDetector):\n",
    "    \"\"\"\n",
    "        Detects anomalies using distribution of data\n",
    "        Detects:\n",
    "                distributions-change zones -\n",
    "                    such zones where normal distribution of given data changes;\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, interval: typing.Tuple[str, str] = None, prev_only: bool = False, threshold=0.3,\n",
    "                 window=50):\n",
    "        super().__init__(data, interval, prev_only)\n",
    "        self.window = window\n",
    "        if window > self.end - self.start:\n",
    "            raise ValueError('Window is bigger than interval')\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def _search_for_anomalies(self):\n",
    "        length, = self.data.shape\n",
    "        result = np.array([np.nan] * length)\n",
    "        std_val = self.data.std()\n",
    "        mean_val = self.data.mean()\n",
    "\n",
    "        for i in range(self.window if self.prev_only else self.start, self.end - self.window + 1):\n",
    "            data_slice = self.data[i:i + self.window]\n",
    "            sl_mean = data_slice.mean()\n",
    "            sl_std = data_slice.std()\n",
    "            if self.prev_only:\n",
    "                prev_slice = self.data[:i]\n",
    "                mean_val = prev_slice.mean()\n",
    "                std_val = prev_slice.std()\n",
    "            is_anomaly = (sl_std > (1 + self.threshold) * std_val or sl_std < (1 - self.threshold) * std_val) \\\n",
    "                         and (sl_mean > (1 + self.threshold) * mean_val or sl_mean < (1 - self.threshold) * mean_val)\n",
    "            if is_anomaly:\n",
    "                result[i:i + self.window] = 1\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ea3dcc-3208-4a27-84ed-08494580b916",
   "metadata": {},
   "outputs": [],
   "source": [
    "detectors = {\n",
    "    'outlier_detector': OutlierDetector(dd[column]),\n",
    "    'great_of_mean_detector': MeanAnomalyDetector(dd[column], lower=False, window=14),\n",
    "    'least_of_mean_detector': MeanAnomalyDetector(dd[column], lower=True, window=14),\n",
    "    'distribution_based_detector': DistributionBasedAnomalyDetector(dd[column]),\n",
    "    'rare_1_distribution_detector': RareDistributionDetector(dd[column], n=1, window=25),\n",
    "    'rare_2_distribution_detector': RareDistributionDetector(dd[column], n=2, window=7),\n",
    "    'rare_3_distribution_detector': RareDistributionDetector(dd[column], n=3, window=3)\n",
    "}\n",
    "\n",
    "for detector_name, detector in detectors.items():\n",
    "  result = detector.get_labels()\n",
    "\n",
    "  if result.shape[0] > 0 :\n",
    "      res = pd.DataFrame(result)\n",
    "      dd[detector_name] = res['label']\n",
    "\n",
    "      a = dd.loc[~dd[detector_name].isna(), [column]]\n",
    "      fig, ax = plt.subplots(figsize=(16,9))\n",
    "\n",
    "      ax.plot(dd[column])\n",
    "      ax.scatter(a.index, a, c='red')\n",
    "\n",
    "      plt.title(detector_name)\n",
    "      plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a17a73-e973-4054-b5fd-27c8eae7beee",
   "metadata": {},
   "source": [
    "## Прогнозный подход"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b3fb83-3faf-48fb-82a9-2d1e3a3cdb23",
   "metadata": {},
   "source": [
    "### EMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611dd663-f65f-403e-9d46-62ee31876a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_fraction = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59fc4a0-3f5d-407d-a37a-4da585753d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = dd[-50:]\n",
    "df_train = dd[:-50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a33f8d-f869-4617-b039-1353f07b51f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_train[c]\n",
    "data.index = pd.DatetimeIndex(data.index.values)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe4281b-7ab5-49a7-970b-70dade9cc904",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = ExponentialSmoothing(data, seasonal_periods=5, trend='add', seasonal='add').fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c15928-f640-4b8f-8260-8f09a053f355",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = fit.forecast(50).to_frame().reset_index()\n",
    "forecast.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425e3402-40ba-4f58-bc92-4fcf0970d971",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_index_for_forecast = df_test.index\n",
    "forecast.index = datetime_index_for_forecast\n",
    "forecast = forecast.rename(columns={0: 'forecast'})\n",
    "forecast = forecast.drop(columns=['index'])\n",
    "print(forecast.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fada450c-07b5-4889-a4bd-d249209b05ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax =plt.subplots()\n",
    "forecast.plot(ax=ax)\n",
    "df_test['close'].plot(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51defbbf-bc34-4d36-943f-30575691669c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = forecast.copy()\n",
    "df_res['fact'] = df_test[c]\n",
    "df_res['MAPE'] = abs(df_res.fact - df_res.forecast) / df_res.fact\n",
    "df_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bebb36-9dce-46c9-bb57-f31ec9de89f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = percentile(df_res.MAPE, 90)\n",
    "df_res['anomaly'] = df_res.MAPE > threshold\n",
    "df_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42322685-cc0e-4c76-be1e-7f8abc5e34a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "a = df_res.loc[df_res.anomaly, ['fact']]\n",
    "\n",
    "ax.plot(df_res.index, df_res.fact)\n",
    "ax.scatter(a.index, a.fact, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e572130-bcb9-495a-a9b4-91d55807eb06",
   "metadata": {},
   "source": [
    "## Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485340b1-d529-4273-acf9-f44ffd42a139",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "np_scaled = scaler.fit_transform(dd['close'].values.reshape(-1,1))\n",
    "data = pd.DataFrame(np_scaled)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456af7b1-3115-4d3f-9868-51a08332c971",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd['anomaly'] = model.predict(data)\n",
    "dd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e3c0f4-fc6f-46ab-9671-f44d857223de",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "a = dd.loc[dd.anomaly == -1, [c]]\n",
    "\n",
    "ax.plot(dd.index, dd[c])\n",
    "ax.scatter(a.index, a[c], color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d04ba6e-cb4b-4e1a-a00a-7b6508aa6336",
   "metadata": {},
   "source": [
    "## Кластеризация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e8d8e9-87c1-49ca-aeb2-e8c271a344ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = df['MOEX']\n",
    "dd = dd.set_index('timestamp')\n",
    "dd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30d5672-4c28-49c4-8c94-e928794e8033",
   "metadata": {},
   "source": [
    "### K-means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48166ac4-56bc-4d94-8bfa-3ad44961856f",
   "metadata": {},
   "source": [
    "#### Elbow Cirve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664a269f-4c20-48a8-9d0a-a160a67d2fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cls = range(1, 20)\n",
    "\n",
    "kmeans = [KMeans(n_clusters=i).fit(dd) for i in n_cls]\n",
    "scores = [kmeans[i].score(dd) for i in range(len(kmeans))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df2935f-c325-4568-92cb-a33a344826f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,9))\n",
    "ax.plot(n_cls, scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c940af-1aa1-4aec-b6b9-ad3f7c34f242",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d402a376-e5d3-4d71-b7bc-5f487c98e782",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dd.values\n",
    "X_std = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688da335-d2ed-4da9-820c-893d548f4c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vec = np.mean(X_std, axis=0)\n",
    "cov_mat = np.cov(X_std.T)\n",
    "eig_vals, eig_vecs = np.linalg.eig(cov_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1a942b-89b0-45a1-a231-1ffb2350adac",
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:, i]) for i in range(len(eig_vals))]\n",
    "eig_pairs.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "tot = sum(eig_vals)\n",
    "var_exp = [(i/tot)*100 for i in sorted(eig_vals, reverse=True)]\n",
    "cum_var_exp = np.cumsum(var_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42be015-ee90-4cff-9efa-2653dd711432",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,9))\n",
    "plt.bar(range(len(var_exp)), var_exp)\n",
    "plt.step(range(len(var_exp)), cum_var_exp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0859bc-f62d-49f4-b172-c25c48d5ff9a",
   "metadata": {},
   "source": [
    "#### K-MEANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162514f8-ddda-46ac-9848-59cab9af0eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDistanceByPoint(data, model):\n",
    "    distance = pd.Series()\n",
    "    for i in range(0,len(data)):\n",
    "        Xa = np.array(data.loc[i])\n",
    "        Xb = model.cluster_centers_[model.labels_[i]-1]\n",
    "        distance.at[i]=np.linalg.norm(Xa-Xb)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a273d14a-b4ce-45f5-a458-61342782b2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(X_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cf982b-9557-4aba-be51-fb340c1df723",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "data = pca.fit_transform(data)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "np_scaled = scaler.fit_transform(data)\n",
    "data = pd.DataFrame(np_scaled)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22115cee-d493-4ff6-9ce6-f5470559ae41",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_model = KMeans(n_clusters=7).fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5af41a-53bc-4941-8c4a-3a8d57ba4bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.reset_index(inplace=True)\n",
    "dd['cluster'] = kmeans_model.predict(data)\n",
    "dd.index = data.index\n",
    "dd['pca1'] = data[0]\n",
    "dd['pca2'] = data[1]\n",
    "\n",
    "dist = getDistanceByPoint(data, kmeans_model)\n",
    "n_outliers = int(0.05*len(dist))\n",
    "threshold = percentile(dist, 95)\n",
    "dd['anomaly_cls'] = (dist >= threshold).astype(int)\n",
    "dd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb2e010-3b03-4928-9361-b76dc42356d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "\n",
    "a = dd.loc[dd.anomaly_cls == 1, [c, 'timestamp']]\n",
    "\n",
    "ax.plot(dd.timestamp, dd[c])\n",
    "ax.scatter(a.timestamp, a[c], color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6122b613-017d-4629-b632-28eecfc8ec20",
   "metadata": {},
   "source": [
    "### K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99520e1e-657d-4d0e-b567-88fd8e951e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = NearestNeighbors(n_neighbors=3)\n",
    "knn.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fd7043-9b34-4e65-ab68-da06ead9ee5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist, idxs = knn.kneighbors(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7aab76-8da3-447d-9cbb-8d4a59b0b4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd['dist'] = dist.mean(axis=1)\n",
    "threshold = percentile(dd.dist, 95)\n",
    "\n",
    "dd['anomaly_knn'] = dd.dist > threshold\n",
    "dd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3ccbfe-85ea-442e-aa84-d14b64989256",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = dd.loc[dd['anomaly_knn'], [c, 'timestamp']]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "\n",
    "ax.plot(dd.timestamp, dd[c])\n",
    "ax.scatter(a.timestamp, a[c], color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ba56e9-b7c4-44dc-acfa-72cd6d196882",
   "metadata": {},
   "source": [
    "## Многомерные аномалии (PyOD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcd57bd-011a-481b-9767-bd722edcf84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_plots(df, columns, anomaly_column=None):\n",
    "    fig, axs = plt.subplots(len(columns), 1, sharex=True, constrained_layout=True, figsize=(12,10))\n",
    "    for i in range(len(columns)):\n",
    "        c = columns[i]\n",
    "\n",
    "        axs[i].plot(dd.index, df[c], color='gray',label='Normal')\n",
    "\n",
    "        if anomaly_column:\n",
    "            a = df.loc[df[anomaly_column] == 1, [c]] #anomaly\n",
    "            axs[i].scatter(a.index, a[c], color='red', label='Anomaly')\n",
    "\n",
    "        axs[i].xaxis_date()\n",
    "        axs[i].set_title(c)\n",
    "        plt.xlabel('Date')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2395bbd3-b366-40bf-ba67-0a80ccb04f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = df['MOEX']\n",
    "dd = dd.set_index('timestamp')\n",
    "dd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3160702-b6f7-4733-8f9f-e21c5d385107",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['open', 'close', 'high', 'low', 'volume']\n",
    "show_plots(dd, columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c485f43-c750-47d8-9ee1-f9219564e451",
   "metadata": {},
   "source": [
    "### HBOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ebc9bb-17e1-4cdd-bdb2-718d8e22da3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_fraction = 0.05\n",
    "random_state = np.random.RandomState(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0daaad-0dc0-4812-b813-cd5f52ac7493",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = HBOS(contamination=outliers_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cf6224-e100-4403-a910-c6d1603dcc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dd.values\n",
    "\n",
    "detector.fit(X)\n",
    "\n",
    "pred = detector.predict(X)\n",
    "\n",
    "dd['anomaly'] = pred\n",
    "show_plots(dd, columns, 'anomaly')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a5fb22-da5a-43e8-8fe8-a7d80cd6c559",
   "metadata": {},
   "source": [
    "### ABOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9082224b-d10c-4143-9a9c-2e2c8f5c2ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_fraction = 0.05\n",
    "random_state = np.random.RandomState(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2228b2-0bfe-4965-af7b-8049c701b8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = ABOD(contamination=outliers_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dcffd7-c460-4857-95c7-2c4e9c66198c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dd.values\n",
    "\n",
    "detector.fit(X)\n",
    "\n",
    "pred = detector.predict(X)\n",
    "dd['anomaly'] = pred\n",
    "\n",
    "show_plots(dd, columns, 'anomaly')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1567fb2-a022-49e6-a58d-4a06218ef1b1",
   "metadata": {},
   "source": [
    "### LOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ca21a7-8679-42be-9dab-d1100432ff50",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = df['MOEX']\n",
    "dd = dd.set_index('timestamp')\n",
    "dd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe663c4b-6109-415d-9287-9df10cc0266d",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_fraction = 0.05\n",
    "random_state = np.random.RandomState(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d93cfe-ad38-4e0a-ab74-1b38aa6ab421",
   "metadata": {},
   "outputs": [],
   "source": [
    "lof_detector = LOF(n_neighbors=20, contamination=outliers_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296d0446-8eba-4775-92fc-4712cbd43289",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dd.values\n",
    "\n",
    "lof_detector.fit(X)\n",
    "\n",
    "pred = lof_detector.predict(X)\n",
    "\n",
    "dd['anomaly'] = pred\n",
    "\n",
    "show_plots(dd, columns, 'anomaly')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ba057e-6409-4626-9a70-13efad5ecb91",
   "metadata": {},
   "source": [
    "### CBLOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fd6a0b-4e8b-43a8-9216-754c9a861f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "cblof_detector = CBLOF(contamination=outliers_fraction, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eac6f09-e099-497e-8235-3fe23605db04",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dd.values\n",
    "\n",
    "cblof_detector.fit(X)\n",
    "\n",
    "pred = cblof_detector.predict(X)\n",
    "\n",
    "dd['anomaly'] = pred\n",
    "\n",
    "show_plots(dd, columns, 'anomaly')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773ca19b-5327-4c55-8f63-f790ac96a411",
   "metadata": {},
   "source": [
    "### Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7ed8f0-985e-4aa4-be91-f4f2b65aba90",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = df['MOEX']\n",
    "dd = dd.set_index('timestamp')\n",
    "dd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40228852-fe17-4b20-9334-af5e867ea8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_fraction = 0.05\n",
    "random_state = np.random.RandomState(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278c7056-8c13-4e88-919f-78618f9d3959",
   "metadata": {},
   "outputs": [],
   "source": [
    "if_detector = IForest(contamination=outliers_fraction, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7929abda-42be-43c3-90d7-6e2a5262cd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dd.values\n",
    "\n",
    "if_detector.fit(X)\n",
    "pred = if_detector.predict(X)\n",
    "dd['anomaly'] = pred\n",
    "\n",
    "show_plots(dd, columns, 'anomaly')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11fb6ed-6d33-472b-b66a-989788fe3d91",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f03182-5b01-4929-9af9-fa90fe0abcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_detector = KNN(contamination=outliers_fraction, method='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e058900-1941-4d75-b6b4-5ff3f551de86",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dd.values\n",
    "\n",
    "knn_detector.fit(X)\n",
    "pred = knn_detector.predict(X)\n",
    "dd['anomaly'] = pred\n",
    "\n",
    "show_plots(dd, columns, 'anomaly')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cc0e67-f184-4cdc-a095-d876f2e05904",
   "metadata": {},
   "source": [
    "### MCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90eac386-1545-44db-9fa6-cfec368f7d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcd_detector = MCD(contamination=outliers_fraction, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655a05fb-0a8b-4b6a-a4f9-8f8aa66d2dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dd.values\n",
    "\n",
    "mcd_detector.fit(X)\n",
    "\n",
    "pred = mcd_detector.predict(X)\n",
    "\n",
    "dd['anomaly'] = pred\n",
    "\n",
    "show_plots(dd, columns, 'anomaly')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74393f1-68b5-4a88-afcc-372ed7389461",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d541584-2980-48f7-8b30-35903708b82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_detector = PCA(contamination=outliers_fraction, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121c5624-05dc-4bdb-aa26-a311dfbd4fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dd.values\n",
    "pca_detector.fit(X)\n",
    "\n",
    "pred = pca_detector.predict(X)\n",
    "\n",
    "dd['anomaly'] = pred\n",
    "\n",
    "show_plots(dd, columns, 'anomaly')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af427fc4-6fdc-45e5-93d6-8fac573f3cb4",
   "metadata": {},
   "source": [
    "### LSCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49184104-083a-41cc-aa49-ded5fbbe13b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_fraction = 0.05\n",
    "random_state = np.random.RandomState(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9060de-e6aa-4016-a3e9-21622466de7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector_list = [\n",
    "    PCA(contamination=outliers_fraction, random_state=random_state),\n",
    "    HBOS(contamination=outliers_fraction),\n",
    "    LOF(contamination=outliers_fraction),\n",
    "    ABOD(contamination=outliers_fraction),\n",
    "    IForest(contamination=outliers_fraction, random_state=random_state)\n",
    "]\n",
    "\n",
    "lscp_detector = LSCP(detector_list, contamination=outliers_fraction, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed82292-964e-4f88-a48c-f92a1a73ee8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dd.values\n",
    "lscp_detector.fit(X)\n",
    "\n",
    "pred = lscp_detector.predict(X)\n",
    "\n",
    "dd['anomaly'] = pred\n",
    "\n",
    "show_plots(dd, columns, 'anomaly')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925a85b5-c059-4a73-85d1-1fba423a249f",
   "metadata": {},
   "source": [
    "## FEDOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100f5f16-0c40-4ca4-8d6e-1350f8c365a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Подготовка ряда\n",
    "series = df['MOEX'].set_index('timestamp')['close']\n",
    "# Разобьём на train/test (80%/20%), чтобы не «подглядывать» в будущие точки\n",
    "split_idx = int(len(series) * 0.8)\n",
    "train_series = series.iloc[:split_idx]\n",
    "test_series  = series.iloc[split_idx:]\n",
    "\n",
    "# Упакуем в формат, который ждёт FedotIndustrial:\n",
    "#   для anomaly_detection y не обязателен, поэтому передаём лишь X\n",
    "train_data = (train_series.values.reshape(-1, 1), None)\n",
    "test_data  = (test_series.values.reshape(-1, 1), None)\n",
    "\n",
    "# 2. Список встроенных линейных детекторов\n",
    "pipeline_labels = [\n",
    "    'stat_detector',\n",
    "    'arima_detector',\n",
    "    'iforest_detector',\n",
    "    'conv_ae_detector',\n",
    "    'lstm_ae_detector'\n",
    "]\n",
    "\n",
    "# 3. Для каждого детектора: обучаем, предсказываем и рисуем\n",
    "fig, axes = plt.subplots(len(pipeline_labels), 1, figsize=(12, 4 * len(pipeline_labels)), sharex=True)\n",
    "\n",
    "for ax, label in zip(axes, pipeline_labels):\n",
    "    # 3.1 Инициализируем AutoML-сервис на конкретном детекторе\n",
    "    ad = FedotIndustrial(\n",
    "        problem='classification',\n",
    "        industrial_strategy='anomaly_detection',\n",
    "        industrial_task_params={\n",
    "            'detection_window': 10,\n",
    "            'detection_pipeline': label  # указываем нужный детектор\n",
    "        },\n",
    "        timeout=2,    # минут\n",
    "        n_jobs=1,\n",
    "        logging_level=30\n",
    "    )\n",
    "\n",
    "    # 3.2 Обучаем на train_series\n",
    "    ad.fit(train_data)\n",
    "    # 3.3 Предсказываем на test_series\n",
    "    labels = ad.predict(test_data).ravel()  # 0/1\n",
    "\n",
    "    # 3.4 Находим timestamps аномалий\n",
    "    anomaly_idx = test_series.index[labels == 1]\n",
    "    anomaly_vals = test_series.loc[anomaly_idx]\n",
    "\n",
    "    # 3.5 Рисуем\n",
    "    ax.plot(test_series.index, test_series.values, label='test series')\n",
    "    ax.scatter(anomaly_idx, anomaly_vals, color='red', s=40, label='anomaly')\n",
    "    ax.set_title(f\"{label} (n_anomalies={len(anomaly_idx)})\")\n",
    "    ax.set_ylabel(\"Цена\")\n",
    "    ax.legend()\n",
    "\n",
    "axes[-1].set_xlabel(\"Дата\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a143a092-6a68-4d58-87ad-968205926155",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedot_ind.api.main import FedotIndustrial\n",
    "\n",
    "# 1. Подготовка multivariate-рядов\n",
    "#    Используем все числовые колонки MOEX\n",
    "df_moex = df['MOEX'].copy().set_index('timestamp')\n",
    "features = ['open','high','low','close','volume']\n",
    "X = df_moex[features].values\n",
    "times = df_moex.index\n",
    "\n",
    "# 2. Train/Test split (80%/20%)\n",
    "split = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "times_test = times[split:]\n",
    "\n",
    "train_data = (X_train, None)\n",
    "test_data  = (X_test, None)\n",
    "\n",
    "# 3. Список линейных детекторов\n",
    "pipeline_labels = [\n",
    "    'stat_detector',\n",
    "    'arima_detector',\n",
    "    'iforest_detector',\n",
    "    'conv_ae_detector',\n",
    "    'lstm_ae_detector'\n",
    "]\n",
    "\n",
    "# 4. Прогоняем каждый детектор и сохраняем метки\n",
    "anomalies_idx = {}\n",
    "\n",
    "for label in pipeline_labels:\n",
    "    ad = FedotIndustrial(\n",
    "        problem='classification',\n",
    "        industrial_strategy='anomaly_detection',\n",
    "        industrial_task_params={\n",
    "            'detection_window': 10,\n",
    "            'detection_pipeline': label\n",
    "        },\n",
    "        timeout=2,    # минуты\n",
    "        n_jobs=1,\n",
    "        logging_level=30\n",
    "    )\n",
    "    ad.fit(train_data)\n",
    "    labels = ad.predict(test_data).ravel().astype(bool)  # True = аномалия\n",
    "    anomalies_idx[label] = times_test[labels]\n",
    "\n",
    "# 5. Визуализация: пять графиков для close\n",
    "fig, axes = plt.subplots(len(pipeline_labels), 1,\n",
    "                         figsize=(12, 3 * len(pipeline_labels)),\n",
    "                         sharex=True)\n",
    "\n",
    "for ax, label in zip(axes, pipeline_labels):\n",
    "    ax.plot(times_test, X_test[:, features.index('close')],\n",
    "            label='close')\n",
    "    ax.scatter(anomalies_idx[label],\n",
    "               df_moex.loc[anomalies_idx[label], 'close'],\n",
    "               color='red', s=40, label='anomaly', zorder=5)\n",
    "    ax.set_title(f\"{label} — найдено {len(anomalies_idx[label])} аномалий\")\n",
    "    ax.set_ylabel(\"Цена закрытия\")\n",
    "    ax.legend()\n",
    "\n",
    "axes[-1].set_xlabel(\"Дата\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760931a5-b9b6-48a2-bf54-36d432d4fac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO OPENROUTER\n",
    "\n",
    "# Ваш токен доступа к LLM-прокси\n",
    "bearer_token = os.environ.get(\"BEARER_TOKEN\") or \"\"\n",
    "API_SEND   = \"https://api.gen-api.ru/api/v1/networks/gpt-4o-mini\"\n",
    "API_STATUS = \"https://api.gen-api.ru/api/v1/request/get/{}\"\n",
    "\n",
    "HEADERS = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Accept': 'application/json',\n",
    "    'Authorization': f'Bearer {bearer_token}'\n",
    "}\n",
    "\n",
    "def extract_indices(result_data):\n",
    "    \"\"\"\n",
    "    Извлекает список индексов из ответа LLM, убирая любые\n",
    "    ```code fences``` и лишние символы.\n",
    "    \"\"\"\n",
    "    # 1) Приводим к строке\n",
    "    text = result_data if isinstance(result_data, str) else str(result_data)\n",
    "\n",
    "    # 2) Убираем все «```json» или «```» в начале и в конце\n",
    "    #    - убираем ```json\\n или ```\\n\n",
    "    text = re.sub(r\"^```(?:json)?\\s*\\n?\", \"\", text)\n",
    "    #    - убираем заключительные ```\n",
    "    text = re.sub(r\"\\n?```$\", \"\", text)\n",
    "\n",
    "    # 3) Находим первый JSON-массив вида [..]\n",
    "    match = re.search(r\"\\[.*?\\]\", text, flags=re.DOTALL)\n",
    "    if not match:\n",
    "        return []\n",
    "\n",
    "    arr_text = match.group(0)\n",
    "    try:\n",
    "        return json.loads(arr_text)\n",
    "    except json.JSONDecodeError:\n",
    "        # пытаемся почистить пробелы и кавычки\n",
    "        arr_text = re.sub(r\"[\\\"']\", \"\", arr_text)\n",
    "        nums = re.findall(r\"\\d+\", arr_text)\n",
    "        return [int(x) for x in nums]\n",
    "\n",
    "def compute_patch_stats(patch):\n",
    "    ex = float(np.mean(patch))\n",
    "    dx = float(np.std(patch))\n",
    "    try:\n",
    "        mode_val = float(statistics.mode([round(x,2) for x in patch]))\n",
    "    except statistics.StatisticsError:\n",
    "        mode_val = None\n",
    "    pct = (patch[-1] - patch[0]) / patch[0] * 100\n",
    "    return ex, dx, mode_val, pct\n",
    "\n",
    "def make_patch_messages(window, patch_size=5):\n",
    "    msgs = []\n",
    "    n_patches = len(window) // patch_size\n",
    "    for i in range(n_patches):\n",
    "        p = window[i*patch_size:(i+1)*patch_size]\n",
    "        ex, dx, mode_val, pct = compute_patch_stats(p)\n",
    "        nums = \", \".join(f\"{x:.2f}\" for x in p)\n",
    "        hint = (\n",
    "            f\"min: {min(p):.2f}, max: {max(p):.2f}, \"\n",
    "            f\"mean: {ex:.2f}, std: {dx:.2f}, change%: {pct:+.2f}%\"\n",
    "        )\n",
    "        content = (\n",
    "            f\"Patch {i+1} (indices {i*patch_size}-{(i+1)*patch_size-1}): \"\n",
    "            f\"[{nums}]\\nHint — {hint}\"\n",
    "        )\n",
    "        msgs.append({\"role\": \"system\", \"content\": content})\n",
    "    return msgs\n",
    "\n",
    "def send_request(messages):\n",
    "    resp = requests.post(API_SEND, headers=HEADERS, json={\"messages\": messages})\n",
    "    resp.raise_for_status()\n",
    "    return resp.json()[\"request_id\"]\n",
    "\n",
    "def wait_for_result(request_id, timeout=30):\n",
    "    url = API_STATUS.format(request_id)\n",
    "    start = time.time()\n",
    "    while True:\n",
    "        r = requests.get(url, headers={\"Authorization\": f\"Bearer {bearer_token}\"})\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "        if data.get(\"status\") == \"success\":\n",
    "            return data[\"result\"]\n",
    "        if time.time() - start > timeout:\n",
    "            raise TimeoutError(\"LLM request timed out\")\n",
    "        time.sleep(0.5)\n",
    "\n",
    "# === AD Detection with window step = W/2 ===\n",
    "\n",
    "prices = list(df['MOEX']['close'][-40:])  # последние 40 точек\n",
    "W = 30                                  # размер окна\n",
    "step = W // 2                           # шаг = половина окна\n",
    "patch_size = 5\n",
    "\n",
    "all_anomalies = []\n",
    "\n",
    "for start in range(0, len(prices) - W + 1, step):\n",
    "    window = prices[start:start + W]\n",
    "\n",
    "    # 1) Патчи и статистика\n",
    "    msgs = make_patch_messages(window, patch_size)\n",
    "\n",
    "    # 2) Общий prompt\n",
    "    msgs.insert(0, {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"You are an anomaly detection assistant. \"\n",
    "            \"Given 30 consecutive closing prices broken into patches with statistics, \"\n",
    "            \"identify which individual price indices in the window are anomalies.  \"\n",
    "            \"Return **only** a JSON array of zero-based indices relative to the window \"\n",
    "            \"where anomalies occur (e.g. [2, 17, 29]). \"\n",
    "            \"If there are no anomalies, return an empty array: [].\"\n",
    "        )\n",
    "    })\n",
    "\n",
    "    # 3) User prompt\n",
    "    msgs.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Detect anomalous price indices in this window.\"\n",
    "    })\n",
    "\n",
    "    # 4) Запрос к LLM\n",
    "    try:\n",
    "        req_id = send_request(msgs)\n",
    "        result_data = wait_for_result(req_id)\n",
    "\n",
    "        indices = extract_indices(result_data)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error at window starting {start}: {e}\")\n",
    "        indices = []\n",
    "\n",
    "    # переводим в глобальные индексы\n",
    "    global_idxs = [start + idx for idx in indices]\n",
    "    all_anomalies.append(global_idxs)\n",
    "    print(f\"Window {start}-{start+W-1}: anomalies at {global_idxs}\")\n",
    "\n",
    "print(\"\\nAll detected anomalies (global indices):\")\n",
    "print(all_anomalies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4424c88-8589-48d8-8941-e7411548c336",
   "metadata": {},
   "source": [
    "# Поиск точек перелома"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0753dd-a4c8-49f2-9449-977a0435bc59",
   "metadata": {},
   "source": [
    "## Fedot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dde2241-1893-4344-a4e2-eefc65e266e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Подготовим данные\n",
    "series = df['MOEX'].set_index('timestamp')['close']\n",
    "# FedotIndustrial ожидает X как массив shape (n_samples, n_features)\n",
    "X = series.values.reshape(-1, 1)\n",
    "\n",
    "# 2. Инициализируем FedotIndustrial для каждого детектора\n",
    "pipelines = {\n",
    "    'StatDetector': 'stat_detector',\n",
    "    'ARIMA_Detector': 'arima_detector'\n",
    "}\n",
    "\n",
    "# Будем хранить для каждого детектора индексы changepoints\n",
    "changepoints = {}\n",
    "\n",
    "for name, pipeline_label in pipelines.items():\n",
    "    ad = FedotIndustrial(\n",
    "        problem='classification',            # бинарная задача: 0/1\n",
    "        industrial_strategy='anomaly_detection',\n",
    "        industrial_task_params={\n",
    "            'detection_window': 10,          # окно для оценки изменений\n",
    "            'detection_pipeline': pipeline_label\n",
    "        },\n",
    "        timeout=1,                           # время AutoML в минутах\n",
    "        n_jobs=1,\n",
    "        logging_level=30\n",
    "    )\n",
    "    # 3. Обучаем на всём ряде\n",
    "    ad.fit((X, None))\n",
    "    # 4. Предсказываем метки змей: 1 означает «anomaly»/changepoint\n",
    "    labels = ad.predict((X, None)).ravel().astype(bool)\n",
    "    # 5. Сохраняем временные метки точек перелома\n",
    "    changepoints[name] = series.index[labels]\n",
    "\n",
    "# 6. Визуализируем оба результата\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 8), sharex=True)\n",
    "for ax, (name, idxs) in zip(axes, changepoints.items()):\n",
    "    ax.plot(series.index, series.values, label='close')\n",
    "    ax.scatter(idxs, series.loc[idxs], color='red', s=50,\n",
    "               label='changepoint', zorder=5)\n",
    "    ax.set_title(f\"Точки перелома ({name}) — найдено {len(idxs)}\")\n",
    "    ax.set_ylabel(\"Цена закрытия\")\n",
    "    ax.legend()\n",
    "\n",
    "axes[-1].set_xlabel(\"Дата\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1922a70-5187-4a1d-9a01-dd3591860932",
   "metadata": {},
   "source": [
    "## Ruptures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d1416d-e108-4b84-89ee-9bab397681a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ruptures as rpt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Загрузка ряда\n",
    "# Предполагаем, что у вас уже есть DataFrame df['MOEX'] с колонками ['timestamp','close']\n",
    "series = df['MOEX'].set_index('timestamp')['close'].sort_index()\n",
    "signal = series.values  # numpy array\n",
    "\n",
    "# 2. Выбор алгоритма и поиск точек перелома\n",
    "#    Здесь — PELT с RBF-моделью и penalization=10 (можно подбирать)\n",
    "algo = rpt.Pelt(model=\"rbf\").fit(signal)\n",
    "breakpoints = algo.predict(pen=10)  # возвращает список индексов после которых меняется поведение\n",
    "\n",
    "print(\"Найденные точки перелома (индексы после смены сегмента):\", breakpoints)\n",
    "\n",
    "# 3. Визуализация результатов\n",
    "plt.figure(figsize=(12, 6))\n",
    "# Removed the 'show=True' argument\n",
    "rpt.display(signal, breakpoints)\n",
    "plt.title(\"Change Point Detection — PELT (model='rbf')\")\n",
    "plt.xlabel(\"Шаг (нулевой отсчёт)\")\n",
    "plt.ylabel(\"Цена закрытия\")\n",
    "# Explicitly call plt.show() to display the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (anomaly)",
   "language": "python",
   "name": "anomaly"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
