{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# –ò–Ω–∂–µ–Ω–µ—Ä–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –º–Ω–æ–≥–æ–º–µ—Ä–Ω—ã—Ö –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤\n",
        "\n",
        "–≠—Ç–æ—Ç –Ω–æ—É—Ç–±—É–∫ –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω –¥–ª—è –æ–±–æ–≥–∞—â–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö —Å –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –Ω–æ–≤–æ—Å—Ç—è–º–∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ —Ñ–∏—á–∞–º–∏:\n",
        "\n",
        "## –≠—Ç–∞–ø—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏:\n",
        "1. **–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã** - –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ —Å –ø–æ–º–æ—â—å—é –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ `ta`\n",
        "2. **–ü–∞—Ç—Ç–µ—Ä–Ω—ã –≥—Ä–∞—Ñ–∏–∫–æ–≤** - –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)\n",
        "3. **–°–≤–æ–π—Å—Ç–≤–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤** - –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –ø–æ–º–æ—â—å—é `tsfresh`\n",
        "4. **–°–∂–∞—Ç–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏** - –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ PCA –¥–ª—è —Å–∂–∞—Ç–∏—è –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
        "5. **–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ** - –∞–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ `data/multivariate_series/`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# –ë–∏–±–ª–∏–æ—Ç–µ–∫–∏ –¥–ª—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤\n",
        "import ta\n",
        "\n",
        "# –ë–∏–±–ª–∏–æ—Ç–µ–∫–∏ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤\n",
        "from tsfresh import extract_features\n",
        "from tsfresh.feature_extraction import EfficientFCParameters\n",
        "from tsfresh.utilities.dataframe_functions import impute\n",
        "\n",
        "# –ë–∏–±–ª–∏–æ—Ç–µ–∫–∏ –¥–ª—è PCA\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
        "plt.style.use('seaborn-v0_8')\n",
        "plt.rcParams['figure.figsize'] = (15, 8)\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "print(\"–ë–∏–±–ª–∏–æ—Ç–µ–∫–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ü—É—Ç–∏ –∫ –¥–∞–Ω–Ω—ã–º\n",
        "INPUT_PATH = 'data/series_with_news/'\n",
        "OUTPUT_PATH = 'data/multivariate_series/'\n",
        "\n",
        "# –°–æ–∑–¥–∞–µ–º –≤—ã—Ö–æ–¥–Ω—É—é –ø–∞–ø–∫—É –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç\n",
        "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
        "\n",
        "# –°–ø–∏—Å–æ–∫ —Ç–∏–∫–µ—Ä–æ–≤\n",
        "tickers = ['AFLT', 'LKOH', 'MOEX', 'NVTK', 'PIKK', 'SBER', 'VKCO', 'VTBR', 'X5', 'YDEX']\n",
        "\n",
        "print(f\"–†–∞–±–æ—á–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏:\")\n",
        "print(f\"- –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (—Å –Ω–æ–≤–æ—Å—Ç—è–º–∏): {INPUT_PATH}\")\n",
        "print(f\"- –í—ã—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (–º–Ω–æ–≥–æ–º–µ—Ä–Ω—ã–µ): {OUTPUT_PATH}\")\n",
        "print(f\"\\n–¢–∏–∫–µ—Ä—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {tickers}\")\n",
        "\n",
        "# –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ\n",
        "df = {}\n",
        "for ticker in tickers:\n",
        "    try:\n",
        "        file_path = f\"{INPUT_PATH}{ticker}_with_news.csv\"\n",
        "        data = pd.read_csv(file_path)\n",
        "        data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
        "        df[ticker] = data\n",
        "        print(f\"–ó–∞–≥—Ä—É–∂–µ–Ω {ticker}: {data.shape}\")\n",
        "    except Exception as e:\n",
        "        print(f\"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {ticker}: {str(e)}\")\n",
        "\n",
        "print(f\"\\n–£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Ç–∏–∫–µ—Ä–æ–≤\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## –≠—Ç–∞–ø 1: –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module='ta.trend')\n",
        "\n",
        "df_ext = {}\n",
        "\n",
        "for ticker, frame in df.items():\n",
        "    print(f\"–î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –¥–ª—è {ticker}...\")\n",
        "    \n",
        "    try:\n",
        "        df0 = frame.copy().set_index('timestamp')\n",
        "\n",
        "        # 1) –°–∫–æ–ª—å–∑—è—â–∏–µ —Å—Ä–µ–¥–Ω–∏–µ\n",
        "        df0['SMA_14'] = df0['close'].rolling(14).mean()\n",
        "        df0['SMA_50'] = df0['close'].rolling(50).mean()\n",
        "        df0['EMA_14'] = ta.trend.EMAIndicator(df0['close'], window=14).ema_indicator()\n",
        "        df0['EMA_50'] = ta.trend.EMAIndicator(df0['close'], window=50).ema_indicator()\n",
        "\n",
        "        # 2) Momentum, ROC\n",
        "        df0['Momentum_10'] = ta.momentum.ROCIndicator(df0['close'], window=10).roc()\n",
        "        df0['Momentum_20'] = ta.momentum.ROCIndicator(df0['close'], window=20).roc()\n",
        "\n",
        "        # 3) RSI, MFI\n",
        "        df0['RSI_14'] = ta.momentum.RSIIndicator(df0['close'], window=14).rsi()\n",
        "        df0['MFI_14'] = ta.volume.MFIIndicator(\n",
        "            df0['high'], df0['low'], df0['close'], df0['volume'], window=14\n",
        "        ).money_flow_index()\n",
        "\n",
        "        # 4) Stochastic %K/%D, Williams %R\n",
        "        stoch = ta.momentum.StochasticOscillator(\n",
        "            df0['high'], df0['low'], df0['close'], window=14, smooth_window=3\n",
        "        )\n",
        "        df0['Stoch_%K'] = stoch.stoch()\n",
        "        df0['Stoch_%D'] = stoch.stoch_signal()\n",
        "        df0['Williams_%R'] = ta.momentum.WilliamsRIndicator(\n",
        "            df0['high'], df0['low'], df0['close'], lbp=14\n",
        "        ).williams_r()\n",
        "\n",
        "        # 5) CCI, ADX/ADXR\n",
        "        df0['CCI_20'] = ta.trend.CCIIndicator(\n",
        "            df0['high'], df0['low'], df0['close'], window=20\n",
        "        ).cci()\n",
        "        adx = ta.trend.ADXIndicator(\n",
        "            df0['high'], df0['low'], df0['close'], window=14\n",
        "        )\n",
        "        df0['ADX_14']  = adx.adx()\n",
        "        df0['ADXR_14'] = df0['ADX_14'].rolling(window=14).mean()\n",
        "\n",
        "        # 6) MACD\n",
        "        macd = ta.trend.MACD(df0['close'])\n",
        "        df0['MACD']        = macd.macd()\n",
        "        df0['MACD_signal'] = macd.macd_signal()\n",
        "        df0['MACD_diff']   = macd.macd_diff()\n",
        "\n",
        "        # 7) Bollinger Bands\n",
        "        bb = ta.volatility.BollingerBands(df0['close'], window=20, window_dev=2)\n",
        "        df0['BB_hband'] = bb.bollinger_hband()\n",
        "        df0['BB_lband'] = bb.bollinger_lband()\n",
        "        df0['BB_mavg']  = bb.bollinger_mavg()\n",
        "\n",
        "        # 8) ATR, Parabolic SAR\n",
        "        df0['ATR_14'] = ta.volatility.AverageTrueRange(\n",
        "            df0['high'], df0['low'], df0['close'], window=14\n",
        "        ).average_true_range()\n",
        "        df0['PSAR']   = ta.trend.PSARIndicator(\n",
        "            df0['high'], df0['low'], df0['close'], step=0.02, max_step=0.2\n",
        "        ).psar()\n",
        "\n",
        "        # 9) Volume-based: OBV, CMF, VWAP\n",
        "        df0['OBV'] = ta.volume.OnBalanceVolumeIndicator(\n",
        "            df0['close'], df0['volume']\n",
        "        ).on_balance_volume()\n",
        "        df0['CMF_20'] = ta.volume.ChaikinMoneyFlowIndicator(\n",
        "            df0['high'], df0['low'], df0['close'], df0['volume'], window=20\n",
        "        ).chaikin_money_flow()\n",
        "        \n",
        "        # VWAP: (high+low+close)/3 * volume cumulative / volume cumulative\n",
        "        tp = (df0['high'] + df0['low'] + df0['close']) / 3\n",
        "        vwap = (tp * df0['volume']).cumsum() / df0['volume'].cumsum()\n",
        "        df0['VWAP'] = vwap\n",
        "\n",
        "        # —Å–æ—Ö—Ä–∞–Ω—è–µ–º\n",
        "        df_ext[ticker] = df0\n",
        "        print(f\"  - –£—Å–ø–µ—à–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω—ã —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã. –†–∞–∑–º–µ—Ä: {df0.shape}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"  - –û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –¥–ª—è {ticker}: {str(e)}\")\n",
        "\n",
        "print(f\"\\n–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –¥–æ–±–∞–≤–ª–µ–Ω—ã –¥–ª—è {len(df_ext)} —Ç–∏–∫–µ—Ä–æ–≤\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ç–∏–∫–µ—Ä–∞\n",
        "if 'MOEX' in df_ext:\n",
        "    print(\"–ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö —Å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º–∏ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞–º–∏ –¥–ª—è MOEX:\")\n",
        "    print(\"\\n–ö–æ–ª–æ–Ω–∫–∏:\")\n",
        "    print(list(df_ext['MOEX'].columns))\n",
        "    print(f\"\\n–ü–æ—Å–ª–µ–¥–Ω–∏–µ 3 —Å—Ç—Ä–æ–∫–∏:\")\n",
        "    print(df_ext['MOEX'].tail(3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## –≠—Ç–∞–ø 1.1: –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –≤ –±–∏–±–ª–∏–æ—Ç–µ–∫–µ ta\n",
        "try:\n",
        "    import ta.others\n",
        "    print(\"–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥—É–ª–∏ ta.others:\")\n",
        "    print(dir(ta.others))\n",
        "    \n",
        "    # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å\n",
        "    for ticker, df0 in df_ext.items():\n",
        "        try:\n",
        "            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–∞–∑–æ–≤—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Å –¥–æ—Å—Ç—É–ø–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏\n",
        "            # DailyReturn\n",
        "            if hasattr(ta.others, 'DailyReturnIndicator'):\n",
        "                df0['Daily_Return'] = ta.others.DailyReturnIndicator(df0['close']).daily_return()\n",
        "            \n",
        "            # Daily Log Return\n",
        "            if hasattr(ta.others, 'DailyLogReturnIndicator'):\n",
        "                df0['Daily_Log_Return'] = ta.others.DailyLogReturnIndicator(df0['close']).daily_log_return()\n",
        "            \n",
        "            # Cumulative Return\n",
        "            if hasattr(ta.others, 'CumulativeReturnIndicator'):\n",
        "                df0['Cumulative_Return'] = ta.others.CumulativeReturnIndicator(df0['close']).cumulative_return()\n",
        "                \n",
        "            print(f\"–î–æ–±–∞–≤–ª–µ–Ω—ã –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è {ticker}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–ª—è {ticker}: {str(e)}\")\n",
        "            \n",
        "except Exception as e:\n",
        "    print(f\"–ú–æ–¥—É–ª—å ta.others –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –∏–ª–∏ –æ—à–∏–±–∫–∞: {str(e)}\")\n",
        "    \n",
        "    # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ - —Å–æ–∑–¥–∞–µ–º —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ—Å—Ç—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã\n",
        "    print(\"–°–æ–∑–¥–∞–µ–º —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ—Å—Ç—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã...\")\n",
        "    \n",
        "    for ticker, df0 in df_ext.items():\n",
        "        try:\n",
        "            # –ü—Ä–æ—Å—Ç—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ü–µ–Ω–æ–≤—ã—Ö –¥–≤–∏–∂–µ–Ω–∏–π\n",
        "            df0['Price_Above_SMA14'] = (df0['close'] > df0['SMA_14']).astype(int)\n",
        "            df0['Price_Above_SMA50'] = (df0['close'] > df0['SMA_50']).astype(int)\n",
        "            df0['SMA14_Above_SMA50'] = (df0['SMA_14'] > df0['SMA_50']).astype(int)\n",
        "            \n",
        "            # –ü–∞—Ç—Ç–µ—Ä–Ω \"–±—ã—á–∏–π\" –∏ \"–º–µ–¥–≤–µ–∂–∏–π\" —Ç—Ä–µ–Ω–¥\n",
        "            df0['Bullish_Trend'] = ((df0['close'] > df0['SMA_14']) & \n",
        "                                   (df0['SMA_14'] > df0['SMA_50']) & \n",
        "                                   (df0['RSI_14'] > 50)).astype(int)\n",
        "            \n",
        "            df0['Bearish_Trend'] = ((df0['close'] < df0['SMA_14']) & \n",
        "                                   (df0['SMA_14'] < df0['SMA_50']) & \n",
        "                                   (df0['RSI_14'] < 50)).astype(int)\n",
        "            \n",
        "            # –ü–∞—Ç—Ç–µ—Ä–Ω –ø–µ—Ä–µ–∫—É–ø–ª–µ–Ω–Ω–æ—Å—Ç–∏/–ø–µ—Ä–µ–ø—Ä–æ–¥–∞–Ω–Ω–æ—Å—Ç–∏\n",
        "            df0['Overbought'] = (df0['RSI_14'] > 70).astype(int)\n",
        "            df0['Oversold'] = (df0['RSI_14'] < 30).astype(int)\n",
        "            \n",
        "            # –ü–∞—Ç—Ç–µ—Ä–Ω –ø—Ä–æ–±–æ—è Bollinger Bands\n",
        "            df0['BB_Upper_Break'] = (df0['close'] > df0['BB_hband']).astype(int)\n",
        "            df0['BB_Lower_Break'] = (df0['close'] < df0['BB_lband']).astype(int)\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–ª—è {ticker}: {str(e)}\")\n",
        "    \n",
        "    print(\"–°–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–æ–±–∞–≤–ª–µ–Ω—ã\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## –≠—Ç–∞–ø 2: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤ —Å –ø–æ–º–æ—â—å—é tsfresh\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "WINDOW = 20\n",
        "STEP   = 1\n",
        "fc_params = EfficientFCParameters()\n",
        "\n",
        "print(\"–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤ —Å –ø–æ–º–æ—â—å—é tsfresh...\")\n",
        "print(f\"–ü–∞—Ä–∞–º–µ—Ç—Ä—ã: –æ–∫–Ω–æ = {WINDOW}, —à–∞–≥ = {STEP}\")\n",
        "\n",
        "for ticker, df0 in df_ext.items():\n",
        "    print(f\"\\n–û–±—Ä–∞–±–æ—Ç–∫–∞ {ticker}...\")\n",
        "    \n",
        "    try:\n",
        "        df0 = df0.copy()  # –°–∫–æ–ª—å–∑—è—â–∏–π DataFrame\n",
        "        n   = len(df0)\n",
        "        \n",
        "        print(f\"  - –ò—Å—Ö–æ–¥–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {df0.shape}\")\n",
        "\n",
        "        # 1) –°–æ–±–∏—Ä–∞–µ–º 'long' DF –¥–ª—è tsfresh –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ü–µ–Ω—ã –∑–∞–∫—Ä—ã—Ç–∏—è\n",
        "        rows = []\n",
        "        for start in range(0, n - WINDOW + 1, STEP):\n",
        "            window = df0['close'].iloc[start:start+WINDOW].values\n",
        "            # –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ –æ–∫–Ω–∞ ‚Äî –æ–¥–Ω–∞ —Å—Ç—Ä–æ–∫–∞\n",
        "            for t, val in enumerate(window):\n",
        "                rows.append({'id': start, 'time': t, 'value': float(val)})\n",
        "        \n",
        "        if len(rows) == 0:\n",
        "            print(f\"  - –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –æ–∫–æ–Ω\")\n",
        "            continue\n",
        "            \n",
        "        df_long = pd.DataFrame(rows)\n",
        "        print(f\"  - –°–æ–∑–¥–∞–Ω long DataFrame: {df_long.shape}\")\n",
        "\n",
        "        # 2) –ò–∑–≤–ª–µ–∫–∞–µ–º —Ñ–∏—á–∏\n",
        "        print(f\"  - –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...\")\n",
        "        features = extract_features(\n",
        "            df_long,\n",
        "            column_id='id',\n",
        "            column_sort='time',\n",
        "            column_value='value',\n",
        "            default_fc_parameters=fc_params,\n",
        "            impute_function=impute,\n",
        "            n_jobs=1  # –ò—Å–ø–æ–ª—å–∑—É–µ–º 1 –ø–æ—Ç–æ–∫ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏\n",
        "        )\n",
        "        print(f\"  - –ò–∑–≤–ª–µ—á–µ–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {features.shape}\")\n",
        "        \n",
        "        # features.index == [0,1,2,...] == –Ω–∞—à–∏ start-–ø–æ–∑–∏—Ü–∏–∏\n",
        "\n",
        "        # 3) –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º features ‚Üí feat_df —Å –∏–Ω–¥–µ–∫—Å–æ–º timestamps –∫–æ–Ω—Ü–∞ –æ–∫–Ω–∞\n",
        "        #    end positions = start + WINDOW - 1\n",
        "        end_positions = features.index + WINDOW - 1\n",
        "        end_timestamps = df0.index[end_positions]\n",
        "        feat_df = features.copy()\n",
        "        feat_df.index = end_timestamps  # —Ç–µ–ø–µ—Ä—å –∏–Ω–¥–µ–∫—Å = –º–µ—Ç–∫–∏ –≤—Ä–µ–º–µ–Ω–∏\n",
        "\n",
        "        # 4) –û–±—Ä–µ–∑–∞–µ–º df0 –ø–µ—Ä–≤—ã—Ö WINDOW-1 —Å—Ç—Ä–æ–∫ (–±–µ–∑ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)\n",
        "        df0 = df0.iloc[WINDOW-1:].copy()\n",
        "        print(f\"  - –û–±—Ä–µ–∑–∞–Ω–Ω—ã–π DataFrame: {df0.shape}\")\n",
        "\n",
        "        # 5) –ö–æ–Ω–∫–∞—Ç–µ–Ω–∏—Ä—É–µ–º df0 –∏ feat_df –ø–æ –≤—Ä–µ–º–µ–Ω–∏\n",
        "        df_combined = pd.concat([df0, feat_df], axis=1)\n",
        "        df_ext[ticker] = df_combined\n",
        "        \n",
        "        print(f\"  - –§–∏–Ω–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {df_combined.shape}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"  - –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è {ticker}: {str(e)}\")\n",
        "        # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –æ—Å—Ç–∞–≤–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ\n",
        "        continue\n",
        "\n",
        "print(f\"\\n–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ tsfresh –∑–∞–≤–µ—Ä—à–µ–Ω–æ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –ø–æ—Å–ª–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è tsfresh –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
        "if 'MOEX' in df_ext:\n",
        "    print(\"–ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è tsfresh –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è MOEX:\")\n",
        "    print(f\"–†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö: {df_ext['MOEX'].shape}\")\n",
        "    print(f\"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–æ–ª–±—Ü–æ–≤: {len(df_ext['MOEX'].columns)}\")\n",
        "    \n",
        "    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –Ω–æ–≤—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤ tsfresh\n",
        "    tsfresh_columns = [col for col in df_ext['MOEX'].columns if 'value__' in col]\n",
        "    print(f\"\\n–ü—Ä–∏–º–µ—Ä—ã tsfresh —Å—Ç–æ–ª–±—Ü–æ–≤ ({len(tsfresh_columns)} –≤—Å–µ–≥–æ):\")\n",
        "    for i, col in enumerate(tsfresh_columns[:10]):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10\n",
        "        print(f\"  {i+1}. {col}\")\n",
        "    if len(tsfresh_columns) > 10:\n",
        "        print(f\"  ... –∏ –µ—â–µ {len(tsfresh_columns) - 10} —Å—Ç–æ–ª–±—Ü–æ–≤\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## –≠—Ç–∞–ø 3: –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ PCA –¥–ª—è —Å–∂–∞—Ç–∏—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def apply_pca_to_features(df, variance_threshold=0.95):\n",
        "    \"\"\"\n",
        "    –ü—Ä–∏–º–µ–Ω—è–µ—Ç PCA –∫ —á–∏—Å–ª–µ–Ω–Ω—ã–º –ø—Ä–∏–∑–Ω–∞–∫–∞–º DataFrame\n",
        "    \n",
        "    Args:\n",
        "        df: DataFrame —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏\n",
        "        variance_threshold: –ü–æ—Ä–æ–≥ –¥–ª—è –æ–±—ä—è—Å–Ω–µ–Ω–Ω–æ–π –¥–∏—Å–ø–µ—Ä—Å–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 95%)\n",
        "    \n",
        "    Returns:\n",
        "        df_with_pca: DataFrame —Å –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–º–∏ PCA –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏\n",
        "        pca: –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å PCA\n",
        "        scaler: –æ–±—É—á–µ–Ω–Ω—ã–π scaler\n",
        "    \"\"\"\n",
        "    \n",
        "    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è PCA\n",
        "    base_columns = ['open', 'close', 'high', 'low', 'volume', 'anomaly', 'method', 'date', \n",
        "                   'kernai_daily_avg', 'gigachat_daily_avg', 'deepseek_daily_avg', \n",
        "                   'weighted_score_base', 'weighted_score_with_decay', 'daily_headlines', 'return']\n",
        "    \n",
        "    # –ù–∞—Ö–æ–¥–∏–º –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è PCA (—á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏, –∏—Å–∫–ª—é—á–∞—è –±–∞–∑–æ–≤—ã–µ)\n",
        "    numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    pca_columns = [col for col in numeric_columns if col not in base_columns]\n",
        "    \n",
        "    print(f\"  - –í—Å–µ–≥–æ —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫: {len(numeric_columns)}\")\n",
        "    print(f\"  - –ë–∞–∑–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ –∏—Å–∫–ª—é—á–µ–Ω–æ: {len(base_columns)}\")\n",
        "    print(f\"  - –ö–æ–ª–æ–Ω–æ–∫ –¥–ª—è PCA: {len(pca_columns)}\")\n",
        "    \n",
        "    if len(pca_columns) == 0:\n",
        "        print(\"  - –ù–µ—Ç –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è PCA\")\n",
        "        return df, None, None\n",
        "    \n",
        "    # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è PCA\n",
        "    pca_data = df[pca_columns].copy()\n",
        "    \n",
        "    # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å NaN\n",
        "    pca_data_clean = pca_data.dropna()\n",
        "    valid_indices = pca_data_clean.index\n",
        "    \n",
        "    print(f\"  - –°—Ç—Ä–æ–∫ —Å –¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è PCA: {len(pca_data_clean)}\")\n",
        "    \n",
        "    if len(pca_data_clean) == 0:\n",
        "        print(\"  - –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è PCA –ø–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è NaN\")\n",
        "        return df, None, None\n",
        "    \n",
        "    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è\n",
        "    scaler = StandardScaler()\n",
        "    pca_data_scaled = scaler.fit_transform(pca_data_clean)\n",
        "    \n",
        "    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç\n",
        "    pca_full = PCA()\n",
        "    pca_full.fit(pca_data_scaled)\n",
        "    \n",
        "    # –ù–∞—Ö–æ–¥–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç –¥–ª—è –∑–∞–¥–∞–Ω–Ω–æ–≥–æ –ø–æ—Ä–æ–≥–∞ –¥–∏—Å–ø–µ—Ä—Å–∏–∏\n",
        "    cumsum_var = np.cumsum(pca_full.explained_variance_ratio_)\n",
        "    n_components = np.argmax(cumsum_var >= variance_threshold) + 1\n",
        "    \n",
        "    print(f\"  - –ö–æ–º–ø–æ–Ω–µ–Ω—Ç –¥–ª—è {variance_threshold*100}% –¥–∏—Å–ø–µ—Ä—Å–∏–∏: {n_components}\")\n",
        "    print(f\"  - –§–∞–∫—Ç–∏—á–µ—Å–∫–∞—è –æ–±—ä—è—Å–Ω–µ–Ω–Ω–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è: {cumsum_var[n_components-1]:.4f}\")\n",
        "    \n",
        "    # –ü—Ä–∏–º–µ–Ω—è–µ–º PCA —Å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç\n",
        "    pca = PCA(n_components=n_components)\n",
        "    pca_result = pca.fit_transform(pca_data_scaled)\\n    \\n    # –°–æ–∑–¥–∞–µ–º DataFrame —Å PCA –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏\\n    pca_df = pd.DataFrame(\\n        pca_result,\\n        index=valid_indices,\\n        columns=[f'PCA_{i+1}' for i in range(n_components)]\\n    )\\n    \\n    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å –∏—Å—Ö–æ–¥–Ω—ã–º DataFrame\\n    df_with_pca = df.copy()\\n    df_with_pca = pd.concat([df_with_pca, pca_df], axis=1)\\n    \\n    return df_with_pca, pca, scaler\\n\\nprint(\\\"–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ PCA –∫ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º –¥–∞–Ω–Ω—ã–º...\\\")\\n\\ndf_final = {}\\npca_info = {}\\n\\nfor ticker, df0 in df_ext.items():\\n    print(f\\\"\\\\n–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ PCA –¥–ª—è {ticker}...\\\")\\n    \\n    try:\\n        df_with_pca, pca_model, scaler_model = apply_pca_to_features(df0)\\n        \\n        df_final[ticker] = df_with_pca\\n        pca_info[ticker] = {\\n            'pca': pca_model,\\n            'scaler': scaler_model,\\n            'n_components': pca_model.n_components_ if pca_model else 0,\\n            'explained_variance_ratio': pca_model.explained_variance_ratio_ if pca_model else None\\n        }\\n        \\n        print(f\\\"  - –§–∏–Ω–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {df_with_pca.shape}\\\")\\n        \\n    except Exception as e:\\n        print(f\\\"  - –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–∏ PCA –¥–ª—è {ticker}: {str(e)}\\\")\\n        df_final[ticker] = df0  # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –±–µ–∑ PCA\\n        pca_info[ticker] = {'pca': None, 'scaler': None, 'n_components': 0, 'explained_variance_ratio': None}\\n\\nprint(f\\\"\\\\nPCA –ø—Ä–∏–º–µ–Ω–µ–Ω–æ –¥–ª—è {len(df_final)} —Ç–∏–∫–µ—Ä–æ–≤\\\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ PCA\n",
        "print(\"\\n–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ PCA –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞—Ö:\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "for ticker, info in pca_info.items():\n",
        "    if info['pca'] is not None:\n",
        "        print(f\"\\n{ticker}:\")\n",
        "        print(f\"  - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç: {info['n_components']}\")\n",
        "        print(f\"  - –û–±—ä—è—Å–Ω–µ–Ω–Ω–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è –ø–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º:\")\n",
        "        for i, var in enumerate(info['explained_variance_ratio'][:5]):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5\n",
        "            print(f\"    PCA_{i+1}: {var:.4f}\")\n",
        "        if len(info['explained_variance_ratio']) > 5:\n",
        "            print(f\"    ... –µ—â–µ {len(info['explained_variance_ratio']) - 5} –∫–æ–º–ø–æ–Ω–µ–Ω—Ç\")\n",
        "\n",
        "# –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
        "if 'MOEX' in df_final:\n",
        "    print(f\"\\n\\n–ü—Ä–∏–º–µ—Ä —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è MOEX:\")\n",
        "    print(f\"–†–∞–∑–º–µ—Ä: {df_final['MOEX'].shape}\")\n",
        "    \n",
        "    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º PCA –∫–æ–ª–æ–Ω–∫–∏\n",
        "    pca_columns = [col for col in df_final['MOEX'].columns if col.startswith('PCA_')]\n",
        "    print(f\"PCA –∫–æ–ª–æ–Ω–∫–∏ ({len(pca_columns)}): {pca_columns[:10]}\")\n",
        "    if len(pca_columns) > 10:\n",
        "        print(f\"... –µ—â–µ {len(pca_columns) - 10} PCA –∫–æ–ª–æ–Ω–æ–∫\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## –≠—Ç–∞–ø 4: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–Ω–æ–≥–æ–º–µ—Ä–Ω—ã—Ö –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤\n",
        "print(\"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–Ω–æ–≥–æ–º–µ—Ä–Ω—ã—Ö –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤...\")\n",
        "\n",
        "saved_files = []\n",
        "processing_stats = []\n",
        "\n",
        "for ticker, df_multivariate in df_final.items():\n",
        "    try:\n",
        "        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏ –≤ –∫–∞—á–µ—Å—Ç–≤–µ –∫–æ–ª–æ–Ω–∫–∏\n",
        "        df_to_save = df_multivariate.reset_index()\n",
        "        \n",
        "        # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ timestamp –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ\n",
        "        if 'timestamp' not in df_to_save.columns and df_to_save.index.name == 'timestamp':\n",
        "            df_to_save = df_multivariate.reset_index()\n",
        "        \n",
        "        output_file = f\"{OUTPUT_PATH}{ticker}_multivariate.csv\"\n",
        "        df_to_save.to_csv(output_file, index=False)\n",
        "        \n",
        "        saved_files.append(output_file)\n",
        "        \n",
        "        # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É\n",
        "        stats = {\n",
        "            'ticker': ticker,\n",
        "            'total_rows': len(df_multivariate),\n",
        "            'total_columns': len(df_multivariate.columns),\n",
        "            'date_start': df_multivariate.index.min() if hasattr(df_multivariate.index, 'min') else 'N/A',\n",
        "            'date_end': df_multivariate.index.max() if hasattr(df_multivariate.index, 'max') else 'N/A',\n",
        "            'pca_components': pca_info.get(ticker, {}).get('n_components', 0),\n",
        "            'technical_indicators': len([col for col in df_multivariate.columns \n",
        "                                       if any(indicator in col for indicator in \n",
        "                                            ['SMA', 'EMA', 'RSI', 'MACD', 'BB_', 'ATR', 'PSAR', 'OBV'])]),\n",
        "            'tsfresh_features': len([col for col in df_multivariate.columns if 'value__' in col]),\n",
        "            'news_features': len([col for col in df_multivariate.columns \n",
        "                                if col in ['kernai_daily_avg', 'gigachat_daily_avg', 'deepseek_daily_avg', \n",
        "                                          'weighted_score_with_decay']]),\n",
        "            'pattern_features': len([col for col in df_multivariate.columns \n",
        "                                   if any(pattern in col for pattern in \n",
        "                                        ['Bullish', 'Bearish', 'Overbought', 'Oversold', 'Break'])])\n",
        "        }\n",
        "        processing_stats.append(stats)\n",
        "        \n",
        "        print(f\"  - {ticker}: —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ {df_multivariate.shape} –≤ {output_file}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"  - –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è {ticker}: {str(e)}\")\n",
        "\n",
        "print(f\"\\n–£—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(saved_files)} —Ñ–∞–π–ª–æ–≤ –≤ {OUTPUT_PATH}\")\n",
        "\n",
        "# –°–æ–∑–¥–∞–µ–º DataFrame —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π\n",
        "stats_df = pd.DataFrame(processing_stats)\n",
        "\n",
        "# –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É\n",
        "stats_file = f\"{OUTPUT_PATH}multivariate_processing_stats.csv\"\n",
        "stats_df.to_csv(stats_file, index=False)\n",
        "\n",
        "print(f\"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {stats_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –í—ã–≤–æ–¥–∏–º –¥–µ—Ç–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"–°–¢–ê–¢–ò–°–¢–ò–ö–ê –ú–ù–û–ì–û–ú–ï–†–ù–´–• –í–†–ï–ú–ï–ù–ù–´–• –†–Ø–î–û–í\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\n–û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:\")\n",
        "print(f\"- –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ç–∏–∫–µ—Ä–æ–≤: {len(stats_df)}\")\n",
        "print(f\"- –§–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {OUTPUT_PATH}\")\n",
        "\n",
        "print(f\"\\n–î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–∫–µ—Ä–∞–º:\")\n",
        "print(\"-\"*80)\n",
        "for _, row in stats_df.iterrows():\n",
        "    print(f\"\\n{row['ticker']}:\")\n",
        "    print(f\"  üìä –†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö: {row['total_rows']} —Å—Ç—Ä–æ–∫ √ó {row['total_columns']} —Å—Ç–æ–ª–±—Ü–æ–≤\")\n",
        "    print(f\"  üìÖ –ü–µ—Ä–∏–æ–¥: {row['date_start']} - {row['date_end']}\")\n",
        "    print(f\"  üîß –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã: {row['technical_indicators']}\")\n",
        "    print(f\"  üìà TSFresh –ø—Ä–∏–∑–Ω–∞–∫–∏: {row['tsfresh_features']}\")\n",
        "    print(f\"  üì∞ –ù–æ–≤–æ—Å—Ç–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: {row['news_features']}\")\n",
        "    print(f\"  üéØ –ü–∞—Ç—Ç–µ—Ä–Ω—ã: {row['pattern_features']}\")\n",
        "    print(f\"  üßÆ PCA –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã: {row['pca_components']}\")\n",
        "\n",
        "# –°–≤–æ–¥–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n",
        "print(f\"\\n\" + \"=\"*50)\n",
        "print(\"–°–í–û–î–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "print(f\"–°—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ –≤—Å–µ–º —Ç–∏–∫–µ—Ä–∞–º:\")\n",
        "numeric_columns = ['total_rows', 'total_columns', 'technical_indicators', \n",
        "                  'tsfresh_features', 'news_features', 'pattern_features', 'pca_components']\n",
        "\n",
        "for col in numeric_columns:\n",
        "    if col in stats_df.columns:\n",
        "        mean_val = stats_df[col].mean()\n",
        "        min_val = stats_df[col].min() \n",
        "        max_val = stats_df[col].max()\n",
        "        print(f\"  {col}: —Å—Ä–µ–¥–Ω–µ–µ={mean_val:.1f}, –º–∏–Ω={min_val}, –º–∞–∫—Å={max_val}\")\n",
        "\n",
        "print(f\"\\n–ò—Ç–æ–≥–æ–≤–∞—è —Å–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞:\")\n",
        "print(stats_df[['ticker', 'total_rows', 'total_columns', 'pca_components']].to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# –ì—Ä–∞—Ñ–∏–∫ 1: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–æ–ª–±—Ü–æ–≤ –ø–æ —Ç–∏–∫–µ—Ä–∞–º\n",
        "axes[0, 0].bar(stats_df['ticker'], stats_df['total_columns'], color='skyblue')\n",
        "axes[0, 0].set_title('–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–æ–ª–±—Ü–æ–≤ –ø–æ —Ç–∏–∫–µ—Ä–∞–º')\n",
        "axes[0, 0].set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–æ–ª–±—Ü–æ–≤')\n",
        "axes[0, 0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# –ì—Ä–∞—Ñ–∏–∫ 2: PCA –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã\n",
        "axes[0, 1].bar(stats_df['ticker'], stats_df['pca_components'], color='lightgreen')\n",
        "axes[0, 1].set_title('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ PCA –∫–æ–º–ø–æ–Ω–µ–Ω—Ç –ø–æ —Ç–∏–∫–µ—Ä–∞–º')\n",
        "axes[0, 1].set_ylabel('PCA –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã')\n",
        "axes[0, 1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# –ì—Ä–∞—Ñ–∏–∫ 3: –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã\n",
        "axes[1, 0].bar(stats_df['ticker'], stats_df['technical_indicators'], color='orange')\n",
        "axes[1, 0].set_title('–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –ø–æ —Ç–∏–∫–µ—Ä–∞–º')\n",
        "axes[1, 0].set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤')\n",
        "axes[1, 0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# –ì—Ä–∞—Ñ–∏–∫ 4: TSFresh –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
        "axes[1, 1].bar(stats_df['ticker'], stats_df['tsfresh_features'], color='coral')\n",
        "axes[1, 1].set_title('TSFresh –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ —Ç–∏–∫–µ—Ä–∞–º')\n",
        "axes[1, 1].set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤')\n",
        "axes[1, 1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## –ó–∞–∫–ª—é—á–µ–Ω–∏–µ\n",
        "\n",
        "–í —ç—Ç–æ–º –Ω–æ—É—Ç–±—É–∫–µ –±—ã–ª–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ –∫–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –∏–Ω–∂–µ–Ω–µ—Ä–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –º–Ω–æ–≥–æ–º–µ—Ä–Ω—ã—Ö –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤:\n",
        "\n",
        "### –í—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã–µ —ç—Ç–∞–ø—ã:\n",
        "\n",
        "1. **–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã** - –¥–æ–±–∞–≤–ª–µ–Ω–æ ~25 —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤:\n",
        "   - –°–∫–æ–ª—å–∑—è—â–∏–µ —Å—Ä–µ–¥–Ω–∏–µ (SMA, EMA)\n",
        "   - –û—Å—Ü–∏–ª–ª—è—Ç–æ—Ä—ã (RSI, Stochastic, Williams %R)\n",
        "   - –¢—Ä–µ–Ω–¥–æ–≤—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã (MACD, ADX, CCI)\n",
        "   - –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å (Bollinger Bands, ATR)\n",
        "   - –û–±—ä–µ–º–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã (OBV, CMF, VWAP)\n",
        "\n",
        "2. **–ì—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã** - —Å–æ–∑–¥–∞–Ω—ã –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤:\n",
        "   - –ë—ã—á—å–∏/–º–µ–¥–≤–µ–∂—å–∏ —Ç—Ä–µ–Ω–¥—ã\n",
        "   - –ü–µ—Ä–µ–∫—É–ø–ª–µ–Ω–Ω–æ—Å—Ç—å/–ø–µ—Ä–µ–ø—Ä–æ–¥–∞–Ω–Ω–æ—Å—Ç—å\n",
        "   - –ü—Ä–æ–±–æ–∏ Bollinger Bands\n",
        "\n",
        "3. **TSFresh –ø—Ä–∏–∑–Ω–∞–∫–∏** - –∏–∑–≤–ª–µ—á–µ–Ω—ã —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤:\n",
        "   - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Å–∫–æ–ª—å–∑—è—â–µ–µ –æ–∫–Ω–æ —Ä–∞–∑–º–µ—Ä–æ–º 20\n",
        "   - –ü—Ä–∏–º–µ–Ω–µ–Ω—ã —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏\n",
        "\n",
        "4. **PCA —Å–∂–∞—Ç–∏–µ** - –ø—Ä–∏–º–µ–Ω–µ–Ω–æ —Å–∂–∞—Ç–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏:\n",
        "   - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç (95% –¥–∏—Å–ø–µ—Ä—Å–∏–∏)\n",
        "   - –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ–¥ PCA\n",
        "   - –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –±–∞–∑–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ –±–µ–∑ —Å–∂–∞—Ç–∏—è\n",
        "\n",
        "5. **–†–µ–∑—É–ª—å—Ç–∞—Ç—ã**:\n",
        "   - –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ø–∞–ø–∫—É `data/multivariate_series/`\n",
        "   - –°–æ–∑–¥–∞–Ω–∞ –¥–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞–∂–¥–æ–º—É —Ç–∏–∫–µ—Ä—É\n",
        "   - –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
        "\n",
        "### –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:\n",
        "- **–ë–æ–≥–∞—Ç–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ** –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤ —Å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏\n",
        "- **–°–∂–∞—Ç–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ** –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è\n",
        "- **–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç–∏** —á–µ—Ä–µ–∑ –±–∞–∑–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
        "- **–ì–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –¥–ª—è –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è** —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ –∞–ª–≥–æ—Ä–∏—Ç–º–∞–º–∏\n",
        "\n",
        "–ü–æ–ª—É—á–µ–Ω–Ω—ã–µ –º–Ω–æ–≥–æ–º–µ—Ä–Ω—ã–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã –≥–æ—Ç–æ–≤—ã –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –∑–∞–¥–∞—á–∞—Ö –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è, –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∞–Ω–æ–º–∞–ª–∏–π –∏ –¥—Ä—É–≥–∏—Ö –∑–∞–¥–∞—á –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
