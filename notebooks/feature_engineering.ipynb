{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Инженерия признаков для многомерных временных рядов\n",
        "\n",
        "Этот ноутбук предназначен для обогащения данных с интегрированными новостями дополнительными фичами:\n",
        "\n",
        "## Этапы обработки:\n",
        "1. **Технические индикаторы** - добавление технических индикаторов с помощью библиотеки `ta`\n",
        "2. **Паттерны графиков** - обнаружение графических паттернов (опционально)\n",
        "3. **Свойства временных рядов** - извлечение признаков с помощью `tsfresh`\n",
        "4. **Сжатие размерности** - применение PCA для сжатия пространства признаков\n",
        "5. **Статистика и сохранение** - анализ результатов и сохранение в `data/multivariate_series/`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Библиотеки для технических индикаторов\n",
        "import ta\n",
        "\n",
        "# Библиотеки для извлечения признаков временных рядов\n",
        "from tsfresh import extract_features\n",
        "from tsfresh.feature_extraction import EfficientFCParameters\n",
        "from tsfresh.utilities.dataframe_functions import impute\n",
        "\n",
        "# Библиотеки для PCA\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Настройка отображения\n",
        "plt.style.use('seaborn-v0_8')\n",
        "plt.rcParams['figure.figsize'] = (15, 8)\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "print(\"Библиотеки загружены успешно\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Пути к данным\n",
        "INPUT_PATH = 'data/series_with_news/'\n",
        "OUTPUT_PATH = 'data/multivariate_series/'\n",
        "\n",
        "# Создаем выходную папку если её нет\n",
        "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
        "\n",
        "# Список тикеров\n",
        "tickers = ['AFLT', 'LKOH', 'MOEX', 'NVTK', 'PIKK', 'SBER', 'VKCO', 'VTBR', 'X5', 'YDEX']\n",
        "\n",
        "print(f\"Рабочие директории:\")\n",
        "print(f\"- Входные данные (с новостями): {INPUT_PATH}\")\n",
        "print(f\"- Выходные данные (многомерные): {OUTPUT_PATH}\")\n",
        "print(f\"\\nТикеры для обработки: {tickers}\")\n",
        "\n",
        "# Загружаем данные\n",
        "df = {}\n",
        "for ticker in tickers:\n",
        "    try:\n",
        "        file_path = f\"{INPUT_PATH}{ticker}_with_news.csv\"\n",
        "        data = pd.read_csv(file_path)\n",
        "        data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
        "        df[ticker] = data\n",
        "        print(f\"Загружен {ticker}: {data.shape}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Ошибка загрузки {ticker}: {str(e)}\")\n",
        "\n",
        "print(f\"\\nУспешно загружено {len(df)} тикеров\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Этап 1: Добавление технических индикаторов\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module='ta.trend')\n",
        "\n",
        "df_ext = {}\n",
        "\n",
        "for ticker, frame in df.items():\n",
        "    print(f\"Добавление технических индикаторов для {ticker}...\")\n",
        "    \n",
        "    try:\n",
        "        df0 = frame.copy().set_index('timestamp')\n",
        "\n",
        "        # 1) Скользящие средние\n",
        "        df0['SMA_14'] = df0['close'].rolling(14).mean()\n",
        "        df0['SMA_50'] = df0['close'].rolling(50).mean()\n",
        "        df0['EMA_14'] = ta.trend.EMAIndicator(df0['close'], window=14).ema_indicator()\n",
        "        df0['EMA_50'] = ta.trend.EMAIndicator(df0['close'], window=50).ema_indicator()\n",
        "\n",
        "        # 2) Momentum, ROC\n",
        "        df0['Momentum_10'] = ta.momentum.ROCIndicator(df0['close'], window=10).roc()\n",
        "        df0['Momentum_20'] = ta.momentum.ROCIndicator(df0['close'], window=20).roc()\n",
        "\n",
        "        # 3) RSI, MFI\n",
        "        df0['RSI_14'] = ta.momentum.RSIIndicator(df0['close'], window=14).rsi()\n",
        "        df0['MFI_14'] = ta.volume.MFIIndicator(\n",
        "            df0['high'], df0['low'], df0['close'], df0['volume'], window=14\n",
        "        ).money_flow_index()\n",
        "\n",
        "        # 4) Stochastic %K/%D, Williams %R\n",
        "        stoch = ta.momentum.StochasticOscillator(\n",
        "            df0['high'], df0['low'], df0['close'], window=14, smooth_window=3\n",
        "        )\n",
        "        df0['Stoch_%K'] = stoch.stoch()\n",
        "        df0['Stoch_%D'] = stoch.stoch_signal()\n",
        "        df0['Williams_%R'] = ta.momentum.WilliamsRIndicator(\n",
        "            df0['high'], df0['low'], df0['close'], lbp=14\n",
        "        ).williams_r()\n",
        "\n",
        "        # 5) CCI, ADX/ADXR\n",
        "        df0['CCI_20'] = ta.trend.CCIIndicator(\n",
        "            df0['high'], df0['low'], df0['close'], window=20\n",
        "        ).cci()\n",
        "        adx = ta.trend.ADXIndicator(\n",
        "            df0['high'], df0['low'], df0['close'], window=14\n",
        "        )\n",
        "        df0['ADX_14']  = adx.adx()\n",
        "        df0['ADXR_14'] = df0['ADX_14'].rolling(window=14).mean()\n",
        "\n",
        "        # 6) MACD\n",
        "        macd = ta.trend.MACD(df0['close'])\n",
        "        df0['MACD']        = macd.macd()\n",
        "        df0['MACD_signal'] = macd.macd_signal()\n",
        "        df0['MACD_diff']   = macd.macd_diff()\n",
        "\n",
        "        # 7) Bollinger Bands\n",
        "        bb = ta.volatility.BollingerBands(df0['close'], window=20, window_dev=2)\n",
        "        df0['BB_hband'] = bb.bollinger_hband()\n",
        "        df0['BB_lband'] = bb.bollinger_lband()\n",
        "        df0['BB_mavg']  = bb.bollinger_mavg()\n",
        "\n",
        "        # 8) ATR, Parabolic SAR\n",
        "        df0['ATR_14'] = ta.volatility.AverageTrueRange(\n",
        "            df0['high'], df0['low'], df0['close'], window=14\n",
        "        ).average_true_range()\n",
        "        df0['PSAR']   = ta.trend.PSARIndicator(\n",
        "            df0['high'], df0['low'], df0['close'], step=0.02, max_step=0.2\n",
        "        ).psar()\n",
        "\n",
        "        # 9) Volume-based: OBV, CMF, VWAP\n",
        "        df0['OBV'] = ta.volume.OnBalanceVolumeIndicator(\n",
        "            df0['close'], df0['volume']\n",
        "        ).on_balance_volume()\n",
        "        df0['CMF_20'] = ta.volume.ChaikinMoneyFlowIndicator(\n",
        "            df0['high'], df0['low'], df0['close'], df0['volume'], window=20\n",
        "        ).chaikin_money_flow()\n",
        "        \n",
        "        # VWAP: (high+low+close)/3 * volume cumulative / volume cumulative\n",
        "        tp = (df0['high'] + df0['low'] + df0['close']) / 3\n",
        "        vwap = (tp * df0['volume']).cumsum() / df0['volume'].cumsum()\n",
        "        df0['VWAP'] = vwap\n",
        "\n",
        "        # сохраняем\n",
        "        df_ext[ticker] = df0\n",
        "        print(f\"  - Успешно добавлены технические индикаторы. Размер: {df0.shape}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"  - Ошибка при добавлении технических индикаторов для {ticker}: {str(e)}\")\n",
        "\n",
        "print(f\"\\nТехнические индикаторы добавлены для {len(df_ext)} тикеров\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Показываем пример результата для одного тикера\n",
        "if 'MOEX' in df_ext:\n",
        "    print(\"Пример данных с техническими индикаторами для MOEX:\")\n",
        "    print(\"\\nКолонки:\")\n",
        "    print(list(df_ext['MOEX'].columns))\n",
        "    print(f\"\\nПоследние 3 строки:\")\n",
        "    print(df_ext['MOEX'].tail(3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Этап 1.1: Добавление графических паттернов (опционально)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Проверяем наличие паттернов в библиотеке ta\n",
        "try:\n",
        "    import ta.others\n",
        "    print(\"Доступные модули ta.others:\")\n",
        "    print(dir(ta.others))\n",
        "    \n",
        "    # Добавляем доступные паттерны если они есть\n",
        "    for ticker, df0 in df_ext.items():\n",
        "        try:\n",
        "            # Проверяем базовые паттерны с доступными данными\n",
        "            # DailyReturn\n",
        "            if hasattr(ta.others, 'DailyReturnIndicator'):\n",
        "                df0['Daily_Return'] = ta.others.DailyReturnIndicator(df0['close']).daily_return()\n",
        "            \n",
        "            # Daily Log Return\n",
        "            if hasattr(ta.others, 'DailyLogReturnIndicator'):\n",
        "                df0['Daily_Log_Return'] = ta.others.DailyLogReturnIndicator(df0['close']).daily_log_return()\n",
        "            \n",
        "            # Cumulative Return\n",
        "            if hasattr(ta.others, 'CumulativeReturnIndicator'):\n",
        "                df0['Cumulative_Return'] = ta.others.CumulativeReturnIndicator(df0['close']).cumulative_return()\n",
        "                \n",
        "            print(f\"Добавлены паттерны для {ticker}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Ошибка добавления паттернов для {ticker}: {str(e)}\")\n",
        "            \n",
        "except Exception as e:\n",
        "    print(f\"Модуль ta.others недоступен или ошибка: {str(e)}\")\n",
        "    \n",
        "    # Альтернативно - создаем собственные простые паттерны\n",
        "    print(\"Создаем собственные простые паттерны...\")\n",
        "    \n",
        "    for ticker, df0 in df_ext.items():\n",
        "        try:\n",
        "            # Простые паттерны на основе ценовых движений\n",
        "            df0['Price_Above_SMA14'] = (df0['close'] > df0['SMA_14']).astype(int)\n",
        "            df0['Price_Above_SMA50'] = (df0['close'] > df0['SMA_50']).astype(int)\n",
        "            df0['SMA14_Above_SMA50'] = (df0['SMA_14'] > df0['SMA_50']).astype(int)\n",
        "            \n",
        "            # Паттерн \"бычий\" и \"медвежий\" тренд\n",
        "            df0['Bullish_Trend'] = ((df0['close'] > df0['SMA_14']) & \n",
        "                                   (df0['SMA_14'] > df0['SMA_50']) & \n",
        "                                   (df0['RSI_14'] > 50)).astype(int)\n",
        "            \n",
        "            df0['Bearish_Trend'] = ((df0['close'] < df0['SMA_14']) & \n",
        "                                   (df0['SMA_14'] < df0['SMA_50']) & \n",
        "                                   (df0['RSI_14'] < 50)).astype(int)\n",
        "            \n",
        "            # Паттерн перекупленности/перепроданности\n",
        "            df0['Overbought'] = (df0['RSI_14'] > 70).astype(int)\n",
        "            df0['Oversold'] = (df0['RSI_14'] < 30).astype(int)\n",
        "            \n",
        "            # Паттерн пробоя Bollinger Bands\n",
        "            df0['BB_Upper_Break'] = (df0['close'] > df0['BB_hband']).astype(int)\n",
        "            df0['BB_Lower_Break'] = (df0['close'] < df0['BB_lband']).astype(int)\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Ошибка создания паттернов для {ticker}: {str(e)}\")\n",
        "    \n",
        "    print(\"Собственные паттерны добавлены\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Этап 2: Извлечение признаков временных рядов с помощью tsfresh\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "WINDOW = 20\n",
        "STEP   = 1\n",
        "fc_params = EfficientFCParameters()\n",
        "\n",
        "print(\"Извлечение признаков временных рядов с помощью tsfresh...\")\n",
        "print(f\"Параметры: окно = {WINDOW}, шаг = {STEP}\")\n",
        "\n",
        "for ticker, df0 in df_ext.items():\n",
        "    print(f\"\\nОбработка {ticker}...\")\n",
        "    \n",
        "    try:\n",
        "        df0 = df0.copy()  # Скользящий DataFrame\n",
        "        n   = len(df0)\n",
        "        \n",
        "        print(f\"  - Исходный размер: {df0.shape}\")\n",
        "\n",
        "        # 1) Собираем 'long' DF для tsfresh на основе цены закрытия\n",
        "        rows = []\n",
        "        for start in range(0, n - WINDOW + 1, STEP):\n",
        "            window = df0['close'].iloc[start:start+WINDOW].values\n",
        "            # для каждого элемента окна — одна строка\n",
        "            for t, val in enumerate(window):\n",
        "                rows.append({'id': start, 'time': t, 'value': float(val)})\n",
        "        \n",
        "        if len(rows) == 0:\n",
        "            print(f\"  - Недостаточно данных для создания окон\")\n",
        "            continue\n",
        "            \n",
        "        df_long = pd.DataFrame(rows)\n",
        "        print(f\"  - Создан long DataFrame: {df_long.shape}\")\n",
        "\n",
        "        # 2) Извлекаем фичи\n",
        "        print(f\"  - Извлечение признаков...\")\n",
        "        features = extract_features(\n",
        "            df_long,\n",
        "            column_id='id',\n",
        "            column_sort='time',\n",
        "            column_value='value',\n",
        "            default_fc_parameters=fc_params,\n",
        "            impute_function=impute,\n",
        "            n_jobs=1  # Используем 1 поток для стабильности\n",
        "        )\n",
        "        print(f\"  - Извлечено признаков: {features.shape}\")\n",
        "        \n",
        "        # features.index == [0,1,2,...] == наши start-позиции\n",
        "\n",
        "        # 3) Преобразуем features → feat_df с индексом timestamps конца окна\n",
        "        #    end positions = start + WINDOW - 1\n",
        "        end_positions = features.index + WINDOW - 1\n",
        "        end_timestamps = df0.index[end_positions]\n",
        "        feat_df = features.copy()\n",
        "        feat_df.index = end_timestamps  # теперь индекс = метки времени\n",
        "\n",
        "        # 4) Обрезаем df0 первых WINDOW-1 строк (без признаков)\n",
        "        df0 = df0.iloc[WINDOW-1:].copy()\n",
        "        print(f\"  - Обрезанный DataFrame: {df0.shape}\")\n",
        "\n",
        "        # 5) Конкатенируем df0 и feat_df по времени\n",
        "        df_combined = pd.concat([df0, feat_df], axis=1)\n",
        "        df_ext[ticker] = df_combined\n",
        "        \n",
        "        print(f\"  - Финальный размер: {df_combined.shape}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"  - Ошибка при извлечении признаков для {ticker}: {str(e)}\")\n",
        "        # В случае ошибки оставляем исходные данные\n",
        "        continue\n",
        "\n",
        "print(f\"\\nИзвлечение признаков tsfresh завершено\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Показываем пример результата после добавления tsfresh признаков\n",
        "if 'MOEX' in df_ext:\n",
        "    print(\"Пример данных после добавления tsfresh признаков для MOEX:\")\n",
        "    print(f\"Размер данных: {df_ext['MOEX'].shape}\")\n",
        "    print(f\"Количество столбцов: {len(df_ext['MOEX'].columns)}\")\n",
        "    \n",
        "    # Показываем несколько новых столбцов tsfresh\n",
        "    tsfresh_columns = [col for col in df_ext['MOEX'].columns if 'value__' in col]\n",
        "    print(f\"\\nПримеры tsfresh столбцов ({len(tsfresh_columns)} всего):\")\n",
        "    for i, col in enumerate(tsfresh_columns[:10]):  # Показываем первые 10\n",
        "        print(f\"  {i+1}. {col}\")\n",
        "    if len(tsfresh_columns) > 10:\n",
        "        print(f\"  ... и еще {len(tsfresh_columns) - 10} столбцов\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Этап 3: Применение PCA для сжатия размерности\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def apply_pca_to_features(df, variance_threshold=0.95):\n",
        "    \"\"\"\n",
        "    Применяет PCA к численным признакам DataFrame\n",
        "    \n",
        "    Args:\n",
        "        df: DataFrame с признаками\n",
        "        variance_threshold: Порог для объясненной дисперсии (по умолчанию 95%)\n",
        "    \n",
        "    Returns:\n",
        "        df_with_pca: DataFrame с добавленными PCA компонентами\n",
        "        pca: обученная модель PCA\n",
        "        scaler: обученный scaler\n",
        "    \"\"\"\n",
        "    \n",
        "    # Определяем основные колонки которые не будем использовать для PCA\n",
        "    base_columns = ['open', 'close', 'high', 'low', 'volume', 'anomaly', 'method', 'date', \n",
        "                   'kernai_daily_avg', 'gigachat_daily_avg', 'deepseek_daily_avg', \n",
        "                   'weighted_score_base', 'weighted_score_with_decay', 'daily_headlines', 'return']\n",
        "    \n",
        "    # Находим колонки для PCA (числовые колонки, исключая базовые)\n",
        "    numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    pca_columns = [col for col in numeric_columns if col not in base_columns]\n",
        "    \n",
        "    print(f\"  - Всего числовых колонок: {len(numeric_columns)}\")\n",
        "    print(f\"  - Базовых колонок исключено: {len(base_columns)}\")\n",
        "    print(f\"  - Колонок для PCA: {len(pca_columns)}\")\n",
        "    \n",
        "    if len(pca_columns) == 0:\n",
        "        print(\"  - Нет колонок для PCA\")\n",
        "        return df, None, None\n",
        "    \n",
        "    # Извлекаем данные для PCA\n",
        "    pca_data = df[pca_columns].copy()\n",
        "    \n",
        "    # Удаляем строки с NaN\n",
        "    pca_data_clean = pca_data.dropna()\n",
        "    valid_indices = pca_data_clean.index\n",
        "    \n",
        "    print(f\"  - Строк с данными для PCA: {len(pca_data_clean)}\")\n",
        "    \n",
        "    if len(pca_data_clean) == 0:\n",
        "        print(\"  - Нет данных для PCA после удаления NaN\")\n",
        "        return df, None, None\n",
        "    \n",
        "    # Стандартизация\n",
        "    scaler = StandardScaler()\n",
        "    pca_data_scaled = scaler.fit_transform(pca_data_clean)\n",
        "    \n",
        "    # Определяем оптимальное количество компонент\n",
        "    pca_full = PCA()\n",
        "    pca_full.fit(pca_data_scaled)\n",
        "    \n",
        "    # Находим количество компонент для заданного порога дисперсии\n",
        "    cumsum_var = np.cumsum(pca_full.explained_variance_ratio_)\n",
        "    n_components = np.argmax(cumsum_var >= variance_threshold) + 1\n",
        "    \n",
        "    print(f\"  - Компонент для {variance_threshold*100}% дисперсии: {n_components}\")\n",
        "    print(f\"  - Фактическая объясненная дисперсия: {cumsum_var[n_components-1]:.4f}\")\n",
        "    \n",
        "    # Применяем PCA с оптимальным количеством компонент\n",
        "    pca = PCA(n_components=n_components)\n",
        "    pca_result = pca.fit_transform(pca_data_scaled)\\n    \\n    # Создаем DataFrame с PCA компонентами\\n    pca_df = pd.DataFrame(\\n        pca_result,\\n        index=valid_indices,\\n        columns=[f'PCA_{i+1}' for i in range(n_components)]\\n    )\\n    \\n    # Объединяем с исходным DataFrame\\n    df_with_pca = df.copy()\\n    df_with_pca = pd.concat([df_with_pca, pca_df], axis=1)\\n    \\n    return df_with_pca, pca, scaler\\n\\nprint(\\\"Применение PCA к расширенным данным...\\\")\\n\\ndf_final = {}\\npca_info = {}\\n\\nfor ticker, df0 in df_ext.items():\\n    print(f\\\"\\\\nПрименение PCA для {ticker}...\\\")\\n    \\n    try:\\n        df_with_pca, pca_model, scaler_model = apply_pca_to_features(df0)\\n        \\n        df_final[ticker] = df_with_pca\\n        pca_info[ticker] = {\\n            'pca': pca_model,\\n            'scaler': scaler_model,\\n            'n_components': pca_model.n_components_ if pca_model else 0,\\n            'explained_variance_ratio': pca_model.explained_variance_ratio_ if pca_model else None\\n        }\\n        \\n        print(f\\\"  - Финальный размер: {df_with_pca.shape}\\\")\\n        \\n    except Exception as e:\\n        print(f\\\"  - Ошибка при применении PCA для {ticker}: {str(e)}\\\")\\n        df_final[ticker] = df0  # В случае ошибки сохраняем без PCA\\n        pca_info[ticker] = {'pca': None, 'scaler': None, 'n_components': 0, 'explained_variance_ratio': None}\\n\\nprint(f\\\"\\\\nPCA применено для {len(df_final)} тикеров\\\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Визуализация результатов PCA\n",
        "print(\"\\nИнформация о PCA компонентах:\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "for ticker, info in pca_info.items():\n",
        "    if info['pca'] is not None:\n",
        "        print(f\"\\n{ticker}:\")\n",
        "        print(f\"  - Количество компонент: {info['n_components']}\")\n",
        "        print(f\"  - Объясненная дисперсия по компонентам:\")\n",
        "        for i, var in enumerate(info['explained_variance_ratio'][:5]):  # Показываем первые 5\n",
        "            print(f\"    PCA_{i+1}: {var:.4f}\")\n",
        "        if len(info['explained_variance_ratio']) > 5:\n",
        "            print(f\"    ... еще {len(info['explained_variance_ratio']) - 5} компонент\")\n",
        "\n",
        "# Показываем пример финальных данных\n",
        "if 'MOEX' in df_final:\n",
        "    print(f\"\\n\\nПример финальных данных для MOEX:\")\n",
        "    print(f\"Размер: {df_final['MOEX'].shape}\")\n",
        "    \n",
        "    # Показываем PCA колонки\n",
        "    pca_columns = [col for col in df_final['MOEX'].columns if col.startswith('PCA_')]\n",
        "    print(f\"PCA колонки ({len(pca_columns)}): {pca_columns[:10]}\")\n",
        "    if len(pca_columns) > 10:\n",
        "        print(f\"... еще {len(pca_columns) - 10} PCA колонок\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Этап 4: Сохранение результатов и статистика\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Сохранение многомерных временных рядов\n",
        "print(\"Сохранение многомерных временных рядов...\")\n",
        "\n",
        "saved_files = []\n",
        "processing_stats = []\n",
        "\n",
        "for ticker, df_multivariate in df_final.items():\n",
        "    try:\n",
        "        # Сохраняем данные с временными метками в качестве колонки\n",
        "        df_to_save = df_multivariate.reset_index()\n",
        "        \n",
        "        # Убеждаемся что timestamp в правильном формате\n",
        "        if 'timestamp' not in df_to_save.columns and df_to_save.index.name == 'timestamp':\n",
        "            df_to_save = df_multivariate.reset_index()\n",
        "        \n",
        "        output_file = f\"{OUTPUT_PATH}{ticker}_multivariate.csv\"\n",
        "        df_to_save.to_csv(output_file, index=False)\n",
        "        \n",
        "        saved_files.append(output_file)\n",
        "        \n",
        "        # Собираем статистику\n",
        "        stats = {\n",
        "            'ticker': ticker,\n",
        "            'total_rows': len(df_multivariate),\n",
        "            'total_columns': len(df_multivariate.columns),\n",
        "            'date_start': df_multivariate.index.min() if hasattr(df_multivariate.index, 'min') else 'N/A',\n",
        "            'date_end': df_multivariate.index.max() if hasattr(df_multivariate.index, 'max') else 'N/A',\n",
        "            'pca_components': pca_info.get(ticker, {}).get('n_components', 0),\n",
        "            'technical_indicators': len([col for col in df_multivariate.columns \n",
        "                                       if any(indicator in col for indicator in \n",
        "                                            ['SMA', 'EMA', 'RSI', 'MACD', 'BB_', 'ATR', 'PSAR', 'OBV'])]),\n",
        "            'tsfresh_features': len([col for col in df_multivariate.columns if 'value__' in col]),\n",
        "            'news_features': len([col for col in df_multivariate.columns \n",
        "                                if col in ['kernai_daily_avg', 'gigachat_daily_avg', 'deepseek_daily_avg', \n",
        "                                          'weighted_score_with_decay']]),\n",
        "            'pattern_features': len([col for col in df_multivariate.columns \n",
        "                                   if any(pattern in col for pattern in \n",
        "                                        ['Bullish', 'Bearish', 'Overbought', 'Oversold', 'Break'])])\n",
        "        }\n",
        "        processing_stats.append(stats)\n",
        "        \n",
        "        print(f\"  - {ticker}: сохранено {df_multivariate.shape} в {output_file}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"  - Ошибка сохранения {ticker}: {str(e)}\")\n",
        "\n",
        "print(f\"\\nУспешно сохранено {len(saved_files)} файлов в {OUTPUT_PATH}\")\n",
        "\n",
        "# Создаем DataFrame со статистикой\n",
        "stats_df = pd.DataFrame(processing_stats)\n",
        "\n",
        "# Сохраняем статистику\n",
        "stats_file = f\"{OUTPUT_PATH}multivariate_processing_stats.csv\"\n",
        "stats_df.to_csv(stats_file, index=False)\n",
        "\n",
        "print(f\"Статистика сохранена в {stats_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Выводим детальную статистику\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"СТАТИСТИКА МНОГОМЕРНЫХ ВРЕМЕННЫХ РЯДОВ\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\nОбщая информация:\")\n",
        "print(f\"- Всего обработано тикеров: {len(stats_df)}\")\n",
        "print(f\"- Файлы сохранены в: {OUTPUT_PATH}\")\n",
        "\n",
        "print(f\"\\nДетальная статистика по тикерам:\")\n",
        "print(\"-\"*80)\n",
        "for _, row in stats_df.iterrows():\n",
        "    print(f\"\\n{row['ticker']}:\")\n",
        "    print(f\"  📊 Размер данных: {row['total_rows']} строк × {row['total_columns']} столбцов\")\n",
        "    print(f\"  📅 Период: {row['date_start']} - {row['date_end']}\")\n",
        "    print(f\"  🔧 Технические индикаторы: {row['technical_indicators']}\")\n",
        "    print(f\"  📈 TSFresh признаки: {row['tsfresh_features']}\")\n",
        "    print(f\"  📰 Новостные признаки: {row['news_features']}\")\n",
        "    print(f\"  🎯 Паттерны: {row['pattern_features']}\")\n",
        "    print(f\"  🧮 PCA компоненты: {row['pca_components']}\")\n",
        "\n",
        "# Сводная статистика\n",
        "print(f\"\\n\" + \"=\"*50)\n",
        "print(\"СВОДНАЯ СТАТИСТИКА\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "print(f\"Средние значения по всем тикерам:\")\n",
        "numeric_columns = ['total_rows', 'total_columns', 'technical_indicators', \n",
        "                  'tsfresh_features', 'news_features', 'pattern_features', 'pca_components']\n",
        "\n",
        "for col in numeric_columns:\n",
        "    if col in stats_df.columns:\n",
        "        mean_val = stats_df[col].mean()\n",
        "        min_val = stats_df[col].min() \n",
        "        max_val = stats_df[col].max()\n",
        "        print(f\"  {col}: среднее={mean_val:.1f}, мин={min_val}, макс={max_val}\")\n",
        "\n",
        "print(f\"\\nИтоговая сводная таблица:\")\n",
        "print(stats_df[['ticker', 'total_rows', 'total_columns', 'pca_components']].to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Визуализация распределения признаков\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# График 1: Количество столбцов по тикерам\n",
        "axes[0, 0].bar(stats_df['ticker'], stats_df['total_columns'], color='skyblue')\n",
        "axes[0, 0].set_title('Общее количество столбцов по тикерам')\n",
        "axes[0, 0].set_ylabel('Количество столбцов')\n",
        "axes[0, 0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# График 2: PCA компоненты\n",
        "axes[0, 1].bar(stats_df['ticker'], stats_df['pca_components'], color='lightgreen')\n",
        "axes[0, 1].set_title('Количество PCA компонент по тикерам')\n",
        "axes[0, 1].set_ylabel('PCA компоненты')\n",
        "axes[0, 1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# График 3: Технические индикаторы\n",
        "axes[1, 0].bar(stats_df['ticker'], stats_df['technical_indicators'], color='orange')\n",
        "axes[1, 0].set_title('Технические индикаторы по тикерам')\n",
        "axes[1, 0].set_ylabel('Количество индикаторов')\n",
        "axes[1, 0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# График 4: TSFresh признаки\n",
        "axes[1, 1].bar(stats_df['ticker'], stats_df['tsfresh_features'], color='coral')\n",
        "axes[1, 1].set_title('TSFresh признаки по тикерам')\n",
        "axes[1, 1].set_ylabel('Количество признаков')\n",
        "axes[1, 1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Заключение\n",
        "\n",
        "В этом ноутбуке была выполнена комплексная инженерия признаков для создания многомерных временных рядов:\n",
        "\n",
        "### Выполненные этапы:\n",
        "\n",
        "1. **Технические индикаторы** - добавлено ~25 технических индикаторов:\n",
        "   - Скользящие средние (SMA, EMA)\n",
        "   - Осцилляторы (RSI, Stochastic, Williams %R)\n",
        "   - Трендовые индикаторы (MACD, ADX, CCI)\n",
        "   - Волатильность (Bollinger Bands, ATR)\n",
        "   - Объемные индикаторы (OBV, CMF, VWAP)\n",
        "\n",
        "2. **Графические паттерны** - созданы индикаторы паттернов:\n",
        "   - Бычьи/медвежьи тренды\n",
        "   - Перекупленность/перепроданность\n",
        "   - Пробои Bollinger Bands\n",
        "\n",
        "3. **TSFresh признаки** - извлечены статистические характеристики временных рядов:\n",
        "   - Использовано скользящее окно размером 20\n",
        "   - Применены эффективные параметры для скорости обработки\n",
        "\n",
        "4. **PCA сжатие** - применено сжатие размерности:\n",
        "   - Автоматическое определение количества компонент (95% дисперсии)\n",
        "   - Стандартизация данных перед PCA\n",
        "   - Сохранение базовых колонок без сжатия\n",
        "\n",
        "5. **Результаты**:\n",
        "   - Данные сохранены в папку `data/multivariate_series/`\n",
        "   - Создана детальная статистика по каждому тикеру\n",
        "   - Визуализация распределения признаков\n",
        "\n",
        "### Преимущества созданных данных:\n",
        "- **Богатое представление** временных рядов с множественными признаками\n",
        "- **Сжатое пространство** для эффективного машинного обучения\n",
        "- **Сохранение интерпретируемости** через базовые признаки\n",
        "- **Готовность для моделирования** различными алгоритмами\n",
        "\n",
        "Полученные многомерные временные ряды готовы для использования в задачах прогнозирования, классификации аномалий и других задач машинного обучения.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
