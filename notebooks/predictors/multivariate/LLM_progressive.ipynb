{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Прогрессивный анализ влияния признаков на качество прогнозирования\n",
    "\n",
    "Этот ноутбук предназначен для анализа того, как поэтапное добавление различных типов признаков влияет на качество прогнозирования временных рядов c помощью LLM.\n",
    "\n",
    "## Этапы анализа:\n",
    "1. **Базовая модель** - обучение только на ряду `close` (univariate)\n",
    "2. **+ Аномалии** - добавление колонки аномалий\n",
    "3. **+ Новости** - добавление взвешенной оценки новостей  \n",
    "4. **+ Паттерны свечей** - добавление паттернов японских свечей\n",
    "5. **+ Технические индикаторы** - добавление технических индикаторов\n",
    "6. **+ TSFresh признаки** - добавление статистических свойств временных рядов\n",
    "7. **+ PCA компоненты** - добавление сжатых признаков\n",
    "\n",
    "## Метрики оценки:\n",
    "- **RMSE** - среднеквадратичная ошибка\n",
    "- **MAPE** - средняя абсолютная процентная ошибка  \n",
    "- **DA** - точность направления (Directional Accuracy)\n",
    "\n",
    "## Модель:\n",
    "- **ChatGPT-4o-mini** из OPENROUTER \n",
    "- **Горизонт прогноза**: последние 20 дней\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Путь к pip в активном ядре\n",
    "pip_path = os.path.join(sys.prefix, \"bin\", \"pip\")\n",
    "\n",
    "subprocess.check_call([pip_path, \"install\", \"requests\", \"langchain\", \"langchain-gigachat\", \"matplotlib\", \"scikit-learn\", \"pandas\", \"numpy\", \"seaborn\", \"gigachat\", \"openai\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Библиотеки загружены успешно\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from langchain_gigachat import GigaChat\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "\n",
    "import requests\n",
    "import re\n",
    "import json\n",
    "\n",
    "# Библиотеки для анализа\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Настройка отображения\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(\"Библиотеки загружены успешно\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Конфигурация API ключей\n",
    "API_KEYS = {\n",
    "    'openrouter': \"\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Параметры анализа:\n",
      "- Входные данные: ../../data/multivariate_series/\n",
      "- Результаты: ./progressive_analysis/\n",
      "- Горизонт прогноза: 10 дней\n",
      "- Размер тестовой выборки: 11 дней\n",
      "- Тикеры для анализа: ['AFLT', 'LKOH', 'MOEX', 'NVTK', 'PIKK', 'SBER', 'VKCO', 'VTBR', 'X5', 'YDEX']\n",
      "Загружен AFLT: (2415, 918)\n",
      "Загружен LKOH: (2415, 915)\n",
      "Загружен MOEX: (2415, 918)\n",
      "Загружен NVTK: (2415, 916)\n",
      "Загружен PIKK: (2415, 911)\n",
      "Загружен SBER: (2415, 909)\n",
      "Загружен VKCO: (1241, 910)\n",
      "Загружен VTBR: (1764, 905)\n",
      "Загружен X5: (1547, 913)\n",
      "Загружен YDEX: (2415, 918)\n",
      "\n",
      "Успешно загружено 10 тикеров\n"
     ]
    }
   ],
   "source": [
    "# Пути к данным\n",
    "INPUT_PATH = '../../data/multivariate_series/'\n",
    "OUTPUT_PATH = './progressive_analysis/'\n",
    "\n",
    "# Создаем выходную папку если её нет\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "# Список тикеров\n",
    "tickers = ['AFLT', 'LKOH', 'MOEX', 'NVTK', 'PIKK', 'SBER', 'VKCO', 'VTBR', 'X5', 'YDEX']\n",
    "\n",
    "# Параметры анализа\n",
    "FORECAST_HORIZON = 10  # Количество дней для прогноза\n",
    "TEST_SIZE = 11         # Размер тестовой выборки (больше чем горизонт прогноза)\n",
    "\n",
    "print(f\"Параметры анализа:\")\n",
    "print(f\"- Входные данные: {INPUT_PATH}\")\n",
    "print(f\"- Результаты: {OUTPUT_PATH}\")\n",
    "print(f\"- Горизонт прогноза: {FORECAST_HORIZON} дней\")\n",
    "print(f\"- Размер тестовой выборки: {TEST_SIZE} дней\")\n",
    "print(f\"- Тикеры для анализа: {tickers}\")\n",
    "\n",
    "# Загружаем данные\n",
    "data = {}\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        file_path = f\"{INPUT_PATH}{ticker}_multivariate.csv\"\n",
    "        # 1) Читаем CSV, парсим timestamp\n",
    "        df = pd.read_csv(file_path, parse_dates=['timestamp'])\n",
    "        # 2) Убираем timezone (делаем tz-naive)\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'], utc=True).dt.tz_localize(None)\n",
    "        # 3) Индексируем и сортируем\n",
    "        df = df.set_index('timestamp').sort_index()\n",
    "        # 4) Рейнжируем по реальным бизнес-дням\n",
    "        bd_index = pd.date_range(df.index.min(), df.index.max(), freq='B')\n",
    "        df = df.reindex(bd_index)\n",
    "        # 5) Заполняем пропуски for all columns\n",
    "        df = df.ffill().bfill()\n",
    "        # 6) Переименовываем индекс\n",
    "        df.index.name = 'timestamp'\n",
    "        \n",
    "        data[ticker] = df\n",
    "        print(f\"Загружен {ticker}: {df.shape}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка загрузки {ticker}: {e}\")\n",
    "\n",
    "print(f\"\\nУспешно загружено {len(data)} тикеров\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вспомогательные функции\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_directional_accuracy(actual, predicted):\n",
    "    \"\"\"\n",
    "    Вычисляет точность направления (Directional Accuracy)\n",
    "    \n",
    "    Args:\n",
    "        actual: фактические значения\n",
    "        predicted: прогнозируемые значения\n",
    "    \n",
    "    Returns:\n",
    "        DA: точность направления (от 0 до 1)\n",
    "    \"\"\"\n",
    "    if len(actual) <= 1 or len(predicted) <= 1:\n",
    "        return np.nan\n",
    "    \n",
    "    # Направление изменения фактических значений\n",
    "    actual_direction = np.diff(actual) > 0\n",
    "    \n",
    "    # Направление изменения прогнозов\n",
    "    predicted_direction = np.diff(predicted) > 0\n",
    "    \n",
    "    # Точность направления\n",
    "    da = np.mean(actual_direction == predicted_direction)\n",
    "    \n",
    "    return da\n",
    "\n",
    "def prepare_features_for_stage(df, stage):\n",
    "    \"\"\"\n",
    "    Подготавливает признаки для определенного этапа анализа\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame с данными\n",
    "        stage: номер этапа (1-7)\n",
    "    \n",
    "    Returns:\n",
    "        feature_columns: список колонок для использования\n",
    "    \"\"\"\n",
    "    \n",
    "    # Базовые колонки (всегда исключаем)\n",
    "    base_exclude = ['date', 'daily_headlines', 'return']\n",
    "    \n",
    "    if stage == 1:\n",
    "        # Этап 1: только close (univariate)\n",
    "        return ['close']\n",
    "    \n",
    "    elif stage == 2:\n",
    "        # Этап 2: + аномалии\n",
    "        features = ['close', 'anomaly']\n",
    "        return features\n",
    "    \n",
    "    elif stage == 3:\n",
    "        # Этап 3: + новости оценкой\n",
    "        features = ['close', 'anomaly', 'weighted_score_with_decay']\n",
    "        return features\n",
    "\n",
    "    elif stage == 4:\n",
    "        # Этап 4: + новости текстом\n",
    "        features = ['close', 'anomaly', 'daily_headlines']\n",
    "        return features\n",
    "    \n",
    "    \n",
    "    elif stage == 5:\n",
    "        # Этап 5: + паттерны свечей\n",
    "        features = ['close', 'anomaly', 'weighted_score_with_decay']\n",
    "\n",
    "        # Добавляем свечи\n",
    "        candels_cols = [col for col in df.columns if col in ['open', 'high', 'low', 'volume']]\n",
    "        features.extend(candels_cols)\n",
    "\n",
    "        return features\n",
    "    \n",
    "    elif stage == 6:\n",
    "        # Этап 6: + технические индикаторы\n",
    "        features = ['close', 'anomaly', 'weighted_score_with_decay']\n",
    "\n",
    "        # Добавляем свечи\n",
    "        candels_cols = [col for col in df.columns if col in ['open', 'high', 'low', 'volume']]\n",
    "        features.extend(candels_cols)\n",
    "        \n",
    "        # Добавляем технические индикаторы\n",
    "        tech_indicators = ['return', 'SMA_14', 'SMA_50', 'EMA_14', 'EMA_50', 'RSI_14', 'MACD', 'MACD_signal', \n",
    "                          'BB_hband', 'BB_lband', 'ATR_14', 'OBV', 'VWAP']\n",
    "        tech_cols = [col for col in df.columns if any(indicator in col for indicator in tech_indicators)]\n",
    "        features.extend(tech_cols)\n",
    "        return features\n",
    "    \n",
    "    elif stage == 7:\n",
    "        # Этап 7: + TSFresh признаки\n",
    "        features = ['close', 'anomaly', 'weighted_score_with_decay']\n",
    "\n",
    "        # Добавляем свечи\n",
    "        candels_cols = [col for col in df.columns if col in ['open', 'high', 'low', 'volume']]\n",
    "        features.extend(candels_cols)\n",
    "        \n",
    "        tech_indicators = ['returb', 'SMA_14', 'SMA_50', 'EMA_14', 'EMA_50', 'RSI_14', 'MACD', 'MACD_signal', \n",
    "                          'BB_hband', 'BB_lband', 'ATR_14', 'OBV', 'VWAP']\n",
    "        tech_cols = [col for col in df.columns if any(indicator in col for indicator in tech_indicators)]\n",
    "        features.extend(tech_cols)\n",
    "\n",
    "        # Добавляем TSFresh признаки\n",
    "        tsfresh_cols = ['value__cwt_coefficients__coeff_14__w10_withs_(2, 5, 10, 20)', 'value__minimun', 'value__maximin', 'value__mean']\n",
    "        features.extend(tsfresh_cols)\n",
    "        return features\n",
    "\n",
    "    elif stage == 8:\n",
    "        # Этап 8: + Картинка\n",
    "        features = ['close', 'anomaly', 'weighted_score_with_decay']\n",
    "\n",
    "        # Добавляем свечи\n",
    "        candels_cols = [col for col in df.columns if col in ['open', 'high', 'low', 'volume']]\n",
    "        features.extend(candels_cols)\n",
    "        \n",
    "        tech_indicators = ['return', 'SMA_14', 'SMA_50', 'EMA_14', 'EMA_50', 'RSI_14', 'MACD', 'MACD_signal', \n",
    "                          'BB_hband', 'BB_lband', 'ATR_14', 'OBV', 'VWAP']\n",
    "        tech_cols = [col for col in df.columns if any(indicator in col for indicator in tech_indicators)]\n",
    "        features.extend(tech_cols)\n",
    "\n",
    "        # Добавляем TSFresh признаки\n",
    "        tsfresh_cols = [col for col in df.columns if 'value__' in col]\n",
    "        features.extend(tsfresh_cols)\n",
    "\n",
    "        #TODO: Картинка в base64 (график + отображение тех.индикаторов, как для тредера)\n",
    "        return features\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Неподдерживаемый этап: {stage}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вспомогательные функции для работы с патчами определены!\n"
     ]
    }
   ],
   "source": [
    "def compute_patch_stats(patch):\n",
    "    \"\"\"Вычисление статистик для патча временного ряда\"\"\"\n",
    "    ex = float(np.mean(patch))\n",
    "    dx = float(np.std(patch))\n",
    "    try:\n",
    "        mode_val = float(statistics.mode([round(x, 2) for x in patch]))\n",
    "    except statistics.StatisticsError:\n",
    "        mode_val = None\n",
    "    pct = (patch[-1] - patch[0]) / patch[0] * 100 if patch[0] != 0 else 0\n",
    "    return ex, dx, mode_val, pct\n",
    "\n",
    "def make_patch_messages(window_data, stage, patch_size=5):\n",
    "    \"\"\"\n",
    "    Разбить временное окно на неперекрывающиеся патчи patch_size\n",
    "    и вернуть list system-сообщений по каждому патчу.\n",
    "    \"\"\"\n",
    "    msgs = []\n",
    "    \n",
    "    # Получаем признаки для данного этапа\n",
    "    features = prepare_features_for_stage(window_data, stage)\n",
    "    available_features = [f for f in features if f in window_data.columns]\n",
    "    \n",
    "    n_patches = len(window_data) // patch_size\n",
    "    if n_patches == 0:\n",
    "        n_patches = 1\n",
    "        patch_size = len(window_data)\n",
    "    \n",
    "    for i in range(n_patches):\n",
    "        start_idx = i * patch_size\n",
    "        end_idx = min((i + 1) * patch_size, len(window_data))\n",
    "        patch_data = window_data.iloc[start_idx:end_idx]\n",
    "        \n",
    "        # Формируем характеристики патча для разных этапов\n",
    "        characteristics = []\n",
    "        \n",
    "        # Всегда добавляем цены\n",
    "        if 'close' in available_features:\n",
    "            prices = [f\"{val:.2f}\" for val in patch_data['close'].values]\n",
    "            characteristics.append(f\"Prices: {', '.join(prices)}\")\n",
    "        \n",
    "        if stage >= 2 and 'anomaly' in available_features:\n",
    "            # Этап 2+: добавляем аномалии\n",
    "            anomalies = [str(int(val)) if not pd.isna(val) else \"0\" for val in patch_data['anomaly'].values]\n",
    "            characteristics.append(f\"Anomaly (0-no, 1-yes): {', '.join(anomalies)}\")\n",
    "        \n",
    "        if stage >= 3 and 'weighted_score_with_decay' in available_features:\n",
    "            # Этап 3+: добавляем новостную оценку\n",
    "            scores = [f\"{val*100:.0f}\" if not pd.isna(val) else \"0\" for val in patch_data['weighted_score_with_decay'].values]\n",
    "            characteristics.append(f\"News sentiment (-100 to +100): {', '.join(scores)}\")\n",
    "        \n",
    "        if stage >= 4 and 'daily_headlines' in available_features:\n",
    "            # Этап 4+: добавляем заголовки новостей (только последний в патче)\n",
    "            headlines = patch_data['daily_headlines'].dropna()\n",
    "            if len(headlines) > 0:\n",
    "                last_headline = str(headlines.iloc[-1])[:100] + (\"...\" if len(str(headlines.iloc[-1])) > 100 else \"\")\n",
    "                characteristics.append(f\"Latest news: {last_headline}\")\n",
    "        \n",
    "        if stage >= 5:\n",
    "            # Этап 5+: добавляем OHLV данные\n",
    "            if 'open' in available_features:\n",
    "                opens = [f\"{val:.2f}\" for val in patch_data['open'].values]\n",
    "                characteristics.append(f\"Open prices: {', '.join(opens)}\")\n",
    "            \n",
    "            if 'high' in available_features:\n",
    "                highs = [f\"{val:.2f}\" for val in patch_data['high'].values]\n",
    "                characteristics.append(f\"High prices: {', '.join(highs)}\")\n",
    "            \n",
    "            if 'low' in available_features:\n",
    "                lows = [f\"{val:.2f}\" for val in patch_data['low'].values]\n",
    "                characteristics.append(f\"Low prices: {', '.join(lows)}\")\n",
    "            \n",
    "            if 'volume' in available_features:\n",
    "                volumes = [f\"{val:.0f}\" if not pd.isna(val) else \"0\" for val in patch_data['volume'].values]\n",
    "                characteristics.append(f\"Volumes: {', '.join(volumes)}\")\n",
    "        \n",
    "        if stage >= 6:\n",
    "            # Этап 6+: добавляем технические индикаторы (выборочно, чтобы не перегружать)\n",
    "            if 'RSI_14' in available_features:\n",
    "                rsi_vals = [f\"{val:.1f}\" if not pd.isna(val) else \"50\" for val in patch_data['RSI_14'].values]\n",
    "                characteristics.append(f\"RSI: {', '.join(rsi_vals)}\")\n",
    "            \n",
    "            if 'MACD' in available_features:\n",
    "                macd_vals = [f\"{val:.3f}\" if not pd.isna(val) else \"0\" for val in patch_data['MACD'].values]\n",
    "                characteristics.append(f\"MACD: {', '.join(macd_vals)}\")\n",
    "            \n",
    "            if 'return' in available_features:\n",
    "                returns = [f\"{val*100:.1f}%\" if not pd.isna(val) else \"0%\" for val in patch_data['return'].values]\n",
    "                characteristics.append(f\"Returns: {', '.join(returns)}\")\n",
    "        \n",
    "        if stage >= 7:\n",
    "            # Этап 7+: добавляем статистические признаки (выборочно)\n",
    "            tsfresh_features = [col for col in available_features if 'value__' in col]\n",
    "            if tsfresh_features:\n",
    "                # Берем первый доступный TSFresh признак\n",
    "                feature = tsfresh_features[0]\n",
    "                vals = [f\"{val:.3f}\" if not pd.isna(val) else \"0\" for val in patch_data[feature].values]\n",
    "                feature_name = feature.replace('value__', '').replace('_', ' ')[:20]\n",
    "                characteristics.append(f\"Stat feature: {', '.join(vals)}\")\n",
    "        \n",
    "        # Собираем все характеристики в одно сообщение\n",
    "        content = f\"Patch {i+1}: \" + \" | \".join(characteristics)\n",
    "        \n",
    "        msgs.append({\"role\": \"system\", \"content\": content})\n",
    "    \n",
    "    return msgs\n",
    "\n",
    "def parse_llm_response(response_text):\n",
    "    \"\"\"Извлечение числового значения из ответа LLM\"\"\"\n",
    "    try:\n",
    "        # Поиск первого числа в тексте\n",
    "        match = re.search(r\"[-+]?\\d*\\.?\\d+\", str(response_text).strip())\n",
    "        if match:\n",
    "            return float(match.group(0))\n",
    "        else:\n",
    "            return np.nan\n",
    "    except (ValueError, AttributeError):\n",
    "        return np.nan\n",
    "\n",
    "print(\"Вспомогательные функции для работы с патчами определены!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Класс OpenRouterLLMPredictor определен!\n"
     ]
    }
   ],
   "source": [
    "class OpenRouterLLMPredictor:\n",
    "    \"\"\"Класс для прогнозирования через OpenRouter API\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key, model_name=\"openai/gpt-4o-mini\", max_retries=3, drop_threshold=0.20):\n",
    "        self.api_key = api_key\n",
    "        self.model_name = model_name\n",
    "        self.api_url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "        self.headers = {\n",
    "            \"Authorization\": f\"Bearer {api_key}\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"HTTP-Referer\": \"https://github.com/\", \n",
    "            \"X-Title\": \"Financial Time Series Forecasting\"\n",
    "        }\n",
    "        self.max_retries = max_retries\n",
    "        self.drop_threshold = drop_threshold\n",
    "    \n",
    "    def predict(self, window_data, stage, window_size=10):\n",
    "        \"\"\"Прогноз следующего значения на основе временного окна\"\"\"\n",
    "        \n",
    "        # Создаем промпт\n",
    "        prompt = create_llm_prompt(window_data, stage, window_size)\n",
    "        if prompt is None:\n",
    "            return np.nan\n",
    "        \n",
    "        prev_price = window_data['close'].iloc[-1]\n",
    "        attempt = 0\n",
    "        \n",
    "        while attempt < self.max_retries:\n",
    "            attempt += 1\n",
    "            \n",
    "            try:\n",
    "                # Формируем сообщения\n",
    "                messages = [\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": (\n",
    "                            \"You are a financial time series forecaster. \"\n",
    "                            \"When asked to predict, return exactly one numeric value \"\n",
    "                            \"and nothing else—no explanations, no units, no commentary.\"\n",
    "                        )\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": prompt\n",
    "                    }\n",
    "                ]\n",
    "                \n",
    "                # Если не первая попытка - добавляем контекст о проблеме\n",
    "                if attempt > 1:\n",
    "                    messages.insert(1, {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": (\n",
    "                            \"Note: Previous prediction was unrealistic. \"\n",
    "                            \"Please reconsider market trends and provide a more plausible prediction. \"\n",
    "                            \"Return only the next price as a single number.\"\n",
    "                        )\n",
    "                    })\n",
    "                \n",
    "                # Отправляем запрос\n",
    "                response = requests.post(\n",
    "                    self.api_url,\n",
    "                    headers=self.headers,\n",
    "                    json={\n",
    "                        \"model\": self.model_name,\n",
    "                        \"messages\": messages,\n",
    "                        \"max_tokens\": 50,\n",
    "                        \"temperature\": 0.1\n",
    "                    },\n",
    "                    timeout=30\n",
    "                )\n",
    "                response.raise_for_status()\n",
    "                \n",
    "                # Парсим ответ\n",
    "                response_data = response.json()\n",
    "                content = response_data[\"choices\"][0][\"message\"][\"content\"]\n",
    "                pred = parse_llm_response(content)\n",
    "                \n",
    "                # Проверка на аномальные значения\n",
    "                if np.isnan(pred):\n",
    "                    print(f\"    Попытка {attempt}: не удалось извлечь число из '{content}'\")\n",
    "                    if attempt >= self.max_retries:\n",
    "                        return prev_price\n",
    "                    time.sleep(1)\n",
    "                    continue\n",
    "                \n",
    "                # Проверка на сильное занижение/завышение\n",
    "                if pred < prev_price * (1 - self.drop_threshold) or pred > prev_price * (1 + self.drop_threshold):\n",
    "                    print(f\"    Попытка {attempt}: аномальный прогноз {pred:.2f} (предыдущая цена {prev_price:.2f})\")\n",
    "                    if attempt < self.max_retries:\n",
    "                        time.sleep(1)\n",
    "                        continue\n",
    "                    else:\n",
    "                        # Возвращаем ограниченное значение\n",
    "                        if pred < prev_price * (1 - self.drop_threshold):\n",
    "                            return prev_price * (1 - self.drop_threshold)\n",
    "                        else:\n",
    "                            return prev_price * (1 + self.drop_threshold)\n",
    "                \n",
    "                return pred\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"    Ошибка попытки {attempt}: {e}\")\n",
    "                if attempt >= self.max_retries:\n",
    "                    return prev_price\n",
    "                time.sleep(1)\n",
    "        \n",
    "        return prev_price\n",
    "\n",
    "print(\"Класс OpenRouterLLMPredictor определен!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Функция evaluate_model_for_ticker_llm определена\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model_for_ticker_llm(df, ticker, stage, predictor, window_size=20):\n",
    "    \"\"\"\n",
    "    Оценивает LLM модель для одного тикера на определенном этапе\n",
    "    Использует стратегию \"точка за точкой\" для честного прогнозирования\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame с данными тикера\n",
    "        ticker: название тикера\n",
    "        stage: номер этапа (1-7)\n",
    "        predictor: экземпляр OpenRouterLLMPredictor\n",
    "        window_size: размер окна для обучения\n",
    "    \n",
    "    Returns:\n",
    "        results: словарь с метриками\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Подготавливаем признаки для этапа\n",
    "        feature_columns = prepare_features_for_stage(df, stage)\n",
    "        \n",
    "        # Проверяем наличие всех колонок\n",
    "        available_features = [col for col in feature_columns if col in df.columns]\n",
    "        \n",
    "        if len(available_features) == 0:\n",
    "            print(f\"  - Нет доступных признаков для {ticker} на этапе {stage}\")\n",
    "            return None\n",
    "        \n",
    "        # Удаляем строки с NaN в выбранных признаках (кроме daily_headlines)\n",
    "        numeric_features = [f for f in available_features if f != 'daily_headlines']\n",
    "        df_clean = df[available_features].copy()\n",
    "        \n",
    "        # Заполняем NaN в числовых признаках\n",
    "        for feature in numeric_features:\n",
    "            if feature in df_clean.columns:\n",
    "                df_clean[feature] = df_clean[feature].fillna(method='ffill').fillna(method='bfill')\n",
    "        \n",
    "        if len(df_clean) < TEST_SIZE + window_size:\n",
    "            print(f\"  - Недостаточно данных для {ticker} на этапе {stage}\")\n",
    "            return None\n",
    "        \n",
    "        # Прогнозирование точка за точкой\n",
    "        predictions = []\n",
    "        actual_values = []\n",
    "        \n",
    "        start_idx = len(df_clean) - TEST_SIZE\n",
    "        \n",
    "        for i in range(FORECAST_HORIZON):\n",
    "            current_idx = start_idx + i\n",
    "            \n",
    "            # Формируем окно для обучения\n",
    "            window_start = max(0, current_idx - window_size)\n",
    "            window_data = df_clean.iloc[window_start:current_idx]\n",
    "            \n",
    "            if len(window_data) < 5:  # Минимальное окно\n",
    "                break\n",
    "            \n",
    "            # Делаем прогноз\n",
    "            pred = predictor.predict(window_data, stage, window_size=min(10, len(window_data)))\n",
    "            \n",
    "            # Получаем фактическое значение\n",
    "            if current_idx < len(df_clean):\n",
    "                actual = df_clean.iloc[current_idx]['close']\n",
    "                \n",
    "                predictions.append(pred)\n",
    "                actual_values.append(actual)\n",
    "                \n",
    "                print(f\"    День {i+1}: прогноз={pred:.2f}, факт={actual:.2f}, ошибка={abs(pred-actual)/actual*100:.1f}%\")\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        if len(predictions) == 0:\n",
    "            print(f\"  - Пустые прогнозы для {ticker} на этапе {stage}\")\n",
    "            return None\n",
    "        \n",
    "        # Преобразуем в numpy массивы\n",
    "        predicted_values = np.array(predictions)\n",
    "        actual_values = np.array(actual_values)\n",
    "        \n",
    "        # Убираем NaN значения\n",
    "        valid_mask = ~(np.isnan(predicted_values) | np.isnan(actual_values))\n",
    "        predicted_values = predicted_values[valid_mask]\n",
    "        actual_values = actual_values[valid_mask]\n",
    "        \n",
    "        if len(predicted_values) == 0:\n",
    "            print(f\"  - Нет валидных прогнозов для {ticker} на этапе {stage}\")\n",
    "            return None\n",
    "        \n",
    "        # Вычисляем метрики\n",
    "        rmse_value = np.sqrt(mean_squared_error(actual_values, predicted_values))\n",
    "        mape_value = mean_absolute_percentage_error(actual_values, predicted_values) * 100\n",
    "        da_value = calculate_directional_accuracy(actual_values, predicted_values)\n",
    "        \n",
    "        results = {\n",
    "            'ticker': ticker,\n",
    "            'stage': stage,\n",
    "            'rmse': rmse_value,\n",
    "            'mape': mape_value,\n",
    "            'da': da_value,\n",
    "            'feature_count': len(available_features),\n",
    "            'predictions_count': len(predicted_values)\n",
    "        }\n",
    "        \n",
    "        print(f\"  - {ticker}: RMSE={rmse_value:.4f}, MAPE={mape_value:.2f}%, DA={da_value:.3f}, Features={len(available_features)}, Predictions={len(predicted_values)}\")\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  - Ошибка для {ticker} на этапе {stage}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "print(\"Функция evaluate_model_for_ticker_llm определена\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 ТЕСТИРОВАНИЕ ПАТЧЕЙ\n",
      "==================================================\n",
      "📊 Тикер: SBER, Этап: 1\n",
      "🔧 Доступные признаки: ['close']\n",
      "\\n📝 Пример патчей (размер патча: 5):\n",
      "================================================================================\n",
      "Патч 1:\n",
      "Patch 1: Prices: 292.46, 299.81, 296.50, 297.99, 300.80\n",
      "----------------------------------------\n",
      "Патч 2:\n",
      "Patch 2: Prices: 304.80, 300.01, 308.12, 312.25, 310.00\n",
      "----------------------------------------\n",
      "Патч 3:\n",
      "Patch 3: Prices: 310.16, 316.69, 314.23, 309.41, 307.80\n",
      "----------------------------------------\n",
      "================================================================================\n",
      "\\n--------------------------------------------------------------------------------\\n\n",
      "📊 Тикер: SBER, Этап: 3\n",
      "🔧 Доступные признаки: ['close', 'anomaly', 'weighted_score_with_decay']\n",
      "\\n📝 Пример патчей (размер патча: 5):\n",
      "================================================================================\n",
      "Патч 1:\n",
      "Patch 1: Prices: 292.46, 299.81, 296.50, 297.99, 300.80 | Anomaly (0-no, 1-yes): 0, 0, 0, 0, 0 | News sentiment (-100 to +100): 0, 0, 0, 0, -39\n",
      "----------------------------------------\n",
      "Патч 2:\n",
      "Patch 2: Prices: 304.80, 300.01, 308.12, 312.25, 310.00 | Anomaly (0-no, 1-yes): 0, 0, 0, 0, 0 | News sentiment (-100 to +100): -46, -72, 0, 71, 0\n",
      "----------------------------------------\n",
      "Патч 3:\n",
      "Patch 3: Prices: 310.16, 316.69, 314.23, 309.41, 307.80 | Anomaly (0-no, 1-yes): 0, 0, 0, 0, 0 | News sentiment (-100 to +100): 0, 94, 121, 39, 0\n",
      "----------------------------------------\n",
      "================================================================================\n",
      "\\n--------------------------------------------------------------------------------\\n\n",
      "📊 Тикер: SBER, Этап: 6\n",
      "🔧 Доступные признаки: ['close', 'anomaly', 'weighted_score_with_decay', 'open', 'high', 'low', 'volume', 'return', 'SMA_14', 'SMA_50', 'EMA_14', 'EMA_50', 'RSI_14', 'MACD', 'MACD_signal', 'MACD_diff', 'BB_hband', 'BB_lband', 'ATR_14', 'OBV', 'VWAP']\n",
      "\\n📝 Пример патчей (размер патча: 5):\n",
      "================================================================================\n",
      "Патч 1:\n",
      "Patch 1: Prices: 292.46, 299.81, 296.50, 297.99, 300.80 | Anomaly (0-no, 1-yes): 0, 0, 0, 0, 0 | News sentiment (-100 to +100): 0, 0, 0, 0, -39 | Open prices: 294.09, 293.00, 301.49, 296.51, 298.00 | High prices: 296.75, 300.48, 302.40, 300.45, 303.30 | Low prices: 288.27, 292.80, 295.13, 295.60, 296.06 | Volumes: 6286284, 5041821, 3476895, 2425871, 3010350 | RSI: 42.1, 48.5, 45.7, 47.1, 49.8 | MACD: -6.616, -5.743, -3.902, -3.548, -3.007 | Returns: -0.3%, 2.5%, -1.7%, 0.5%, 0.9%\n",
      "----------------------------------------\n",
      "Патч 2:\n",
      "Patch 2: Prices: 304.80, 300.01, 308.12, 312.25, 310.00 | Anomaly (0-no, 1-yes): 0, 0, 0, 0, 0 | News sentiment (-100 to +100): -46, -72, 0, 71, 0 | Open prices: 300.89, 302.70, 302.67, 308.50, 313.00 | High prices: 305.07, 303.85, 308.70, 315.00, 314.98 | Low prices: 300.41, 296.25, 301.76, 306.55, 305.55 | Volumes: 3757980, 4614792, 5126013, 6448201, 5885119 | RSI: 53.4, 48.9, 55.7, 58.7, 56.5 | MACD: -2.229, -1.977, -1.109, -0.088, 0.534 | Returns: 1.3%, -1.6%, 2.7%, 1.3%, -0.7%\n",
      "----------------------------------------\n",
      "Патч 3:\n",
      "Patch 3: Prices: 310.16, 316.69, 314.23, 309.41, 307.80 | Anomaly (0-no, 1-yes): 0, 0, 0, 0, 0 | News sentiment (-100 to +100): 0, 94, 121, 39, 0 | Open prices: 310.77, 310.85, 318.36, 314.99, 309.28 | High prices: 312.80, 317.87, 320.00, 315.45, 309.95 | Low prices: 309.09, 310.71, 313.52, 308.10, 303.12 | Volumes: 2412000, 5176357, 5231579, 3024999, 4126629 | RSI: 56.6, 61.6, 57.8, 52.4, 50.8 | MACD: 1.028, 1.924, 3.404, 3.076, 2.656 | Returns: 0.1%, 2.1%, -1.2%, -1.5%, -0.5%\n",
      "----------------------------------------\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'Patch 1: Prices: 292.46, 299.81, 296.50, 297.99, 300.80 | Anomaly (0-no, 1-yes): 0, 0, 0, 0, 0 | News sentiment (-100 to +100): 0, 0, 0, 0, -39 | Open prices: 294.09, 293.00, 301.49, 296.51, 298.00 | High prices: 296.75, 300.48, 302.40, 300.45, 303.30 | Low prices: 288.27, 292.80, 295.13, 295.60, 296.06 | Volumes: 6286284, 5041821, 3476895, 2425871, 3010350 | RSI: 42.1, 48.5, 45.7, 47.1, 49.8 | MACD: -6.616, -5.743, -3.902, -3.548, -3.007 | Returns: -0.3%, 2.5%, -1.7%, 0.5%, 0.9%'},\n",
       " {'role': 'system',\n",
       "  'content': 'Patch 2: Prices: 304.80, 300.01, 308.12, 312.25, 310.00 | Anomaly (0-no, 1-yes): 0, 0, 0, 0, 0 | News sentiment (-100 to +100): -46, -72, 0, 71, 0 | Open prices: 300.89, 302.70, 302.67, 308.50, 313.00 | High prices: 305.07, 303.85, 308.70, 315.00, 314.98 | Low prices: 300.41, 296.25, 301.76, 306.55, 305.55 | Volumes: 3757980, 4614792, 5126013, 6448201, 5885119 | RSI: 53.4, 48.9, 55.7, 58.7, 56.5 | MACD: -2.229, -1.977, -1.109, -0.088, 0.534 | Returns: 1.3%, -1.6%, 2.7%, 1.3%, -0.7%'},\n",
       " {'role': 'system',\n",
       "  'content': 'Patch 3: Prices: 310.16, 316.69, 314.23, 309.41, 307.80 | Anomaly (0-no, 1-yes): 0, 0, 0, 0, 0 | News sentiment (-100 to +100): 0, 94, 121, 39, 0 | Open prices: 310.77, 310.85, 318.36, 314.99, 309.28 | High prices: 312.80, 317.87, 320.00, 315.45, 309.95 | Low prices: 309.09, 310.71, 313.52, 308.10, 303.12 | Volumes: 2412000, 5176357, 5231579, 3024999, 4126629 | RSI: 56.6, 61.6, 57.8, 52.4, 50.8 | MACD: 1.028, 1.924, 3.404, 3.076, 2.656 | Returns: 0.1%, 2.1%, -1.2%, -1.5%, -0.5%'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Тестируем патчи для одного тикера\n",
    "def test_patch_example(ticker='SBER', stage=3, patch_size=5):\n",
    "    \"\"\"Показывает пример патчей для отладки\"\"\"\n",
    "    if ticker not in data:\n",
    "        print(f\"Тикер {ticker} не найден\")\n",
    "        return\n",
    "    \n",
    "    df = data[ticker]\n",
    "    feature_columns = prepare_features_for_stage(df, stage)\n",
    "    \n",
    "    # Проверяем наличие всех колонок\n",
    "    available_features = [col for col in feature_columns if col in df.columns]\n",
    "    print(f\"📊 Тикер: {ticker}, Этап: {stage}\")\n",
    "    print(f\"🔧 Доступные признаки: {available_features}\")\n",
    "    \n",
    "    # Удаляем строки с NaN в выбранных признаках (кроме daily_headlines)\n",
    "    numeric_features = [f for f in available_features if f != 'daily_headlines']\n",
    "    df_clean = df[available_features].copy()\n",
    "    \n",
    "    # Заполняем NaN в числовых признаках\n",
    "    for feature in numeric_features:\n",
    "        if feature in df_clean.columns:\n",
    "            df_clean[feature] = df_clean[feature].fillna(method='ffill').fillna(method='bfill')\n",
    "    \n",
    "    # Берем последние 15 дней для примера\n",
    "    window_data = df_clean.tail(15)\n",
    "    \n",
    "    # Создаем патчи\n",
    "    patches = make_patch_messages(window_data, stage, patch_size)\n",
    "    \n",
    "    print(f\"\\\\n📝 Пример патчей (размер патча: {patch_size}):\")\n",
    "    print(\"=\" * 80)\n",
    "    for i, patch in enumerate(patches):\n",
    "        print(f\"Патч {i+1}:\")\n",
    "        print(patch['content'])\n",
    "        print(\"-\" * 40)\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    return patches\n",
    "\n",
    "# Тестируем разные этапы\n",
    "print(\"🧪 ТЕСТИРОВАНИЕ ПАТЧЕЙ\")\n",
    "print(\"=\"*50)\n",
    "test_patch_example('SBER', 1, 5)\n",
    "print(\"\\\\n\" + \"-\"*80 + \"\\\\n\")\n",
    "test_patch_example('SBER', 3, 5)\n",
    "print(\"\\\\n\" + \"-\"*80 + \"\\\\n\")\n",
    "test_patch_example('SBER', 6, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 ТЕСТИРОВАНИЯ ОДИНОЧНОГО ПРОГНОЗА\n",
      "==================================================\n",
      "📊 Тестовый прогноз для SBER, Этап: 1\n",
      "🔧 Доступные признаки: ['close']\n",
      "💰 Предыдущая цена: 309.41\n",
      "💰 Фактическая цена: 307.80\n",
      "📈 Фактическое изменение: -0.52%\n",
      "\\n🤖 Отправляем запрос к LLM...\n",
      "🎯 Прогнозируемая цена: 312.50\n",
      "📊 Прогнозируемое изменение: +1.00%\n",
      "❌ Абсолютная ошибка: 1.53%\n",
      "🧭 Направление: факт=падение, прогноз=рост (❌)\n",
      "\\n--------------------------------------------------\\n\n",
      "📊 Тестовый прогноз для SBER, Этап: 7\n",
      "🔧 Доступные признаки: ['close', 'anomaly', 'weighted_score_with_decay', 'open', 'high', 'low', 'volume', 'SMA_14', 'SMA_50', 'EMA_14', 'EMA_50', 'RSI_14', 'MACD', 'MACD_signal', 'MACD_diff', 'BB_hband', 'BB_lband', 'ATR_14', 'OBV', 'VWAP', 'value__mean']\n",
      "💰 Предыдущая цена: 309.41\n",
      "💰 Фактическая цена: 307.80\n",
      "📈 Фактическое изменение: -0.52%\n",
      "\\n🤖 Отправляем запрос к LLM...\n",
      "🎯 Прогнозируемая цена: 311.50\n",
      "📊 Прогнозируемое изменение: +0.68%\n",
      "❌ Абсолютная ошибка: 1.20%\n",
      "🧭 Направление: факт=падение, прогноз=рост (❌)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "311.5"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Тест одиночного прогноза\n",
    "def test_single_prediction(ticker='SBER', stage=3, patch=3):\n",
    "    \"\"\"Тестирует одиночный прогноз для отладки\"\"\"\n",
    "    if ticker not in data:\n",
    "        print(f\"Тикер {ticker} не найден\")\n",
    "        return\n",
    "    \n",
    "    # Создаем тестовый предиктор\n",
    "    test_predictor = OpenRouterPredictor(\n",
    "        api_key=API_KEYS['openrouter'],\n",
    "        model_name=\"openai/gpt-4o-mini-2024-07-18\",\n",
    "        max_retries=1,\n",
    "        drop_threshold=0.15\n",
    "    )\n",
    "    \n",
    "    df = data[ticker]\n",
    "    feature_columns = prepare_features_for_stage(df, stage)\n",
    "    \n",
    "    # Проверяем наличие всех колонок\n",
    "    available_features = [col for col in feature_columns if col in df.columns]\n",
    "    print(f\"📊 Тестовый прогноз для {ticker}, Этап: {stage}\")\n",
    "    print(f\"🔧 Доступные признаки: {available_features}\")\n",
    "    \n",
    "    # Подготавливаем данные\n",
    "    numeric_features = [f for f in available_features if f != 'daily_headlines']\n",
    "    df_clean = df[available_features].copy()\n",
    "    \n",
    "    # Заполняем NaN в числовых признаках\n",
    "    for feature in numeric_features:\n",
    "        if feature in df_clean.columns:\n",
    "            df_clean[feature] = df_clean[feature].fillna(method='ffill').fillna(method='bfill')\n",
    "    \n",
    "    # Берем окно для прогноза (последние 20 дней, исключая последний день)\n",
    "    window_data = df_clean.iloc[-21:-1]  # 20 дней\n",
    "    actual_price = df_clean.iloc[-1]['close']  # Фактическая цена последнего дня\n",
    "    prev_price = window_data.iloc[-1]['close']  # Цена предыдущего дня\n",
    "    \n",
    "    print(f\"💰 Предыдущая цена: {prev_price:.2f}\")\n",
    "    print(f\"💰 Фактическая цена: {actual_price:.2f}\")\n",
    "    print(f\"📈 Фактическое изменение: {((actual_price - prev_price) / prev_price * 100):+.2f}%\")\n",
    "    \n",
    "    # Делаем прогноз\n",
    "    print(\"\\\\n🤖 Отправляем запрос к LLM...\")\n",
    "    predicted_price = test_predictor.predict(window_data, stage, 1)\n",
    "    \n",
    "    if not np.isnan(predicted_price):\n",
    "        error_pct = abs(predicted_price - actual_price) / actual_price * 100\n",
    "        predicted_change = (predicted_price - prev_price) / prev_price * 100\n",
    "        \n",
    "        print(f\"🎯 Прогнозируемая цена: {predicted_price:.2f}\")\n",
    "        print(f\"📊 Прогнозируемое изменение: {predicted_change:+.2f}%\") \n",
    "        print(f\"❌ Абсолютная ошибка: {error_pct:.2f}%\")\n",
    "        \n",
    "        # Проверка направления\n",
    "        actual_direction = \"рост\" if actual_price > prev_price else \"падение\"\n",
    "        predicted_direction = \"рост\" if predicted_price > prev_price else \"падение\"\n",
    "        direction_correct = actual_direction == predicted_direction\n",
    "        \n",
    "        print(f\"🧭 Направление: факт={actual_direction}, прогноз={predicted_direction} ({'✅' if direction_correct else '❌'})\")\n",
    "    else:\n",
    "        print(\"❌ Не удалось получить прогноз\")\n",
    "    \n",
    "    return predicted_price\n",
    "\n",
    "# Запускаем тест (раскомментируйте для тестирования)\n",
    "print(\"🧪 ТЕСТИРОВАНИЯ ОДИНОЧНОГО ПРОГНОЗА\")\n",
    "print(\"=\"*50)\n",
    "test_single_prediction('SBER', 1)\n",
    "print(\"\\\\n\" + \"-\"*50 + \"\\\\n\")\n",
    "test_single_prediction('SBER', 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_llm_ticker(df, ticker, stage, predictor, window_size=20, patch_size=5):\n",
    "    \"\"\"\n",
    "    Оценивает LLM модель для одного тикера на определенном этапе\n",
    "    Использует стратегию \"точка за точкой\" с патчами\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Подготавливаем признаки для этапа\n",
    "        feature_columns = prepare_features_for_stage(df, stage)\n",
    "        \n",
    "        # Проверяем наличие всех колонок\n",
    "        available_features = [col for col in feature_columns if col in df.columns]\n",
    "        \n",
    "        if len(available_features) == 0:\n",
    "            print(f\"  - Нет доступных признаков для {ticker} на этапе {stage}\")\n",
    "            return None\n",
    "        \n",
    "        # Подготавливаем данные\n",
    "        numeric_features = [f for f in available_features if f != 'daily_headlines']\n",
    "        df_clean = df[available_features].copy()\n",
    "        \n",
    "        # Заполняем NaN в числовых признаках\n",
    "        for feature in numeric_features:\n",
    "            if feature in df_clean.columns:\n",
    "                df_clean[feature] = df_clean[feature].fillna(method='ffill').fillna(method='bfill')\n",
    "        \n",
    "        if len(df_clean) < TEST_SIZE + window_size:\n",
    "            print(f\"  - Недостаточно данных для {ticker} на этапе {stage}\")\n",
    "            return None\n",
    "        \n",
    "        # Прогнозирование точка за точкой\n",
    "        predictions = []\n",
    "        actual_values = []\n",
    "        \n",
    "        start_idx = len(df_clean) - TEST_SIZE\n",
    "        \n",
    "        for i in range(FORECAST_HORIZON):\n",
    "            current_idx = start_idx + i\n",
    "            \n",
    "            # Формируем окно для обучения\n",
    "            window_start = max(0, current_idx - window_size)\n",
    "            window_data = df_clean.iloc[window_start:current_idx]\n",
    "            \n",
    "            if len(window_data) < 5:  # Минимальное окно\n",
    "                break\n",
    "            \n",
    "            # Делаем прогноз\n",
    "            pred = predictor.predict(window_data, stage, patch_size=patch_size)\n",
    "            \n",
    "            # Получаем фактическое значение\n",
    "            if current_idx < len(df_clean):\n",
    "                actual = df_clean.iloc[current_idx]['close']\n",
    "                \n",
    "                predictions.append(pred)\n",
    "                actual_values.append(actual)\n",
    "                \n",
    "                print(f\"    День {i+1}: прогноз={pred:.2f}, факт={actual:.2f}, ошибка={abs(pred-actual)/actual*100:.1f}%\")\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        if len(predictions) == 0:\n",
    "            print(f\"  - Пустые прогнозы для {ticker} на этапе {stage}\")\n",
    "            return None\n",
    "        \n",
    "        # Преобразуем в numpy массивы\n",
    "        predicted_values = np.array(predictions)\n",
    "        actual_values = np.array(actual_values)\n",
    "        \n",
    "        # Убираем NaN значения\n",
    "        valid_mask = ~(np.isnan(predicted_values) | np.isnan(actual_values))\n",
    "        predicted_values = predicted_values[valid_mask]\n",
    "        actual_values = actual_values[valid_mask]\n",
    "        \n",
    "        if len(predicted_values) == 0:\n",
    "            print(f\"  - Нет валидных прогнозов для {ticker} на этапе {stage}\")\n",
    "            return None\n",
    "        \n",
    "        # Вычисляем метрики\n",
    "        rmse_value = np.sqrt(mean_squared_error(actual_values, predicted_values))\n",
    "        mape_value = mean_absolute_percentage_error(actual_values, predicted_values) * 100\n",
    "        da_value = calculate_directional_accuracy(actual_values, predicted_values)\n",
    "        \n",
    "        results = {\n",
    "            'ticker': ticker,\n",
    "            'stage': stage,\n",
    "            'rmse': rmse_value,\n",
    "            'mape': mape_value,\n",
    "            'da': da_value,\n",
    "            'feature_count': len(available_features),\n",
    "            'predictions_count': len(predicted_values)\n",
    "        }\n",
    "        \n",
    "        print(f\"  - {ticker}: RMSE={rmse_value:.4f}, MAPE={mape_value:.2f}%, DA={da_value:.3f}, Features={len(available_features)}\")\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  - Ошибка для {ticker} на этапе {stage}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "print(\"Функция evaluate_llm_ticker определена\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 🚀 Инструкция по запуску прогрессивного анализа\n",
    "\n",
    "### Подготовка:\n",
    "1. **Убедитесь, что API ключ OpenRouter настроен** в ячейке с `API_KEYS`\n",
    "2. **Проверьте, что данные загружены** - должны быть доступны multivariate файлы для всех тикеров\n",
    "3. **Протестируйте промпты** - запустите ячейку с `test_prompt_example()` чтобы увидеть, как выглядят промпты для разных этапов\n",
    "\n",
    "### Тестирование:\n",
    "```python\n",
    "# Протестируйте одиночный прогноз перед полным анализом\n",
    "test_single_prediction('SBER', 1)  # Базовая модель\n",
    "test_single_prediction('SBER', 3)  # С новостями\n",
    "```\n",
    "\n",
    "### Запуск полного анализа:\n",
    "- Запустите ячейку с основным циклом анализа\n",
    "- **Внимание**: Полный анализ может занять **2-3 часа** (7 этапов × 10 тикеров × 10 прогнозов × 2 секунды = ~2300 запросов к API)\n",
    "- Для сокращения времени можно:\n",
    "  - Уменьшить количество тикеров в списке `tickers`\n",
    "  - Уменьшить `FORECAST_HORIZON` (сейчас 10 дней)\n",
    "  - Увеличить паузу `time.sleep()` если получаете ошибки rate limit\n",
    "\n",
    "### Этапы анализа:\n",
    "1. **Этап 1**: Только цены закрытия (baseline)\n",
    "2. **Этап 2**: + Индикаторы аномалий\n",
    "3. **Этап 3**: + Новостная оценка (числовой скор)\n",
    "4. **Этап 4**: + Текст новостей (заголовки)\n",
    "5. **Этап 5**: + OHLV данные (свечи)\n",
    "6. **Этап 6**: + Технические индикаторы (SMA, RSI, MACD и т.д.)\n",
    "7. **Этап 7**: + TSFresh статистические признаки\n",
    "\n",
    "### Результаты:\n",
    "- Будут сохранены в папку `./progressive_analysis/`\n",
    "- Графики изменения метрик по этапам\n",
    "- CSV файлы с детальными результатами\n",
    "- Анализ влияния каждого типа признаков на качество прогнозирования\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Основной цикл прогрессивного анализа с патчами\n",
    "\n",
    "# Определяем названия этапов\n",
    "stage_names = {\n",
    "    1: \"Базовая модель (close)\",\n",
    "    2: \"+ Аномалии\", \n",
    "    3: \"+ Новости (оценка)\",\n",
    "    4: \"+ Новости (текст)\",\n",
    "    5: \"+ Свечи (OHLV)\",\n",
    "    6: \"+ Технические индикаторы\",\n",
    "    7: \"+ TSFresh признаки\"\n",
    "}\n",
    "\n",
    "# Контейнер для результатов\n",
    "all_results = []\n",
    "stage_summaries = []\n",
    "\n",
    "print(\"🚀 Начинаем прогрессивный анализ влияния признаков с LLM (патчи)\\\\n\")\n",
    "\n",
    "# Проходим по всем этапам\n",
    "for stage in range(1, 8):  # 7 этапов\n",
    "    print(f\"📊 ЭТАП {stage}: {stage_names[stage]}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Создаем предиктор для этого этапа\n",
    "    predictor = OpenRouterPredictor(\n",
    "        api_key=API_KEYS['openrouter'],\n",
    "        model_name=\"openai/gpt-4o-mini-2024-07-18\",\n",
    "        max_retries=2,\n",
    "        drop_threshold=0.15\n",
    "    )\n",
    "    \n",
    "    stage_results = []\n",
    "    \n",
    "    # Оцениваем каждый тикер на текущем этапе\n",
    "    for ticker in tickers:\n",
    "        if ticker in data:\n",
    "            print(f\"\\\\n  Обрабатываем {ticker}...\")\n",
    "            result = evaluate_llm_ticker(data[ticker], ticker, stage, predictor, window_size=20, patch_size=5)\n",
    "            if result is not None:\n",
    "                all_results.append(result)\n",
    "                stage_results.append(result)\n",
    "            \n",
    "            # Небольшая пауза между запросами к API\n",
    "            time.sleep(2)\n",
    "    \n",
    "    # Вычисляем средние метрики по этапу\n",
    "    if stage_results:\n",
    "        avg_rmse = np.mean([r['rmse'] for r in stage_results])\n",
    "        avg_mape = np.mean([r['mape'] for r in stage_results])\n",
    "        avg_da = np.mean([r['da'] for r in stage_results if not np.isnan(r['da'])])\n",
    "        avg_features = np.mean([r['feature_count'] for r in stage_results])\n",
    "        \n",
    "        stage_summary = {\n",
    "            'stage': stage,\n",
    "            'stage_name': stage_names[stage],\n",
    "            'avg_rmse': avg_rmse,\n",
    "            'avg_mape': avg_mape,\n",
    "            'avg_da': avg_da,\n",
    "            'avg_features': avg_features,\n",
    "            'ticker_count': len(stage_results)\n",
    "        }\n",
    "        \n",
    "        stage_summaries.append(stage_summary)\n",
    "        \n",
    "        print(f\"\\\\n📈 Средние результаты этапа {stage}:\")\n",
    "        print(f\"   RMSE: {avg_rmse:.4f}\")\n",
    "        print(f\"   MAPE: {avg_mape:.2f}%\")\n",
    "        print(f\"   DA: {avg_da:.3f}\")\n",
    "        print(f\"   Признаков: {avg_features:.1f}\")\n",
    "        print(f\"   Успешных тикеров: {len(stage_results)}/{len(tickers)}\")\n",
    "    else:\n",
    "        print(f\"❌ Нет успешных результатов для этапа {stage}\")\n",
    "    \n",
    "    print(\"\\\\n\" + \"=\"*50 + \"\\\\n\")\n",
    "\n",
    "print(f\"✅ Анализ завершен! Собрано {len(all_results)} результатов из {len(stage_summaries)} этапов\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 🚀 Как запустить прогрессивный анализ\n",
    "\n",
    "### 1. Предварительное тестирование\n",
    "\n",
    "**Сначала протестируйте патчи:**\n",
    "```python\n",
    "# Запустите ячейку с test_patch_example() чтобы посмотреть как выглядят патчи\n",
    "```\n",
    "\n",
    "**Затем протестируйте одиночный прогноз:**\n",
    "```python\n",
    "# Раскомментируйте и запустите тестирование в ячейке test_single_prediction()\n",
    "test_single_prediction('SBER', 1)  # Базовая модель\n",
    "test_single_prediction('SBER', 3)  # С новостями  \n",
    "```\n",
    "\n",
    "### 2. Запуск полного анализа\n",
    "\n",
    "**Для полного анализа запустите ячейку с основным циклом**\n",
    "\n",
    "**⚠️ Внимание:**\n",
    "- Полный анализ займет **2-3 часа** \n",
    "- Будет выполнено ~1400 запросов к API (7 этапов × 10 тикеров × 10 прогнозов × 2 секунды)\n",
    "- Стоимость: примерно $5-10 в зависимости от тарифов OpenRouter\n",
    "\n",
    "**🔧 Для ускорения тестирования:**\n",
    "```python\n",
    "# Уменьшите количество тикеров:\n",
    "tickers = ['SBER', 'MOEX', 'LKOH']  # Только 3 тикера\n",
    "\n",
    "# Или уменьшите горизонт прогноза:\n",
    "FORECAST_HORIZON = 5  # Вместо 10 дней\n",
    "\n",
    "# Или протестируйте только несколько этапов:\n",
    "for stage in range(1, 4):  # Только первые 3 этапа\n",
    "```\n",
    "\n",
    "### 3. Результаты\n",
    "\n",
    "После завершения анализа:\n",
    "- Результаты сохранятся в `./progressive_analysis/`\n",
    "- Вы увидите как каждый тип признаков влияет на качество прогнозирования\n",
    "- Графики покажут изменение RMSE, MAPE и DA по этапам\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Базовый класс OpenRouterPredictor определен!\n"
     ]
    }
   ],
   "source": [
    "class OpenRouterPredictor:\n",
    "    \"\"\"Базовый класс для LLM моделей через OpenRouter API\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key, model_name, max_retries=1, drop_threshold=0.20):\n",
    "        self.api_key = api_key\n",
    "        self.model_name = model_name\n",
    "        self.api_url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "        self.headers = {\n",
    "            \"Authorization\": f\"Bearer {api_key}\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"HTTP-Referer\": \"https://github.com/\", \n",
    "            \"X-Title\": \"Financial Time Series Forecasting\"\n",
    "        }\n",
    "        self.max_retries = max_retries\n",
    "        self.drop_threshold = drop_threshold\n",
    "    \n",
    "    def predict(self, window_data, stage, patch_size=5):\n",
    "        \"\"\"Прогноз следующего значения на основе временного окна\"\"\"\n",
    "        prev_price = window_data['close'].iloc[-1]\n",
    "        attempt = 0\n",
    "        \n",
    "        while attempt < self.max_retries:\n",
    "            attempt += 1\n",
    "            \n",
    "            try:\n",
    "                # Формируем сообщения по патчам\n",
    "                msgs = make_patch_messages(window_data, stage, patch_size)\n",
    "                \n",
    "                # Добавляем system prompt\n",
    "                msgs.insert(0, {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": (\n",
    "                        \"You are a financial time series forecaster. \"\n",
    "                        \"When asked to predict, return exactly one numeric value \"\n",
    "                        \"and nothing else—no explanations, no units, no commentary.\"\n",
    "                    )\n",
    "                })\n",
    "                \n",
    "                # Если не первая попытка - добавляем контекст о проблеме\n",
    "                if attempt > 1:\n",
    "                    msgs.insert(1, {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": (\n",
    "                            \"Note: Previous prediction was unrealistic. \"\n",
    "                            \"Please reconsider market trends and provide a more plausible prediction. \"\n",
    "                            \"Return only the next price as a single number.\"\n",
    "                        )\n",
    "                    })\n",
    "                \n",
    "                # User prompt\n",
    "                msgs.append({\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"Based on these financial characteristics, predict the next closing price value. Output only the next closing price as a number.\"\n",
    "                })\n",
    "                \n",
    "                # Отправляем запрос\n",
    "                response = requests.post(\n",
    "                    self.api_url,\n",
    "                    headers=self.headers,\n",
    "                    json={\n",
    "                        \"model\": self.model_name,\n",
    "                        \"messages\": msgs,\n",
    "                        \"max_tokens\": 50,\n",
    "                        \"temperature\": 0.1\n",
    "                    },\n",
    "                    timeout=30\n",
    "                )\n",
    "                response.raise_for_status()\n",
    "                \n",
    "                # Парсим ответ\n",
    "                response_data = response.json()\n",
    "                content = response_data[\"choices\"][0][\"message\"][\"content\"]\n",
    "                pred = parse_llm_response(content)\n",
    "                \n",
    "                # Проверка на аномальные значения\n",
    "                if np.isnan(pred):\n",
    "                    print(f\"    Попытка {attempt}: не удалось извлечь число из '{content}'\")\n",
    "                    if attempt >= self.max_retries:\n",
    "                        return prev_price\n",
    "                    time.sleep(1)\n",
    "                    continue\n",
    "                \n",
    "                # Проверка на сильное занижение/завышение\n",
    "                if pred < prev_price * (1 - self.drop_threshold) or pred > prev_price * (1 + self.drop_threshold):\n",
    "                    print(f\"    Попытка {attempt}: аномальный прогноз {pred:.2f} (предыдущая цена {prev_price:.2f})\")\n",
    "                    if attempt < self.max_retries:\n",
    "                        time.sleep(1)\n",
    "                        continue\n",
    "                    else:\n",
    "                        # Возвращаем ограниченное значение\n",
    "                        if pred < prev_price * (1 - self.drop_threshold):\n",
    "                            return prev_price * (1 - self.drop_threshold)\n",
    "                        else:\n",
    "                            return prev_price * (1 + self.drop_threshold)\n",
    "                \n",
    "                return pred\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"    Ошибка попытки {attempt}: {e}\")\n",
    "                if attempt >= self.max_retries:\n",
    "                    return prev_price\n",
    "                time.sleep(1)\n",
    "        \n",
    "        return prev_price\n",
    "\n",
    "print(\"Базовый класс OpenRouterPredictor определен!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_for_ticker_llm():\n",
    "    #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_for_ticker(df, ticker, stage):\n",
    "    \"\"\"\n",
    "    Обучает модель и оценивает её для одного тикера на определенном этапе\n",
    "    Использует стратегию \"точка за точкой\" для честного прогнозирования\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame с данными тикера\n",
    "        ticker: название тикера\n",
    "        stage: номер этапа (1-7)\n",
    "    \n",
    "    Returns:\n",
    "        results: словарь с метриками и важностью признаков\n",
    "    \"\"\"\n",
    "    \n",
    "    #try:\n",
    "    # Подготавливаем признаки для этапа\n",
    "    feature_columns = prepare_features_for_stage(df, stage)\n",
    "    \n",
    "    # Проверяем наличие всех колонок\n",
    "    available_features = [col for col in feature_columns if col in df.columns]\n",
    "    \n",
    "    if len(available_features) == 0:\n",
    "        print(f\"  - Нет доступных признаков для {ticker} на этапе {stage}\")\n",
    "        return None\n",
    "    \n",
    "    # Удаляем строки с NaN в выбранных признаках\n",
    "    df_clean = df[available_features].dropna()\n",
    "    \n",
    "    if len(df_clean) < TEST_SIZE + 10:  # Минимум данных для обучения\n",
    "        print(f\"  - Недостаточно данных для {ticker} на этапе {stage}\")\n",
    "        return None\n",
    "    \n",
    "    # Готовим данные для DARTS\n",
    "    if stage == 1:\n",
    "        # Univariate модель по стратегии extending window\n",
    "        ts = TimeSeries.from_dataframe(df_clean, time_col=None, value_cols='close')\n",
    "        current_ts = ts[:-TEST_SIZE]   # начальное обучающее окно\n",
    "        predictions = []\n",
    "\n",
    "        for i in range(FORECAST_HORIZON):\n",
    "            # 1) Переобучаем модель на всем current_ts\n",
    "            model = RandomForest(lags=14, random_state=42)\n",
    "            model.fit(current_ts)\n",
    "\n",
    "            # 2) Делаем прогноз на 1 шаг вперед\n",
    "            pred = model.predict(n=1)\n",
    "            y_pred = pred.values().flatten()[0]\n",
    "            predictions.append(y_pred)\n",
    "\n",
    "            # 3) Добавляем фактическое значение в окно\n",
    "            next_time = ts.time_index[len(current_ts)]\n",
    "            y_true = ts.values()[len(current_ts)][0]\n",
    "            s = pd.Series([y_true], index=[next_time])\n",
    "            actual_ts = TimeSeries.from_series(\n",
    "                s,\n",
    "                fill_missing_dates=False,\n",
    "                freq=ts.freq\n",
    "            )\n",
    "            current_ts = current_ts.append(actual_ts)\n",
    "\n",
    "        feature_importance = {}\n",
    "        \n",
    "    else:\n",
    "        # Multivariate модель\n",
    "        target_col = 'close'\n",
    "        past_covariates_cols = [col for col in available_features if col != target_col]\n",
    "        \n",
    "        if len(past_covariates_cols) == 0:\n",
    "            # Fallback к univariate если нет ковариат\n",
    "            ts = TimeSeries.from_dataframe(df_clean, time_col=None, value_cols=target_col)\n",
    " \n",
    "            # Прогнозирование точка за точкой\n",
    "            predictions = []\n",
    "            current_ts = ts[:-TEST_SIZE]\n",
    "            \n",
    "            for i in range(FORECAST_HORIZON):\n",
    "                # 1) Переобучаем модель на всем current_ts\n",
    "                model = RandomForest(lags=14, random_state=42)\n",
    "                model.fit(current_ts)\n",
    "    \n",
    "                # 2) Делаем прогноз на 1 шаг вперед\n",
    "                pred = model.predict(n=1)\n",
    "                y_pred = pred.values().flatten()[0]\n",
    "                predictions.append(y_pred)\n",
    "    \n",
    "                # 3) Добавляем фактическое значение в окно\n",
    "                next_time = ts.time_index[len(current_ts)]\n",
    "                y_true = ts.values()[len(current_ts)][0]\n",
    "                s = pd.Series([y_true], index=[next_time])\n",
    "                actual_ts = TimeSeries.from_series(\n",
    "                    s,\n",
    "                    fill_missing_dates=False,\n",
    "                    freq=ts.freq\n",
    "                )\n",
    "                current_ts = current_ts.append(actual_ts)\n",
    "            \n",
    "            feature_importance = {}\n",
    "            \n",
    "        else:\n",
    "            # Создаем TimeSeries для цели и ковариат\n",
    "            target_ts = TimeSeries.from_dataframe(df_clean, time_col=None, value_cols=target_col)\n",
    "            past_covariates_ts = TimeSeries.from_dataframe(df_clean, time_col=None, value_cols=past_covariates_cols)\n",
    "\n",
    "            # чтобы в конце можно было читать actual_values из ts\n",
    "            ts = target_ts\n",
    "            \n",
    "            # Прогнозирование точка за точкой\n",
    "            predictions = []\n",
    "            current_target = target_ts[:-TEST_SIZE]\n",
    "            current_covariates = past_covariates_ts[:-TEST_SIZE]\n",
    "            \n",
    "            for i in range(FORECAST_HORIZON):\n",
    "                # 1) Переобучаем multivariate модель\n",
    "                model = RandomForest(lags=14, lags_past_covariates=7, random_state=42)\n",
    "                model.fit(series=current_target, past_covariates=current_covariates)\n",
    "    \n",
    "                # 2) Прогноз\n",
    "                pred = model.predict(n=1, past_covariates=current_covariates)\n",
    "                y_pred = pred.values().flatten()[0]\n",
    "                predictions.append(y_pred)\n",
    "    \n",
    "                # 3) Добавляем фактическое значение таргета\n",
    "                next_t = target_ts.time_index[len(current_target)]\n",
    "                y_true = target_ts.values()[len(current_target)][0]\n",
    "                s_y = pd.Series([y_true], index=[next_t])\n",
    "                actual_y_ts = TimeSeries.from_series(\n",
    "                    s_y, fill_missing_dates=False, freq=target_ts.freq\n",
    "                )\n",
    "                current_target = current_target.append(actual_y_ts)\n",
    "    \n",
    "                # 4) Добавляем фактические ковариаты\n",
    "                next_t = past_covariates_ts.time_index[len(current_covariates)]\n",
    "                x_true = past_covariates_ts.values()[len(current_covariates)].flatten()\n",
    "                df_x = pd.DataFrame([x_true], index=[next_t], columns=past_covariates_cols)\n",
    "                actual_x_ts = TimeSeries.from_dataframe(\n",
    "                    df_x, time_col=None, value_cols=past_covariates_cols,\n",
    "                    fill_missing_dates=False, freq=past_covariates_ts.freq\n",
    "                )\n",
    "                current_covariates = current_covariates.append(actual_x_ts)\n",
    "            \n",
    "            # Извлекаем важность признаков\n",
    "            if hasattr(model.model, 'feature_importances_'):\n",
    "                importance_values = model.model.feature_importances_\n",
    "                # Создаем названия признаков (lags + past_covariates)\n",
    "                feature_names = []\n",
    "                for lag in range(1, 15):  # lags=14\n",
    "                    feature_names.append(f'{target_col}_lag_{lag}')\n",
    "                for lag in range(1, 8):   # lags_past_covariates=7\n",
    "                    for col in past_covariates_cols:\n",
    "                        feature_names.append(f'{col}_lag_{lag}')\n",
    "                \n",
    "                feature_importance = dict(zip(feature_names[:len(importance_values)], importance_values))\n",
    "            else:\n",
    "                feature_importance = {}\n",
    "    \n",
    "    # Получаем реальные значения для сравнения\n",
    "    actual_values = ts[-TEST_SIZE:-TEST_SIZE+FORECAST_HORIZON].values().flatten()\n",
    "    predicted_values = np.array(predictions)\n",
    "    \n",
    "    # Убеждаемся что размеры совпадают\n",
    "    min_length = min(len(actual_values), len(predicted_values))\n",
    "    actual_values = actual_values[:min_length]\n",
    "    predicted_values = predicted_values[:min_length]\n",
    "    \n",
    "    if min_length == 0:\n",
    "        print(f\"  - Пустые прогнозы для {ticker} на этапе {stage}\")\n",
    "        return None\n",
    "    \n",
    "    # RMSE\n",
    "    rmse_value = np.sqrt(mean_squared_error(actual_values, predicted_values))\n",
    "    \n",
    "    # MAPE\n",
    "    mape_value = mean_absolute_percentage_error(actual_values, predicted_values) * 100\n",
    "    \n",
    "    # DA (Directional Accuracy)\n",
    "    da_value = calculate_directional_accuracy(actual_values, predicted_values)\n",
    "    \n",
    "    results = {\n",
    "        'ticker': ticker,\n",
    "        'stage': stage,\n",
    "        'rmse': rmse_value,\n",
    "        'mape': mape_value,\n",
    "        'da': da_value,\n",
    "        'feature_count': len(available_features),\n",
    "        'feature_importance': feature_importance\n",
    "    }\n",
    "    \n",
    "    print(f\"  - {ticker}: RMSE={rmse_value:.4f}, MAPE={mape_value:.2f}%, DA={da_value:.3f}, Features={len(available_features)}\")\n",
    "    \n",
    "    return results\n",
    "        \n",
    "    # except Exception as e:\n",
    "    #     print(f\"  - Ошибка для {ticker} на этапе {stage}: {str(e)}\")\n",
    "    #     return None\n",
    "\n",
    "print(\"Вспомогательные функции определены\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Прогрессивный анализ по этапам\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем предиктор\n",
    "predictor = OpenRouterLLMPredictor(\n",
    "    api_key=API_KEYS['openrouter'],\n",
    "    model_name=\"openai/gpt-4o-mini-2024-07-18\",\n",
    "    max_retries=2,\n",
    "    drop_threshold=0.15\n",
    ")\n",
    "\n",
    "# Определяем названия этапов\n",
    "stage_names = {\n",
    "    1: \"Базовая модель (close)\",\n",
    "    2: \"+ Аномалии\", \n",
    "    3: \"+ Новости (оценка)\",\n",
    "    4: \"+ Новости (текст)\",\n",
    "    5: \"+ Свечи (OHLV)\",\n",
    "    6: \"+ Технические индикаторы\",\n",
    "    7: \"+ TSFresh признаки\"\n",
    "}\n",
    "\n",
    "# Контейнер для результатов\n",
    "all_results = []\n",
    "stage_summaries = []\n",
    "\n",
    "print(\"🚀 Начинаем прогрессивный анализ влияния признаков LLM\\\\n\")\n",
    "\n",
    "# Проходим по всем этапам\n",
    "for stage in range(1, 8):  # 7 этапов\n",
    "    print(f\"📊 ЭТАП {stage}: {stage_names[stage]}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    stage_results = []\n",
    "    \n",
    "    # Оцениваем каждый тикер на текущем этапе\n",
    "    for ticker in tickers:\n",
    "        if ticker in data:\n",
    "            print(f\"\\\\n  Обрабатываем {ticker}...\")\n",
    "            result = evaluate_model_for_ticker_llm(data[ticker], ticker, stage, predictor)\n",
    "            if result is not None:\n",
    "                all_results.append(result)\n",
    "                stage_results.append(result)\n",
    "            \n",
    "            # Небольшая пауза между запросами к API\n",
    "            time.sleep(2)\n",
    "    \n",
    "    # Вычисляем средние метрики по этапу\n",
    "    if stage_results:\n",
    "        avg_rmse = np.mean([r['rmse'] for r in stage_results])\n",
    "        avg_mape = np.mean([r['mape'] for r in stage_results])\n",
    "        avg_da = np.mean([r['da'] for r in stage_results if not np.isnan(r['da'])])\n",
    "        avg_features = np.mean([r['feature_count'] for r in stage_results])\n",
    "        \n",
    "        stage_summary = {\n",
    "            'stage': stage,\n",
    "            'stage_name': stage_names[stage],\n",
    "            'avg_rmse': avg_rmse,\n",
    "            'avg_mape': avg_mape,\n",
    "            'avg_da': avg_da,\n",
    "            'avg_features': avg_features,\n",
    "            'ticker_count': len(stage_results)\n",
    "        }\n",
    "        \n",
    "        stage_summaries.append(stage_summary)\n",
    "        \n",
    "        print(f\"\\\\n📈 Средние результаты этапа {stage}:\")\n",
    "        print(f\"   RMSE: {avg_rmse:.4f}\")\n",
    "        print(f\"   MAPE: {avg_mape:.2f}%\")\n",
    "        print(f\"   DA: {avg_da:.3f}\")\n",
    "        print(f\"   Признаков: {avg_features:.1f}\")\n",
    "        print(f\"   Успешных тикеров: {len(stage_results)}/{len(tickers)}\")\n",
    "    else:\n",
    "        print(f\"❌ Нет успешных результатов для этапа {stage}\")\n",
    "    \n",
    "    print(\"\\\\n\" + \"=\"*50 + \"\\\\n\")\n",
    "\n",
    "print(f\"✅ Анализ завершен! Собрано {len(all_results)} результатов из {len(stage_summaries)} этапов\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Начинаем прогрессивный анализ влияния признаков\n",
      "\n",
      "📊 ЭТАП 1: Базовая модель (close)\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Определяем названия этапов\n",
    "stage_names = {\n",
    "    1: \"Базовая модель (close)\",\n",
    "    2: \"+ Аномалии\", \n",
    "    3: \"+ Новости\",\n",
    "    4: \"+ Свечи\",\n",
    "    5: \"+ Технические индикаторы\",\n",
    "    6: \"+ PCA компоненты\",\n",
    "    7: \"+ TSFresh признаки\", \n",
    "    8: \"+ Картинка\",\n",
    "}\n",
    "\n",
    "# Контейнер для результатов\n",
    "all_results = []\n",
    "stage_summaries = []\n",
    "\n",
    "print(\"🚀 Начинаем прогрессивный анализ влияния признаков\\n\")\n",
    "\n",
    "## TODO: adapt to LLM\n",
    "\n",
    "# Проходим по всем этапам\n",
    "for stage in range(1, 9):\n",
    "    print(f\"📊 ЭТАП {stage}: {stage_names[stage]}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    stage_results = []\n",
    "    \n",
    "    # Оцениваем каждый тикер на текущем этапе\n",
    "    for ticker in tickers:\n",
    "        if ticker in data:\n",
    "            result = evaluate_model_for_ticker_llm(data[ticker], ticker, stage)\n",
    "            if result is not None:\n",
    "                all_results.append(result)\n",
    "                stage_results.append(result)\n",
    "    \n",
    "    # Вычисляем средние метрики по этапу\n",
    "    if stage_results:\n",
    "        avg_rmse = np.mean([r['rmse'] for r in stage_results])\n",
    "        avg_mape = np.mean([r['mape'] for r in stage_results])\n",
    "        avg_da = np.mean([r['da'] for r in stage_results if not np.isnan(r['da'])])\n",
    "        avg_features = np.mean([r['feature_count'] for r in stage_results])\n",
    "        \n",
    "        stage_summary = {\n",
    "            'stage': stage,\n",
    "            'stage_name': stage_names[stage],\n",
    "            'avg_rmse': avg_rmse,\n",
    "            'avg_mape': avg_mape,\n",
    "            'avg_da': avg_da,\n",
    "            'avg_features': avg_features,\n",
    "            'ticker_count': len(stage_results)\n",
    "        }\n",
    "        \n",
    "        stage_summaries.append(stage_summary)\n",
    "        \n",
    "        print(f\"\\n📈 Средние результаты этапа {stage}:\")\n",
    "        print(f\"   RMSE: {avg_rmse:.4f}\")\n",
    "        print(f\"   MAPE: {avg_mape:.2f}%\")\n",
    "        print(f\"   DA: {avg_da:.3f}\")\n",
    "        print(f\"   Признаков: {avg_features:.1f}\")\n",
    "        print(f\"   Успешных тикеров: {len(stage_results)}/{len(tickers)}\")\n",
    "    else:\n",
    "        print(f\"❌ Нет успешных результатов для этапа {stage}\")\n",
    "    \n",
    "    print(\"\\\\n\" + \"=\"*50 + \"\\\\n\")\n",
    "\n",
    "print(f\"✅ Анализ завершен! Собрано {len(all_results)} результатов из {len(stage_summaries)} этапов\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Итоговая таблица результатов\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем итоговую таблицу\n",
    "results_df = pd.DataFrame(stage_summaries)\n",
    "\n",
    "if not results_df.empty:\n",
    "    print(\"📊 ИТОГОВАЯ ТАБЛИЦА РЕЗУЛЬТАТОВ\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Форматируем таблицу для красивого отображения\n",
    "    display_df = results_df.copy()\n",
    "    display_df['RMSE'] = display_df['avg_rmse'].apply(lambda x: f\"{x:.4f}\")\n",
    "    display_df['MAPE (%)'] = display_df['avg_mape'].apply(lambda x: f\"{x:.2f}\")\n",
    "    display_df['DA'] = display_df['avg_da'].apply(lambda x: f\"{x:.3f}\")\n",
    "    display_df['Признаков'] = display_df['avg_features'].apply(lambda x: f\"{x:.0f}\")\n",
    "    display_df['Тикеров'] = display_df['ticker_count'].apply(lambda x: f\"{x}\")\n",
    "    \n",
    "    # Выбираем колонки для отображения\n",
    "    final_table = display_df[['stage', 'stage_name', 'RMSE', 'MAPE (%)', 'DA', 'Признаков', 'Тикеров']].copy()\n",
    "    final_table.columns = ['Этап', 'Описание', 'RMSE', 'MAPE (%)', 'DA', 'Признаков', 'Тикеров']\n",
    "    \n",
    "    print(final_table.to_string(index=False))\n",
    "    \n",
    "    # Сохраняем таблицу\n",
    "    results_df.to_csv(f\"{OUTPUT_PATH}progressive_analysis_summary.csv\", index=False)\n",
    "    final_table.to_csv(f\"{OUTPUT_PATH}progressive_analysis_formatted.csv\", index=False)\n",
    "    \n",
    "    print(f\"\\\\n💾 Результаты сохранены в {OUTPUT_PATH}\")\n",
    "    \n",
    "    # Показываем изменения метрик относительно базовой модели\n",
    "    if len(results_df) > 1:\n",
    "        base_rmse = results_df.iloc[0]['avg_rmse']\n",
    "        base_mape = results_df.iloc[0]['avg_mape'] \n",
    "        base_da = results_df.iloc[0]['avg_da']\n",
    "        \n",
    "        print(\"\\\\n📈 ИЗМЕНЕНИЯ ОТНОСИТЕЛЬНО БАЗОВОЙ МОДЕЛИ:\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        for i, row in results_df.iterrows():\n",
    "            if i == 0:\n",
    "                continue  # Пропускаем базовую модель\n",
    "                \n",
    "            rmse_change = ((row['avg_rmse'] - base_rmse) / base_rmse) * 100\n",
    "            mape_change = ((row['avg_mape'] - base_mape) / base_mape) * 100\n",
    "            da_change = ((row['avg_da'] - base_da) / base_da) * 100\n",
    "            \n",
    "            print(f\"Этап {row['stage']} - {row['stage_name']}:\")\n",
    "            print(f\"  RMSE: {rmse_change:+.1f}% ({'улучшение' if rmse_change < 0 else 'ухудшение'})\")\n",
    "            print(f\"  MAPE: {mape_change:+.1f}% ({'улучшение' if mape_change < 0 else 'ухудшение'})\")\n",
    "            print(f\"  DA: {da_change:+.1f}% ({'улучшение' if da_change > 0 else 'ухудшение'})\")\n",
    "            print()\n",
    "            \n",
    "else:\n",
    "    print(\"❌ Нет данных для создания итоговой таблицы\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Визуализация изменения метрик\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not results_df.empty:\n",
    "    # Создаем графики изменения метрик\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('Прогрессивное изменение метрик качества прогнозирования', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # График 1: RMSE\n",
    "    axes[0,0].plot(results_df['stage'], results_df['avg_rmse'], 'o-', linewidth=2, markersize=8, color='red')\n",
    "    axes[0,0].set_title('RMSE (среднеквадратичная ошибка)', fontweight='bold')\n",
    "    axes[0,0].set_xlabel('Этап')\n",
    "    axes[0,0].set_ylabel('RMSE')\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    axes[0,0].set_xticks(results_df['stage'])\n",
    "    \n",
    "    # График 2: MAPE\n",
    "    axes[0,1].plot(results_df['stage'], results_df['avg_mape'], 'o-', linewidth=2, markersize=8, color='orange')\n",
    "    axes[0,1].set_title('MAPE (средняя абсолютная процентная ошибка)', fontweight='bold')\n",
    "    axes[0,1].set_xlabel('Этап')\n",
    "    axes[0,1].set_ylabel('MAPE (%)')\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    axes[0,1].set_xticks(results_df['stage'])\n",
    "    \n",
    "    # График 3: DA\n",
    "    axes[1,0].plot(results_df['stage'], results_df['avg_da'], 'o-', linewidth=2, markersize=8, color='green')\n",
    "    axes[1,0].set_title('DA (точность направления)', fontweight='bold')\n",
    "    axes[1,0].set_xlabel('Этап')\n",
    "    axes[1,0].set_ylabel('DA')\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    axes[1,0].set_xticks(results_df['stage'])\n",
    "    axes[1,0].set_ylim(0, 1)\n",
    "    \n",
    "    # График 4: Количество признаков\n",
    "    axes[1,1].plot(results_df['stage'], results_df['avg_features'], 'o-', linewidth=2, markersize=8, color='purple')\n",
    "    axes[1,1].set_title('Количество признаков', fontweight='bold')\n",
    "    axes[1,1].set_xlabel('Этап')\n",
    "    axes[1,1].set_ylabel('Количество признаков')\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    axes[1,1].set_xticks(results_df['stage'])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{OUTPUT_PATH}metrics_progression.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Создаем heatmap сравнения метрик\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "    \n",
    "    # Подготавливаем данные для heatmap\n",
    "    heatmap_data = results_df[['stage', 'avg_rmse', 'avg_mape', 'avg_da']].copy()\n",
    "    \n",
    "    # Нормализуем данные для лучшей визуализации (min-max scaling)\n",
    "    for col in ['avg_rmse', 'avg_mape', 'avg_da']:\n",
    "        min_val = heatmap_data[col].min()\n",
    "        max_val = heatmap_data[col].max()\n",
    "        if max_val > min_val:\n",
    "            heatmap_data[col] = (heatmap_data[col] - min_val) / (max_val - min_val)\n",
    "    \n",
    "    # Для RMSE и MAPE - инвертируем (меньше = лучше)\n",
    "    heatmap_data['avg_rmse'] = 1 - heatmap_data['avg_rmse']\n",
    "    heatmap_data['avg_mape'] = 1 - heatmap_data['avg_mape']\n",
    "    \n",
    "    # Создаем heatmap\n",
    "    heatmap_matrix = heatmap_data[['avg_rmse', 'avg_mape', 'avg_da']].T\n",
    "    heatmap_matrix.columns = [f\"Этап {i}\" for i in results_df['stage']]\n",
    "    heatmap_matrix.index = ['RMSE (норм.)', 'MAPE (норм.)', 'DA']\n",
    "    \n",
    "    sns.heatmap(heatmap_matrix, annot=True, cmap='RdYlGn', center=0.5, \n",
    "                cbar_kws={'label': 'Качество (нормализовано)'}, ax=ax)\n",
    "    ax.set_title('Тепловая карта качества моделей по этапам\\\\n(зеленый = лучше, красный = хуже)', \n",
    "                 fontweight='bold', fontsize=14)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{OUTPUT_PATH}quality_heatmap.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"❌ Нет данных для визуализации\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы и рекомендации\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🎯 РЕЗЮМЕ ПРОГРЕССИВНОГО АНАЛИЗА\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if results_df.empty:\n",
    "    print(\"❌ Нет результатов для анализа\")\n",
    "else:\n",
    "    print(f\"✅ Проанализировано {len(results_df)} этапов для {len(tickers)} тикеров\")\n",
    "    print(f\"📊 Собрано {len(all_results)} успешных результатов\")\n",
    "    \n",
    "    # Найдем лучший этап по каждой метрике\n",
    "    best_rmse_stage = results_df.loc[results_df['avg_rmse'].idxmin()]\n",
    "    best_mape_stage = results_df.loc[results_df['avg_mape'].idxmin()]\n",
    "    best_da_stage = results_df.loc[results_df['avg_da'].idxmax()]\n",
    "    \n",
    "    print(\"\\\\n🏆 ЛУЧШИЕ РЕЗУЛЬТАТЫ:\")\n",
    "    print(f\"   Лучший RMSE: Этап {best_rmse_stage['stage']} ({best_rmse_stage['stage_name']}) - {best_rmse_stage['avg_rmse']:.4f}\")\n",
    "    print(f\"   Лучший MAPE: Этап {best_mape_stage['stage']} ({best_mape_stage['stage_name']}) - {best_mape_stage['avg_mape']:.2f}%\")\n",
    "    print(f\"   Лучший DA: Этап {best_da_stage['stage']} ({best_da_stage['stage_name']}) - {best_da_stage['avg_da']:.3f}\")\n",
    "    \n",
    "    # Анализ тренда качества\n",
    "    base_metrics = results_df.iloc[0]\n",
    "    final_metrics = results_df.iloc[-1]\n",
    "    \n",
    "    rmse_change = ((final_metrics['avg_rmse'] - base_metrics['avg_rmse']) / base_metrics['avg_rmse']) * 100\n",
    "    mape_change = ((final_metrics['avg_mape'] - base_metrics['avg_mape']) / base_metrics['avg_mape']) * 100\n",
    "    da_change = ((final_metrics['avg_da'] - base_metrics['avg_da']) / base_metrics['avg_da']) * 100\n",
    "    \n",
    "    print(\"\\\\n📈 ОБЩЕЕ УЛУЧШЕНИЕ (финальный этап vs базовая модель):\")\n",
    "    print(f\"   RMSE: {rmse_change:+.1f}% ({'✅ улучшение' if rmse_change < 0 else '❌ ухудшение'})\")\n",
    "    print(f\"   MAPE: {mape_change:+.1f}% ({'✅ улучшение' if mape_change < 0 else '❌ ухудшение'})\")\n",
    "    print(f\"   DA: {da_change:+.1f}% ({'✅ улучшение' if da_change > 0 else '❌ ухудшение'})\")\n",
    "    \n",
    "    # Рекомендации\n",
    "    print(\"\\\\n💡 РЕКОМЕНДАЦИИ:\")\n",
    "    \n",
    "    # Определяем наиболее эффективные этапы\n",
    "    rmse_improvements = []\n",
    "    mape_improvements = []\n",
    "    da_improvements = []\n",
    "    \n",
    "    for i in range(1, len(results_df)):\n",
    "        prev_metrics = results_df.iloc[i-1]\n",
    "        curr_metrics = results_df.iloc[i]\n",
    "        \n",
    "        rmse_change = ((curr_metrics['avg_rmse'] - prev_metrics['avg_rmse']) / prev_metrics['avg_rmse']) * 100\n",
    "        mape_change = ((curr_metrics['avg_mape'] - prev_metrics['avg_mape']) / prev_metrics['avg_mape']) * 100\n",
    "        da_change = ((curr_metrics['avg_da'] - prev_metrics['avg_da']) / prev_metrics['avg_da']) * 100\n",
    "        \n",
    "        rmse_improvements.append((curr_metrics['stage'], rmse_change))\n",
    "        mape_improvements.append((curr_metrics['stage'], mape_change))\n",
    "        da_improvements.append((curr_metrics['stage'], da_change))\n",
    "    \n",
    "    # Находим этапы с наибольшими улучшениями\n",
    "    best_rmse_improvement = min(rmse_improvements, key=lambda x: x[1])\n",
    "    best_mape_improvement = min(mape_improvements, key=lambda x: x[1])\n",
    "    best_da_improvement = max(da_improvements, key=lambda x: x[1])\n",
    "    \n",
    "    print(f\"   1. Наибольшее улучшение RMSE дал этап {best_rmse_improvement[0]} ({best_rmse_improvement[1]:+.1f}%)\")\n",
    "    print(f\"   2. Наибольшее улучшение MAPE дал этап {best_mape_improvement[0]} ({best_mape_improvement[1]:+.1f}%)\")\n",
    "    print(f\"   3. Наибольшее улучшение DA дал этап {best_da_improvement[0]} ({best_da_improvement[1]:+.1f}%)\")\n",
    "    \n",
    "    # Анализ эффективности по соотношению качества к сложности\n",
    "    print(\"\\\\n⚖️ АНАЛИЗ ЭФФЕКТИВНОСТИ (качество vs сложность):\")\n",
    "    for _, row in results_df.iterrows():\n",
    "        efficiency_score = (1 - row['avg_rmse']/base_metrics['avg_rmse']) / (row['avg_features']/base_metrics['avg_features'])\n",
    "        print(f\"   Этап {row['stage']}: Эффективность = {efficiency_score:.3f} (качество/сложность)\")\n",
    "\n",
    "print(\"\\\\n🎉 ПРОГРЕССИВНЫЙ АНАЛИЗ ЗАВЕРШЕН!\")\n",
    "print(f\"📁 Все результаты сохранены в папке: {OUTPUT_PATH}\")\n",
    "print(\"\\\\nФайлы результатов:\")\n",
    "print(\"   - progressive_analysis_summary.csv - сводка по этапам\")\n",
    "print(\"   - progressive_analysis_formatted.csv - форматированная таблица\")\n",
    "print(\"   - feature_importance_summary.csv - важность признаков\")\n",
    "print(\"   - metrics_progression.png - графики изменения метрик\")\n",
    "print(\"   - quality_heatmap.png - тепловая карта качества\")\n",
    "print(\"   - feature_importance_stage_N.png - важность признаков для последнего этапа\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llms)",
   "language": "python",
   "name": "llms"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
