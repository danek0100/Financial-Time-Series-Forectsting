{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Статистические модели для прогнозирования временных рядов\n",
        "\n",
        "В этом блокноте тестируем статистические модели из пакета ETNA:\n",
        "- AutoARIMA\n",
        "- SARIMAX\n",
        "- Holt-Winters\n",
        "- StatsForecast ARIMA\n",
        "\n",
        "Для статистических моделей важно правильно подготовить данные (приведение к стационарности).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Настройка среды\n",
        "import sys\n",
        "print(sys.executable)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Установка необходимых пакетов\n",
        "import subprocess\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Путь к pip в активном ядре\n",
        "pip_path = os.path.join(sys.prefix, \"bin\", \"pip\")\n",
        "\n",
        "# Установка\n",
        "subprocess.check_call([pip_path, \"install\", \"etna[all]\", \"pandas\", \"matplotlib\", \"statsmodels\", \"pmdarima\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Импорты\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "from math import floor\n",
        "import numpy as np\n",
        "import os\n",
        "from pathlib import Path\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ETNA\n",
        "from etna.datasets import TSDataset\n",
        "from etna.models import (\n",
        "    AutoARIMAModel, \n",
        "    SARIMAXModel, \n",
        "    HoltWintersModel,\n",
        "    StatsForecastARIMAModel\n",
        ")\n",
        "from etna.metrics import MAE, MAPE, RMSE, SMAPE\n",
        "from etna.analysis import plot_forecast\n",
        "\n",
        "# Статистические тесты и преобразования\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Установим читаемый формат для вывода чисел\n",
        "pd.options.display.float_format = '{:.3f}'.format\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Функция для расчета Directional Accuracy\n",
        "def directional_accuracy(actual, predicted):\n",
        "    \"\"\"\n",
        "    Calculates Directional Accuracy by comparing each predicted value's\n",
        "    direction with the actual value's direction.\n",
        "    \"\"\"\n",
        "    actual_direction = np.sign(actual - np.roll(actual, 1))  # Direction of actual values\n",
        "    predicted_direction = np.sign(predicted - np.roll(predicted, 1))  # Direction of predictions\n",
        "\n",
        "    # Ignore the first element (due to np.roll)\n",
        "    actual_direction[0] = np.nan\n",
        "    predicted_direction[0] = np.nan\n",
        "\n",
        "    # Calculate accuracy for elements where both actual and predicted directions are not NaN\n",
        "    mask = ~np.isnan(actual_direction) & ~np.isnan(predicted_direction)\n",
        "\n",
        "    return np.mean(actual_direction[mask] == predicted_direction[mask]) * 100\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ADF тест для проверки стационарности\n",
        "def check_stationarity(timeseries, title):\n",
        "    \"\"\"\n",
        "    Выполняет Augmented Dickey-Fuller тест для проверки стационарности.\n",
        "    \"\"\"\n",
        "    print(f'Results of Augmented Dickey-Fuller Test for {title}:')\n",
        "    dftest = adfuller(timeseries, autolag='AIC')\n",
        "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
        "    for key,value in dftest[4].items():\n",
        "        dfoutput['Critical Value (%s)'%key] = value\n",
        "    print(dfoutput)\n",
        "    \n",
        "    if dftest[1] <= 0.05:\n",
        "        print(\"*** Series is Stationary ***\")\n",
        "        return True\n",
        "    else:\n",
        "        print(\"*** Series is Non-Stationary ***\")\n",
        "        return False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Функции для приведения к стационарности и обратного преобразования\n",
        "def make_stationary(ts, method='diff'):\n",
        "    \"\"\"\n",
        "    Приводит временной ряд к стационарному виду.\n",
        "    \n",
        "    Parameters:\n",
        "    ts: pandas Series - временной ряд\n",
        "    method: str - метод преобразования ('diff', 'log_diff', 'pct_change')\n",
        "    \n",
        "    Returns:\n",
        "    transformed_ts: pandas Series - преобразованный ряд\n",
        "    \"\"\"\n",
        "    if method == 'diff':\n",
        "        return ts.diff().dropna()\n",
        "    elif method == 'log_diff':\n",
        "        return np.log(ts).diff().dropna()\n",
        "    elif method == 'pct_change':\n",
        "        return ts.pct_change().dropna()\n",
        "    else:\n",
        "        raise ValueError(\"Method should be 'diff', 'log_diff', or 'pct_change'\")\n",
        "\n",
        "def inverse_transform(original_ts, transformed_predictions, method='diff'):\n",
        "    \"\"\"\n",
        "    Обращает преобразование для получения прогнозов в исходном масштабе.\n",
        "    \n",
        "    Parameters:\n",
        "    original_ts: pandas Series - исходный временной ряд\n",
        "    transformed_predictions: array-like - прогнозы в преобразованном масштабе\n",
        "    method: str - метод преобразования, который нужно обратить\n",
        "    \n",
        "    Returns:\n",
        "    original_scale_predictions: array - прогнозы в исходном масштабе\n",
        "    \"\"\"\n",
        "    if method == 'diff':\n",
        "        # Обращение разности\n",
        "        last_value = original_ts.iloc[-1]\n",
        "        predictions = []\n",
        "        current_value = last_value\n",
        "        \n",
        "        for diff_pred in transformed_predictions:\n",
        "            next_value = current_value + diff_pred\n",
        "            predictions.append(next_value)\n",
        "            current_value = next_value\n",
        "            \n",
        "        return np.array(predictions)\n",
        "    \n",
        "    elif method == 'log_diff':\n",
        "        # Обращение лог-разности\n",
        "        last_log_value = np.log(original_ts.iloc[-1])\n",
        "        predictions = []\n",
        "        current_log_value = last_log_value\n",
        "        \n",
        "        for log_diff_pred in transformed_predictions:\n",
        "            next_log_value = current_log_value + log_diff_pred\n",
        "            next_value = np.exp(next_log_value)\n",
        "            predictions.append(next_value)\n",
        "            current_log_value = next_log_value\n",
        "            \n",
        "        return np.array(predictions)\n",
        "    \n",
        "    elif method == 'pct_change':\n",
        "        # Обращение процентного изменения\n",
        "        last_value = original_ts.iloc[-1]\n",
        "        predictions = []\n",
        "        current_value = last_value\n",
        "        \n",
        "        for pct_pred in transformed_predictions:\n",
        "            next_value = current_value * (1 + pct_pred)\n",
        "            predictions.append(next_value)\n",
        "            current_value = next_value\n",
        "            \n",
        "        return np.array(predictions)\n",
        "    \n",
        "    else:\n",
        "        raise ValueError(\"Method should be 'diff', 'log_diff', or 'pct_change'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Загрузка данных\n",
        "def load_series_map(series_dir=\"../../data/series\"):\n",
        "    series_map = {}\n",
        "    series_path = Path(series_dir)\n",
        "    if not series_path.exists():\n",
        "        raise FileNotFoundError(f\"Папка не найдена: {series_dir}\")\n",
        "    for csv_file in series_path.glob(\"*.csv\"):\n",
        "        ticker = csv_file.stem.upper()\n",
        "        df = pd.read_csv(csv_file)\n",
        "        if \"timestamp\" not in df.columns or \"close\" not in df.columns:\n",
        "            raise ValueError(f\"{csv_file.name} не содержит 'timestamp' или 'close'\")\n",
        "        df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], utc=True)\n",
        "        df = df[[\"timestamp\", \"close\"]].sort_values(\"timestamp\").reset_index(drop=True)\n",
        "        series_map[ticker] = df\n",
        "        print(f\"✔ Loaded: {csv_file} → ticker='{ticker}', rows={len(df)}\")\n",
        "    return series_map\n",
        "\n",
        "series_map = load_series_map(\"../../data/series\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Подготовка данных для моделирования\n",
        "series = {}\n",
        "for ticker, df in series_map.items():\n",
        "    tmp = df.copy()\n",
        "    tmp[\"timestamp\"] = pd.to_datetime(tmp[\"timestamp\"], utc=True)\n",
        "    tmp = tmp.rename(columns={\"close\": \"target\"})\n",
        "    tmp[\"segment\"] = ticker\n",
        "    tmp = tmp[[\"timestamp\", \"segment\", \"target\"]]\n",
        "\n",
        "    # 1) Сначала вручную реиндексируем по business-day (freq=\"B\") и заполним пропуски ffill→bfill\n",
        "    tmp = tmp.set_index(\"timestamp\")\n",
        "    all_biz = pd.date_range(start=tmp.index.min(), end=tmp.index.max(), freq=\"B\", tz=\"UTC\")\n",
        "    tmp = tmp.reindex(all_biz)\n",
        "    tmp[\"target\"] = tmp[\"target\"].ffill().bfill()\n",
        "    tmp = tmp.reset_index().rename(columns={\"index\": \"timestamp\"})\n",
        "    tmp[\"segment\"] = ticker\n",
        "\n",
        "    # 2) Строим одно-сегментный TSDataset с freq=\"B\"\n",
        "    ts = TSDataset(tmp, freq=\"B\")\n",
        "\n",
        "    # 3) Разбиваем 90% / 10% по количеству точек\n",
        "    n_points = ts.df.shape[0]\n",
        "    train_size = int(n_points * 0.9)\n",
        "    test_size = n_points - train_size\n",
        "\n",
        "    train_ts, test_ts = ts.train_test_split(test_size=test_size)\n",
        "\n",
        "    # Проверим, что в конце train нет NaN\n",
        "    df_train_flat = train_ts.to_pandas(flatten=True)\n",
        "    last_val = df_train_flat.iloc[-1]['target']\n",
        "    assert not pd.isna(last_val), f\"NaN в последнем значении train для {ticker}\"\n",
        "\n",
        "    series[ticker] = (ts, train_ts, test_ts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## AutoARIMA Model\n",
        "\n",
        "AutoARIMA автоматически определяет наилучшие параметры ARIMA для временного ряда.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# AutoARIMA Model\n",
        "results_map = {}\n",
        "\n",
        "for ticker, (full_ts, train_ts, test_ts) in series.items():\n",
        "    print(f\"\\n--- Тикер {ticker} ---\")\n",
        "    \n",
        "    # 1) Инициализируем и обучаем AutoARIMA модель\n",
        "    model = AutoARIMAModel()\n",
        "    start_time = time.time()\n",
        "    model.fit(train_ts)\n",
        "    fit_time = time.time() - start_time\n",
        "    \n",
        "    # 2) Выполняем прогноз на test_size точек и замеряем время\n",
        "    test_size = test_ts.df.shape[0]\n",
        "    start_time = time.time()\n",
        "    forecast_ts = model.forecast(ts=train_ts, prediction_size=test_size)\n",
        "    end_time = time.time()\n",
        "    forecast_time = ((end_time - start_time) / test_size) * 100  # Время в секундах на один прогноз\n",
        "    \n",
        "    # 3) Собираем прогноз и реальные значения\n",
        "    df_pred = forecast_ts.to_pandas(flatten=True)\n",
        "    df_true = test_ts.to_pandas(flatten=True)\n",
        "    \n",
        "    y_true = df_true[\"target\"].values\n",
        "    y_pred = df_pred[\"target\"].values\n",
        "\n",
        "    # 4) Считаем метрики\n",
        "    mae_v   = MAE()(test_ts, forecast_ts)\n",
        "    mape_v  = MAPE()(test_ts, forecast_ts)\n",
        "    rmse_v  = RMSE()(test_ts, forecast_ts)\n",
        "    smape_v = SMAPE()(test_ts, forecast_ts)\n",
        "    da_v = directional_accuracy(y_true, y_pred)\n",
        "    \n",
        "    # 5) Сохраняем метрики и прогноз\n",
        "    results_map[ticker] = {\n",
        "        \"MAE\": mae_v[ticker],\n",
        "        \"MAPE (%)\": mape_v[ticker],\n",
        "        \"RMSE\": rmse_v[ticker],\n",
        "        \"SMAPE (%)\": smape_v[ticker],\n",
        "        \"DA (%)\": da_v,\n",
        "        \"Fit time (s)\": fit_time,\n",
        "        \"Forecast time (s)\": forecast_time\n",
        "    }\n",
        "    \n",
        "    # 6) Визуализируем результаты\n",
        "    plot_forecast(forecast_ts, test_ts)\n",
        "    plt.title(f'{ticker} - AutoARIMA Forecast')\n",
        "    plt.show()\n",
        "\n",
        "# 7) Собираем сводную таблицу метрик\n",
        "metrics_df = pd.DataFrame.from_dict(results_map, orient=\"index\")\n",
        "metrics_df.loc[\"AVERAGE\"] = metrics_df.mean(numeric_only=True)\n",
        "metrics_df = metrics_df.round(3)\n",
        "\n",
        "print(\"\\n=== Итоговая таблица метрик AutoARIMA ===\")\n",
        "display(metrics_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## SARIMAX Model\n",
        "\n",
        "SARIMA с экзогенными переменными. Подходит для рядов с сезонностью.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SARIMAX Model\n",
        "results_map = {}\n",
        "\n",
        "for ticker, (full_ts, train_ts, test_ts) in series.items():\n",
        "    print(f\"\\n--- Тикер {ticker} ---\")\n",
        "    \n",
        "    # 1) Инициализируем и обучаем SARIMAX модель\n",
        "    # Параметры можно настроить: order=(p,d,q), seasonal_order=(P,D,Q,s)\n",
        "    model = SARIMAXModel(order=(1,1,1), seasonal_order=(1,1,1,12))\n",
        "    start_time = time.time()\n",
        "    model.fit(train_ts)\n",
        "    fit_time = time.time() - start_time\n",
        "    \n",
        "    # 2) Выполняем прогноз на test_size точек и замеряем время\n",
        "    test_size = test_ts.df.shape[0]\n",
        "    start_time = time.time()\n",
        "    forecast_ts = model.forecast(ts=train_ts, prediction_size=test_size)\n",
        "    end_time = time.time()\n",
        "    forecast_time = ((end_time - start_time) / test_size) * 100  # Время в секундах на один прогноз\n",
        "    \n",
        "    # 3) Собираем прогноз и реальные значения\n",
        "    df_pred = forecast_ts.to_pandas(flatten=True)\n",
        "    df_true = test_ts.to_pandas(flatten=True)\n",
        "    \n",
        "    y_true = df_true[\"target\"].values\n",
        "    y_pred = df_pred[\"target\"].values\n",
        "\n",
        "    # 4) Считаем метрики\n",
        "    mae_v   = MAE()(test_ts, forecast_ts)\n",
        "    mape_v  = MAPE()(test_ts, forecast_ts)\n",
        "    rmse_v  = RMSE()(test_ts, forecast_ts)\n",
        "    smape_v = SMAPE()(test_ts, forecast_ts)\n",
        "    da_v = directional_accuracy(y_true, y_pred)\n",
        "    \n",
        "    # 5) Сохраняем метрики и прогноз\n",
        "    results_map[ticker] = {\n",
        "        \"MAE\": mae_v[ticker],\n",
        "        \"MAPE (%)\": mape_v[ticker],\n",
        "        \"RMSE\": rmse_v[ticker],\n",
        "        \"SMAPE (%)\": smape_v[ticker],\n",
        "        \"DA (%)\": da_v,\n",
        "        \"Fit time (s)\": fit_time,\n",
        "        \"Forecast time (s)\": forecast_time\n",
        "    }\n",
        "    \n",
        "    # 6) Визуализируем результаты\n",
        "    plot_forecast(forecast_ts, test_ts)\n",
        "    plt.title(f'{ticker} - SARIMAX Forecast')\n",
        "    plt.show()\n",
        "\n",
        "# 7) Собираем сводную таблицу метрик\n",
        "metrics_df = pd.DataFrame.from_dict(results_map, orient=\"index\")\n",
        "metrics_df.loc[\"AVERAGE\"] = metrics_df.mean(numeric_only=True)\n",
        "metrics_df = metrics_df.round(3)\n",
        "\n",
        "print(\"\\n=== Итоговая таблица метрик SARIMAX ===\")\n",
        "display(metrics_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Holt-Winters Model\n",
        "\n",
        "Экспоненциальное сглаживание с трендом и сезонностью.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Holt-Winters Model\n",
        "results_map = {}\n",
        "\n",
        "for ticker, (full_ts, train_ts, test_ts) in series.items():\n",
        "    print(f\"\\n--- Тикер {ticker} ---\")\n",
        "    \n",
        "    # 1) Инициализируем и обучаем Holt-Winters модель\n",
        "    # Параметры: seasonal_periods - период сезонности, trend, seasonal - типы тренда и сезонности\n",
        "    model = HoltWintersModel(seasonal_periods=12, trend=\"add\", seasonal=\"add\")\n",
        "    start_time = time.time()\n",
        "    model.fit(train_ts)\n",
        "    fit_time = time.time() - start_time\n",
        "    \n",
        "    # 2) Выполняем прогноз на test_size точек и замеряем время\n",
        "    test_size = test_ts.df.shape[0]\n",
        "    start_time = time.time()\n",
        "    forecast_ts = model.forecast(ts=train_ts, prediction_size=test_size)\n",
        "    end_time = time.time()\n",
        "    forecast_time = ((end_time - start_time) / test_size) * 100  # Время в секундах на один прогноз\n",
        "    \n",
        "    # 3) Собираем прогноз и реальные значения\n",
        "    df_pred = forecast_ts.to_pandas(flatten=True)\n",
        "    df_true = test_ts.to_pandas(flatten=True)\n",
        "    \n",
        "    y_true = df_true[\"target\"].values\n",
        "    y_pred = df_pred[\"target\"].values\n",
        "\n",
        "    # 4) Считаем метрики\n",
        "    mae_v   = MAE()(test_ts, forecast_ts)\n",
        "    mape_v  = MAPE()(test_ts, forecast_ts)\n",
        "    rmse_v  = RMSE()(test_ts, forecast_ts)\n",
        "    smape_v = SMAPE()(test_ts, forecast_ts)\n",
        "    da_v = directional_accuracy(y_true, y_pred)\n",
        "    \n",
        "    # 5) Сохраняем метрики и прогноз\n",
        "    results_map[ticker] = {\n",
        "        \"MAE\": mae_v[ticker],\n",
        "        \"MAPE (%)\": mape_v[ticker],\n",
        "        \"RMSE\": rmse_v[ticker],\n",
        "        \"SMAPE (%)\": smape_v[ticker],\n",
        "        \"DA (%)\": da_v,\n",
        "        \"Fit time (s)\": fit_time,\n",
        "        \"Forecast time (s)\": forecast_time\n",
        "    }\n",
        "    \n",
        "    # 6) Визуализируем результаты\n",
        "    plot_forecast(forecast_ts, test_ts)\n",
        "    plt.title(f'{ticker} - Holt-Winters Forecast')\n",
        "    plt.show()\n",
        "\n",
        "# 7) Собираем сводную таблицу метрик\n",
        "metrics_df = pd.DataFrame.from_dict(results_map, orient=\"index\")\n",
        "metrics_df.loc[\"AVERAGE\"] = metrics_df.mean(numeric_only=True)\n",
        "metrics_df = metrics_df.round(3)\n",
        "\n",
        "print(\"\\n=== Итоговая таблица метрик Holt-Winters ===\")\n",
        "display(metrics_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Анализ стационарности и работа с преобразованными данными\n",
        "\n",
        "Проверим стационарность рядов и покажем, как работать с преобразованиями.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Проверим стационарность для нескольких рядов\n",
        "sample_tickers = ['SBER', 'LKOH', 'MOEX']  # Берем несколько тикеров для анализа\n",
        "\n",
        "for ticker in sample_tickers:\n",
        "    if ticker in series_map:\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\"Анализ стационарности для {ticker}\")\n",
        "        print(f\"{'='*50}\")\n",
        "        \n",
        "        ts_data = series_map[ticker]['close']\n",
        "        \n",
        "        # 1) Проверим исходный ряд\n",
        "        print(f\"\\n1. Исходный ряд {ticker}:\")\n",
        "        is_stationary_orig = check_stationarity(ts_data, f\"{ticker} Original\")\n",
        "        \n",
        "        # 2) Проверим после взятия первой разности\n",
        "        print(f\"\\n2. Ряд {ticker} после взятия разности:\")\n",
        "        ts_diff = make_stationary(ts_data, method='diff')\n",
        "        is_stationary_diff = check_stationarity(ts_diff, f\"{ticker} Differenced\")\n",
        "        \n",
        "        # 3) Проверим логарифмические доходности\n",
        "        print(f\"\\n3. Ряд {ticker} - логарифмические доходности:\")\n",
        "        ts_log_diff = make_stationary(ts_data, method='log_diff')\n",
        "        is_stationary_log_diff = check_stationarity(ts_log_diff, f\"{ticker} Log Returns\")\n",
        "        \n",
        "        # 4) Визуализация\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "        \n",
        "        # Исходный ряд\n",
        "        axes[0,0].plot(ts_data)\n",
        "        axes[0,0].set_title(f'{ticker} - Исходный ряд')\n",
        "        axes[0,0].grid(True)\n",
        "        \n",
        "        # Разности\n",
        "        axes[0,1].plot(ts_diff)\n",
        "        axes[0,1].set_title(f'{ticker} - Первые разности')\n",
        "        axes[0,1].grid(True)\n",
        "        \n",
        "        # Логарифмические доходности\n",
        "        axes[1,0].plot(ts_log_diff)\n",
        "        axes[1,0].set_title(f'{ticker} - Логарифмические доходности')\n",
        "        axes[1,0].grid(True)\n",
        "        \n",
        "        # Процентные изменения\n",
        "        ts_pct = make_stationary(ts_data, method='pct_change')\n",
        "        axes[1,1].plot(ts_pct)\n",
        "        axes[1,1].set_title(f'{ticker} - Процентные изменения')\n",
        "        axes[1,1].grid(True)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        print(f\"\\nРезультаты для {ticker}:\")\n",
        "        print(f\"Исходный ряд стационарен: {is_stationary_orig}\")\n",
        "        print(f\"Ряд разностей стационарен: {is_stationary_diff}\")\n",
        "        print(f\"Лог-доходности стационарны: {is_stationary_log_diff}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
